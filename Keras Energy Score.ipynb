{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018=pd.read_csv(r'C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\energy-2018.csv')\n",
    "df_2017=pd.read_csv(r'C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\energy-2017.csv')\n",
    "df_2016=pd.read_csv(r'C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\energy-2016.csv')\n",
    "df_feat = pd.read_csv(r'C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\energy.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_2019=df_feat.iloc[:,21:24].columns\n",
    "col_2018=df_2018.iloc[:,21:24].columns\n",
    "col_2017=df_2017.iloc[:,21:24].columns\n",
    "col_2016=df_2016.iloc[:,21:24].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = df_feat.drop(columns=col_2019) \n",
    "df_2018=df_2018.drop(columns=col_2018)\n",
    "df_2017=df_2017.drop(columns=col_2017)\n",
    "df_2016=df_2016.drop(columns=col_2016)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = df_feat.drop(columns='5 Year Energy Action and Assessment Compliance Status') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2019</th>\n",
       "      <th>2018</th>\n",
       "      <th>2017</th>\n",
       "      <th>2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Property Name</td>\n",
       "      <td>Property Name</td>\n",
       "      <td>Property Name</td>\n",
       "      <td>Property Name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reported</td>\n",
       "      <td>Reported</td>\n",
       "      <td>Reported</td>\n",
       "      <td>Reported</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Property Type</td>\n",
       "      <td>Property Type</td>\n",
       "      <td>Property Type</td>\n",
       "      <td>Property Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Address</td>\n",
       "      <td>Address</td>\n",
       "      <td>Address</td>\n",
       "      <td>Address</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZIP</td>\n",
       "      <td>ZIP</td>\n",
       "      <td>ZIP</td>\n",
       "      <td>ZIP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gross Area (sq ft)</td>\n",
       "      <td>Gross Area (sq ft)</td>\n",
       "      <td>Gross Area (sq ft)</td>\n",
       "      <td>Gross Area (sq ft)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Site EUI (kBTU/sf)</td>\n",
       "      <td>Site EUI (kBTU/sf)</td>\n",
       "      <td>Site EUI (kBTU/sf)</td>\n",
       "      <td>Site EUI (kBTU/sf)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Energy Star Score</td>\n",
       "      <td>Energy Star Score</td>\n",
       "      <td>Energy Star Score</td>\n",
       "      <td>Energy Star Score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Energy Star Certified</td>\n",
       "      <td>Energy Star Certified</td>\n",
       "      <td>Energy Star Certified</td>\n",
       "      <td>Energy Star Certified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Property Uses</td>\n",
       "      <td>Property Uses</td>\n",
       "      <td>Property Uses</td>\n",
       "      <td>Property Uses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Year Built</td>\n",
       "      <td>Year Built</td>\n",
       "      <td>Year Built</td>\n",
       "      <td>Year Built</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GHG Emissions (MTCO2e)</td>\n",
       "      <td>GHG Emissions (MTCO2e)</td>\n",
       "      <td>GHG Emissions (MTCO2e)</td>\n",
       "      <td>GHG Emissions (MTCO2e)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GHG Intensity (kgCO2/sf)</td>\n",
       "      <td>GHG Intensity (kgCO2/sf)</td>\n",
       "      <td>GHG Intensity (kgCO2/sf)</td>\n",
       "      <td>GHG Intensity (kgCO2/sf)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Total Site Energy (kBTU)</td>\n",
       "      <td>Total Site Energy (kBTU)</td>\n",
       "      <td>Total Site Energy (kBTU)</td>\n",
       "      <td>Total Site Energy (kBTU)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>% Electricity</td>\n",
       "      <td>% Electricity</td>\n",
       "      <td>% Electricity</td>\n",
       "      <td>% Electricity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>% Gas</td>\n",
       "      <td>% Gas</td>\n",
       "      <td>% Gas</td>\n",
       "      <td>% Gas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>% Steam</td>\n",
       "      <td>% Steam</td>\n",
       "      <td>% Steam</td>\n",
       "      <td>% Steam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Water Intensity (gal/sf)</td>\n",
       "      <td>Water Intensity (gal/sf)</td>\n",
       "      <td>Water Intensity (gal/sf)</td>\n",
       "      <td>Water Intensity (gal/sf)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Onsite Renewable (kWh)</td>\n",
       "      <td>Onsite Solar (kWh)</td>\n",
       "      <td>Onsite Renewable (kWh)</td>\n",
       "      <td>Onsite Solar (kWh)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>User Submitted Info</td>\n",
       "      <td>User Submitted Info</td>\n",
       "      <td>User Submitted Info</td>\n",
       "      <td>User Submitted Info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>User Submitted Link</td>\n",
       "      <td>User Submitted Link</td>\n",
       "      <td>User Submitted Link</td>\n",
       "      <td>User Submitted Link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          2019                        2018  \\\n",
       "0                Property Name               Property Name   \n",
       "1                     Reported                    Reported   \n",
       "2                Property Type               Property Type   \n",
       "3                      Address                     Address   \n",
       "4                          ZIP                         ZIP   \n",
       "5          Gross Area (sq ft)           Gross Area (sq ft)   \n",
       "6           Site EUI (kBTU/sf)          Site EUI (kBTU/sf)   \n",
       "7            Energy Star Score           Energy Star Score   \n",
       "8        Energy Star Certified       Energy Star Certified   \n",
       "9                Property Uses               Property Uses   \n",
       "10                  Year Built                  Year Built   \n",
       "11     GHG Emissions (MTCO2e)       GHG Emissions (MTCO2e)   \n",
       "12    GHG Intensity (kgCO2/sf)    GHG Intensity (kgCO2/sf)   \n",
       "13   Total Site Energy (kBTU)    Total Site Energy (kBTU)    \n",
       "14               % Electricity               % Electricity   \n",
       "15                       % Gas                       % Gas   \n",
       "16                     % Steam                     % Steam   \n",
       "17    Water Intensity (gal/sf)    Water Intensity (gal/sf)   \n",
       "18     Onsite Renewable (kWh)           Onsite Solar (kWh)   \n",
       "19         User Submitted Info         User Submitted Info   \n",
       "20         User Submitted Link         User Submitted Link   \n",
       "\n",
       "                          2017                        2016  \n",
       "0                Property Name               Property Name  \n",
       "1                     Reported                    Reported  \n",
       "2                Property Type               Property Type  \n",
       "3                      Address                     Address  \n",
       "4                          ZIP                         ZIP  \n",
       "5          Gross Area (sq ft)           Gross Area (sq ft)  \n",
       "6           Site EUI (kBTU/sf)          Site EUI (kBTU/sf)  \n",
       "7            Energy Star Score           Energy Star Score  \n",
       "8        Energy Star Certified       Energy Star Certified  \n",
       "9                Property Uses               Property Uses  \n",
       "10                  Year Built                  Year Built  \n",
       "11     GHG Emissions (MTCO2e)       GHG Emissions (MTCO2e)  \n",
       "12    GHG Intensity (kgCO2/sf)    GHG Intensity (kgCO2/sf)  \n",
       "13   Total Site Energy (kBTU)    Total Site Energy (kBTU)   \n",
       "14               % Electricity               % Electricity  \n",
       "15                       % Gas                       % Gas  \n",
       "16                     % Steam                     % Steam  \n",
       "17    Water Intensity (gal/sf)    Water Intensity (gal/sf)  \n",
       "18     Onsite Renewable (kWh)           Onsite Solar (kWh)  \n",
       "19         User Submitted Info         User Submitted Info  \n",
       "20         User Submitted Link         User Submitted Link  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b,c,d=[],[],[],[]\n",
    "a=df_feat.columns\n",
    "b=df_2018.columns\n",
    "c=df_2017.columns\n",
    "d=df_2016.columns\n",
    "dictum={'2019':a,'2018':b,'2017':c,'2016':d}\n",
    "df = pd.DataFrame.from_dict(dictum, orient='index')\n",
    "df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combine=pd.concat([df_feat,df_2018,df_2017,df_2016],sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combine.index=range(6560)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combine.to_csv(r'C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\Combine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Index(['Property Name', 'Reported', 'Property Type', 'Address', 'ZIP',\n",
       "        'Energy Star Certified', 'Property Uses', 'Year Built', '% Steam',\n",
       "        ' Onsite Renewable (kWh) ', 'User Submitted Info',\n",
       "        'User Submitted Link', 'Gross Area (sq ft)', 'GHG Emissions (MTCO2e)',\n",
       "        'Onsite Solar (kWh)'],\n",
       "       dtype='object')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_col=[]\n",
    "drop_col.append(df_combine.iloc[:,[0,1,2,3,4,8,9,10,16,18,19,20,21,22,23]].columns)\n",
    "drop_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combine=df_combine.drop(columns=df_combine.iloc[:,[0,1,2,3,4,8,9,10,21,16,18,19,20,22,23]].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combine=df_combine.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([' Gross Area (sq ft) ', 'Site EUI (kBTU/sf)', 'Energy Star Score',\n",
       "       ' GHG Emissions (MTCO2e) ', 'GHG Intensity (kgCO2/sf)',\n",
       "       ' Total Site Energy (kBTU) ', '% Electricity', '% Gas',\n",
       "       'Water Intensity (gal/sf)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_feat.iloc[:,3]=df_feat.iloc[:,3].astype('object')\n",
    "\n",
    "X=df_combine.drop(columns='Energy Star Score')\n",
    "df_combine.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_combine.iloc[:,2]\n",
    "y=y.astype('int32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[:,-1]=X.iloc[:,-1].apply(lambda x:0 if x=='Not Available' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[:,-1]=pd.to_numeric(X.iloc[:,-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gross Area (sq ft)</th>\n",
       "      <th>Site EUI (kBTU/sf)</th>\n",
       "      <th>GHG Emissions (MTCO2e)</th>\n",
       "      <th>GHG Intensity (kgCO2/sf)</th>\n",
       "      <th>Total Site Energy (kBTU)</th>\n",
       "      <th>% Electricity</th>\n",
       "      <th>% Gas</th>\n",
       "      <th>Water Intensity (gal/sf)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123596</td>\n",
       "      <td>86.8</td>\n",
       "      <td>696.5</td>\n",
       "      <td>5.6</td>\n",
       "      <td>10733299</td>\n",
       "      <td>0.497101</td>\n",
       "      <td>0.460182</td>\n",
       "      <td>5.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130520</td>\n",
       "      <td>69.6</td>\n",
       "      <td>590.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9085993</td>\n",
       "      <td>0.49998</td>\n",
       "      <td>0.457056</td>\n",
       "      <td>5.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42918</td>\n",
       "      <td>251.9</td>\n",
       "      <td>1019.8</td>\n",
       "      <td>17.1</td>\n",
       "      <td>14993662.6</td>\n",
       "      <td>0.628841</td>\n",
       "      <td>0.317121</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gross Area (sq ft)  Site EUI (kBTU/sf)  GHG Emissions (MTCO2e)   \\\n",
       "0               123596               86.8                    696.5   \n",
       "1               130520               69.6                    590.3   \n",
       "2                42918              251.9                   1019.8   \n",
       "\n",
       "  GHG Intensity (kgCO2/sf)  Total Site Energy (kBTU)  % Electricity     % Gas  \\\n",
       "0                      5.6                   10733299      0.497101  0.460182   \n",
       "1                      4.5                    9085993       0.49998  0.457056   \n",
       "2                     17.1                 14993662.6      0.628841  0.317121   \n",
       "\n",
       "   Water Intensity (gal/sf)  \n",
       "0                      5.52  \n",
       "1                      5.99  \n",
       "2                      0.00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 object\n",
      "1 object\n",
      "2 object\n",
      "3 object\n",
      "4 object\n",
      "5 object\n",
      "6 object\n",
      "7 float64\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X.columns)):\n",
    "     print(i,X.iloc[:,i].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[:,5]=X.iloc[:,5].apply(lambda x: 0 if x == '#DIV/0' else x)\n",
    "X.iloc[:,6]=X.iloc[:,6].apply(lambda x: 0 if x == '#DIV/0' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 float64\n",
      "1 float64\n",
      "2 float64\n",
      "3 float64\n",
      "4 float64\n",
      "5 float64\n",
      "6 float64\n",
      "7 float64\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X.columns)):\n",
    "     X.iloc[:,i]=X.iloc[:,i].astype('float')\n",
    "     print(i,X.iloc[:,i].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gross Area (sq ft)</th>\n",
       "      <th>Site EUI (kBTU/sf)</th>\n",
       "      <th>GHG Emissions (MTCO2e)</th>\n",
       "      <th>GHG Intensity (kgCO2/sf)</th>\n",
       "      <th>Total Site Energy (kBTU)</th>\n",
       "      <th>% Electricity</th>\n",
       "      <th>% Gas</th>\n",
       "      <th>Water Intensity (gal/sf)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.906000e+03</td>\n",
       "      <td>1906.000000</td>\n",
       "      <td>1.906000e+03</td>\n",
       "      <td>1906.000000</td>\n",
       "      <td>1.906000e+03</td>\n",
       "      <td>1906.000000</td>\n",
       "      <td>1906.000000</td>\n",
       "      <td>1.906000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.614648e+05</td>\n",
       "      <td>414.998688</td>\n",
       "      <td>1.672102e+03</td>\n",
       "      <td>27.132489</td>\n",
       "      <td>2.682264e+07</td>\n",
       "      <td>0.366933</td>\n",
       "      <td>0.578424</td>\n",
       "      <td>1.501656e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.562886e+05</td>\n",
       "      <td>13319.465910</td>\n",
       "      <td>2.608905e+04</td>\n",
       "      <td>884.501048</td>\n",
       "      <td>3.942956e+08</td>\n",
       "      <td>0.227698</td>\n",
       "      <td>0.267033</td>\n",
       "      <td>3.762485e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.200000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.450800e+04</td>\n",
       "      <td>54.850000</td>\n",
       "      <td>1.830250e+02</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.028352e+06</td>\n",
       "      <td>0.178089</td>\n",
       "      <td>0.396815</td>\n",
       "      <td>8.460000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.013850e+04</td>\n",
       "      <td>70.900000</td>\n",
       "      <td>3.676500e+02</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>5.957904e+06</td>\n",
       "      <td>0.320326</td>\n",
       "      <td>0.638255</td>\n",
       "      <td>2.688500e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.710350e+05</td>\n",
       "      <td>94.475000</td>\n",
       "      <td>8.298500e+02</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>1.324854e+07</td>\n",
       "      <td>0.515545</td>\n",
       "      <td>0.801994</td>\n",
       "      <td>4.550750e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.912529e+06</td>\n",
       "      <td>579540.100000</td>\n",
       "      <td>1.098619e+06</td>\n",
       "      <td>38485.100000</td>\n",
       "      <td>1.654579e+10</td>\n",
       "      <td>0.999740</td>\n",
       "      <td>0.999006</td>\n",
       "      <td>1.058521e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Gross Area (sq ft)   Site EUI (kBTU/sf)   GHG Emissions (MTCO2e)   \\\n",
       "count          1.906000e+03         1906.000000              1.906000e+03   \n",
       "mean           1.614648e+05          414.998688              1.672102e+03   \n",
       "std            2.562886e+05        13319.465910              2.608905e+04   \n",
       "min            7.200000e+03            0.000000              0.000000e+00   \n",
       "25%            4.450800e+04           54.850000              1.830250e+02   \n",
       "50%            8.013850e+04           70.900000              3.676500e+02   \n",
       "75%            1.710350e+05           94.475000              8.298500e+02   \n",
       "max            3.912529e+06       579540.100000              1.098619e+06   \n",
       "\n",
       "       GHG Intensity (kgCO2/sf)   Total Site Energy (kBTU)   % Electricity  \\\n",
       "count               1906.000000                1.906000e+03    1906.000000   \n",
       "mean                  27.132489                2.682264e+07       0.366933   \n",
       "std                  884.501048                3.942956e+08       0.227698   \n",
       "min                    0.000000                0.000000e+00       0.000000   \n",
       "25%                    3.400000                3.028352e+06       0.178089   \n",
       "50%                    4.400000                5.957904e+06       0.320326   \n",
       "75%                    5.800000                1.324854e+07       0.515545   \n",
       "max                38485.100000                1.654579e+10       0.999740   \n",
       "\n",
       "             % Gas  Water Intensity (gal/sf)  \n",
       "count  1906.000000              1.906000e+03  \n",
       "mean      0.578424              1.501656e+04  \n",
       "std       0.267033              3.762485e+05  \n",
       "min       0.000000              0.000000e+00  \n",
       "25%       0.396815              8.460000e+00  \n",
       "50%       0.638255              2.688500e+01  \n",
       "75%       0.801994              4.550750e+01  \n",
       "max       0.999006              1.058521e+07  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a879cea240>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a879b9ef60>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(X.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "sc= MinMaxScaler()\n",
    "X_transform= sc.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transform, y, test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor\n",
    "error_rate = []\n",
    "\n",
    "# Will take some time\n",
    "for i in range(1,40):\n",
    "    \n",
    "    knn = KNeighborsRegressor(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Error Rate')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2568bbdcc88>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04895104895104895\n"
     ]
    }
   ],
   "source": [
    "# NOW WITH K=23\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=36)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 33.88986013986014\n",
      "MSE: 1911.2395104895104\n",
      "RMSE: 43.71772535813718\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "#print('MAE:', metrics.mean_absolute_error(y_test, pred))\n",
    "#print('MSE:', metrics.mean_squared_error(y_test, pred))\n",
    "#print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=[]\n",
    "mse=[]\n",
    "rmse=[]\n",
    "mae=[]\n",
    "for i in range(1,41):\n",
    "    knn = KNeighborsRegressor(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred = knn.predict(X_test)\n",
    "    #print('K value is {} and Accuracy is:{}'.format(i,accuracy_score(y_test,pred)))\n",
    "    #acc.append(accuracy_score(y_test,pred))\n",
    "    mae.append(metrics.mean_absolute_error(y_test, pred))\n",
    "    mse.append(metrics.mean_squared_error(y_test, pred))\n",
    "    rmse.append(np.sqrt(metrics.mean_squared_error(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1732.25786163522\n",
      "1240.3836477987422\n",
      "1142.6049382716049\n",
      "1031.4261006289307\n",
      "1006.5962264150944\n",
      "990.9084556254368\n",
      "955.5072091729774\n",
      "937.0088770964361\n",
      "942.944069156508\n",
      "940.2662893081762\n",
      "932.8350919139941\n",
      "927.2850570696484\n",
      "926.7421135548856\n",
      "917.621978351089\n",
      "914.5175401816911\n",
      "918.6525402908806\n",
      "914.0646775913473\n",
      "911.927362372855\n",
      "914.6996347206978\n",
      "913.4121016771488\n",
      "921.3574019405107\n",
      "923.1422068021554\n",
      "925.0271744084207\n",
      "924.1500007279291\n",
      "925.9448486373166\n",
      "926.1550153201098\n",
      "921.8169141266432\n",
      "920.4733399649168\n",
      "914.9570043648746\n",
      "912.2232285115304\n",
      "911.571186111602\n",
      "913.6638516280136\n",
      "912.8918747220634\n",
      "911.9500246639536\n",
      "911.3244718264663\n",
      "910.8005765199161\n",
      "908.7157284770747\n",
      "906.0366440762615\n",
      "902.5386999891111\n",
      "902.3461176624738\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,41):\n",
    "    knn = KNeighborsRegressor(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred = knn.predict(X_test)\n",
    "    print(metrics.mean_squared_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x256834a4400>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x256ff35fcc0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,41),acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(902.3461176624738, 24.981394129979037, 30.03907651147874)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(mse),np.min(mae),np.min(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']} \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kanishk\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.064, total=   0.2s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.064, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.064, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.064, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.064, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.064, total=   0.2s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.064, total=   0.2s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.064, total=   0.1s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.064, total=   0.1s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.064, total=   0.2s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.064, total=   0.3s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.060, total=   0.4s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.064, total=   0.3s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.064, total=   0.2s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.064, total=   0.2s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.064, total=   0.2s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.056, total=   0.4s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.064, total=   0.5s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.052, total=   0.4s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.060, total=   0.5s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.060, total=   0.4s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.064, total=   0.3s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.064, total=   0.2s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.064, total=   0.2s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.064, total=   0.1s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.060, total=   0.1s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.049, total=   1.2s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.060, total=   1.2s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.052, total=   1.4s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.056, total=   1.3s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.056, total=   1.3s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.056, total=   0.8s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.064, total=   0.8s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.060, total=   0.7s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.060, total=   0.8s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.056, total=   0.8s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.056, total=   0.4s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.064, total=   0.3s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.064, total=   0.2s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.064, total=   0.2s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.060, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:   32.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['rbf']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05244755244755245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 38.48076923076923\n",
      "MSE: 2386.6975524475524\n",
      "RMSE: 48.85383866645028\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, prediction))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, prediction))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=GradientBoostingClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "prediction_Grad=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07966457023060797\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,prediction_Grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for train, test in kf.split(X):\n",
    "#     grid.fit(X_transform[train], y[train])\n",
    "y=y.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kanishk\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.060, total=   0.4s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.056, total=   0.4s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.052, total=   0.5s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.060, total=   0.5s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.056, total=   0.4s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.056, total=   0.4s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.060, total=   0.4s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.063, total=   0.8s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.059, total=   0.8s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.052, total=   0.8s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.063, total=   0.8s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.056, total=   0.9s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.059, total=   0.6s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.059, total=   0.5s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.056, total=   0.5s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.059, total=   0.6s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.060, total=   0.6s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.056, total=   0.4s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.056, total=   0.4s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.060, total=   0.4s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.060, total=   0.4s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.063, total=   2.4s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.049, total=   2.3s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.049, total=   2.4s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.066, total=   2.5s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.063, total=   2.5s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.066, total=   1.5s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.063, total=   1.4s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.056, total=   1.5s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.059, total=   1.5s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.063, total=   1.4s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.059, total=   0.7s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.059, total=   0.7s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.052, total=   0.7s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.059, total=   0.7s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.060, total=   0.7s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.056, total=   0.4s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.060, total=   0.4s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.060, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kanishk\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.056, total=   0.5s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.059, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.056, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.056, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.059, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.056, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.056, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.056, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.059, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.059, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.056, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.056, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.052, total=   0.3s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.059, total=   0.1s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.056, total=   0.1s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.066, total=   0.3s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.063, total=   0.3s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.067, total=   0.3s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.052, total=   0.2s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.059, total=   0.1s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.059, total=   0.1s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.056, total=   0.1s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.063, total=   0.5s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.059, total=   0.5s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.063, total=   0.5s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.066, total=   0.5s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.063, total=   0.5s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.052, total=   0.3s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.056, total=   0.4s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.052, total=   0.2s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.056, total=   0.2s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.059, total=   0.1s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.056, total=   0.1s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.056, total=   0.1s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.056, total=   0.1s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.066, total=   1.3s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.052, total=   1.4s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.063, total=   1.3s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.066, total=   1.3s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.060, total=   2.3s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.063, total=   1.2s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.056, total=   1.3s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.063, total=   1.2s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.063, total=   1.3s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.063, total=   1.5s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.059, total=   0.7s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.052, total=   0.6s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.059, total=   0.6s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.059, total=   0.6s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.056, total=   0.7s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.052, total=   0.4s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.056, total=   0.4s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.056, total=   0.4s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.056, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:   42.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kanishk\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.056, total=   0.3s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.060, total=   0.4s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.056, total=   0.5s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.063, total=   0.4s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.063, total=   0.5s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.059, total=   0.5s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.067, total=   0.5s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.056, total=   0.4s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.060, total=   0.4s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.056, total=   0.8s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.059, total=   0.9s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.056, total=   0.8s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.056, total=   0.9s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.056, total=   0.8s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.059, total=   0.6s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.059, total=   0.6s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.059, total=   0.6s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.059, total=   0.6s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.060, total=   0.6s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.056, total=   0.4s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.060, total=   0.4s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.042, total=   2.2s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.059, total=   2.4s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.056, total=   2.2s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.063, total=   2.6s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.060, total=   2.3s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.063, total=   1.4s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.063, total=   1.4s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.063, total=   1.5s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.059, total=   1.5s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.067, total=   1.5s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.059, total=   0.6s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.059, total=   0.7s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.059, total=   0.7s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.059, total=   0.7s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.060, total=   0.7s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.056, total=   0.4s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.060, total=   0.4s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.060, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kanishk\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.063, total=   0.3s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.063, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.063, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.063, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.063, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.063, total=   0.4s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.060, total=   0.4s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.063, total=   0.3s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.063, total=   0.3s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.063, total=   0.3s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.063, total=   0.3s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.059, total=   0.5s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.059, total=   0.5s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.059, total=   0.5s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.059, total=   0.5s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.056, total=   0.5s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.063, total=   0.4s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.059, total=   0.5s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.060, total=   0.4s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.063, total=   0.3s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.063, total=   0.3s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.063, total=   0.2s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.063, total=   0.9s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.059, total=   0.9s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.066, total=   0.9s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.063, total=   0.9s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.060, total=   0.7s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.059, total=   0.6s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.063, total=   0.6s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.059, total=   0.6s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.056, total=   0.4s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.063, total=   0.4s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.063, total=   0.2s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.060, total=   0.2s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.063, total=   0.3s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.049, total=   2.5s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.052, total=   2.3s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.063, total=   2.7s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.063, total=   2.5s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.056, total=   2.3s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.059, total=   1.4s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.066, total=   1.6s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.063, total=   1.6s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.059, total=   1.6s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.060, total=   1.5s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.059, total=   0.7s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.063, total=   0.7s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.059, total=   0.7s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.056, total=   0.6s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.056, total=   0.6s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.063, total=   0.3s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.059, total=   0.4s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.060, total=   0.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.059, total=   0.2s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.063, total=   0.2s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.059, total=   0.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.060, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:  1.0min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "ss = ShuffleSplit(n_splits=4, test_size=0.25, random_state=0)\n",
    "for train_index, test_index in ss.split(X_transform):\n",
    "    X_train, y_train, X_test, y_test=X_transform[train_index],y.iloc[train_index],X_transform[test_index],y.iloc[test_index]\n",
    "    grid.fit(X_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_Kfold=grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[448,  13],\n",
       "        [ 15,   1]],\n",
       "\n",
       "       [[473,   0],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[474,   0],\n",
       "        [  3,   0]],\n",
       "\n",
       "       [[474,   0],\n",
       "        [  3,   0]],\n",
       "\n",
       "       [[475,   0],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[474,   0],\n",
       "        [  3,   0]],\n",
       "\n",
       "       [[475,   0],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[475,   0],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[475,   0],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[475,   0],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[473,   0],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[475,   0],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[472,   0],\n",
       "        [  5,   0]],\n",
       "\n",
       "       [[472,   0],\n",
       "        [  5,   0]],\n",
       "\n",
       "       [[474,   0],\n",
       "        [  3,   0]],\n",
       "\n",
       "       [[475,   0],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[475,   0],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[475,   1],\n",
       "        [  1,   0]],\n",
       "\n",
       "       [[475,   0],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[472,   0],\n",
       "        [  5,   0]],\n",
       "\n",
       "       [[473,   0],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[474,   0],\n",
       "        [  3,   0]],\n",
       "\n",
       "       [[473,   2],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[472,   0],\n",
       "        [  5,   0]],\n",
       "\n",
       "       [[476,   0],\n",
       "        [  1,   0]],\n",
       "\n",
       "       [[473,   0],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[475,   0],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[475,   0],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[472,   0],\n",
       "        [  5,   0]],\n",
       "\n",
       "       [[476,   0],\n",
       "        [  1,   0]],\n",
       "\n",
       "       [[475,   0],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[470,   0],\n",
       "        [  7,   0]],\n",
       "\n",
       "       [[474,   0],\n",
       "        [  3,   0]],\n",
       "\n",
       "       [[473,   0],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[474,   0],\n",
       "        [  3,   0]],\n",
       "\n",
       "       [[475,   0],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[473,   0],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[474,   0],\n",
       "        [  3,   0]],\n",
       "\n",
       "       [[475,   0],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[471,   0],\n",
       "        [  6,   0]],\n",
       "\n",
       "       [[476,   0],\n",
       "        [  1,   0]],\n",
       "\n",
       "       [[474,   0],\n",
       "        [  3,   0]],\n",
       "\n",
       "       [[474,   0],\n",
       "        [  3,   0]],\n",
       "\n",
       "       [[469,   0],\n",
       "        [  8,   0]],\n",
       "\n",
       "       [[475,   0],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[472,   0],\n",
       "        [  5,   0]],\n",
       "\n",
       "       [[472,   0],\n",
       "        [  5,   0]],\n",
       "\n",
       "       [[472,   0],\n",
       "        [  5,   0]],\n",
       "\n",
       "       [[474,   0],\n",
       "        [  3,   0]],\n",
       "\n",
       "       [[473,   0],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[475,   0],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[473,   0],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[457,  16],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[473,   0],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[471,   0],\n",
       "        [  6,   0]],\n",
       "\n",
       "       [[474,   0],\n",
       "        [  3,   0]],\n",
       "\n",
       "       [[471,   0],\n",
       "        [  6,   0]],\n",
       "\n",
       "       [[469,   3],\n",
       "        [  5,   0]],\n",
       "\n",
       "       [[473,   0],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[470,   3],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[470,   0],\n",
       "        [  7,   0]],\n",
       "\n",
       "       [[472,   0],\n",
       "        [  5,   0]],\n",
       "\n",
       "       [[472,   0],\n",
       "        [  5,   0]],\n",
       "\n",
       "       [[473,   0],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[470,   0],\n",
       "        [  7,   0]],\n",
       "\n",
       "       [[470,   0],\n",
       "        [  7,   0]],\n",
       "\n",
       "       [[475,   0],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[473,   0],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[475,   0],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[472,   0],\n",
       "        [  5,   0]],\n",
       "\n",
       "       [[472,   0],\n",
       "        [  5,   0]],\n",
       "\n",
       "       [[469,   0],\n",
       "        [  8,   0]],\n",
       "\n",
       "       [[470,   0],\n",
       "        [  7,   0]],\n",
       "\n",
       "       [[468,   2],\n",
       "        [  7,   0]],\n",
       "\n",
       "       [[470,   0],\n",
       "        [  7,   0]],\n",
       "\n",
       "       [[469,   0],\n",
       "        [  8,   0]],\n",
       "\n",
       "       [[469,   0],\n",
       "        [  8,   0]],\n",
       "\n",
       "       [[473,   0],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[467,   0],\n",
       "        [ 10,   0]],\n",
       "\n",
       "       [[472,   0],\n",
       "        [  5,   0]],\n",
       "\n",
       "       [[471,   0],\n",
       "        [  6,   0]],\n",
       "\n",
       "       [[467,   2],\n",
       "        [  8,   0]],\n",
       "\n",
       "       [[472,   0],\n",
       "        [  5,   0]],\n",
       "\n",
       "       [[470,   0],\n",
       "        [  7,   0]],\n",
       "\n",
       "       [[472,   0],\n",
       "        [  5,   0]],\n",
       "\n",
       "       [[470,   0],\n",
       "        [  7,   0]],\n",
       "\n",
       "       [[465,   0],\n",
       "        [ 12,   0]],\n",
       "\n",
       "       [[466,   0],\n",
       "        [ 11,   0]],\n",
       "\n",
       "       [[465,   0],\n",
       "        [ 12,   0]],\n",
       "\n",
       "       [[471,   0],\n",
       "        [  6,   0]],\n",
       "\n",
       "       [[470,   0],\n",
       "        [  7,   0]],\n",
       "\n",
       "       [[465,   0],\n",
       "        [ 12,   0]],\n",
       "\n",
       "       [[469,   0],\n",
       "        [  8,   0]],\n",
       "\n",
       "       [[464,   0],\n",
       "        [ 13,   0]],\n",
       "\n",
       "       [[ 42, 410],\n",
       "        [  1,  24]]], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "multilabel_confusion_matrix(y_test,predict_Kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 36.9937106918239\n",
      "MSE: 2273.2159329140463\n",
      "RMSE: 47.678254298097436\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predict_Kfold))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predict_Kfold))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predict_Kfold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Actual Values':y_test,'Predictions':predict_Kfold})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.as_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm=LinearRegression()\n",
    "lm.fit(X_transform,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 24.38154825035872\n",
      "MSE: 868.7539694779532\n",
      "RMSE: 29.4746326436472\n"
     ]
    }
   ],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, prediction))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, prediction))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((652, 8), (652, 1), (280, 8), (280, 1))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense,Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.utils import Sequence, to_categorical\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import (EarlyStopping, LearningRateScheduler, ModelCheckpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_=y.values.reshape(-1,1)\n",
    "y_=to_categorical(y_)\n",
    "from keras.models import Sequential\n",
    "nClasses = len(np.unique(y.values))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transform, y_, test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=r'C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\energy.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=True, mode='auto')\n",
    "#early = EarlyStopping(monitor=\"acc\", mode=\"auto\", patience= 10)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 256)               2304      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 101)               25957     \n",
      "=================================================================\n",
      "Total params: 28,261\n",
      "Trainable params: 28,261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim = 8, activation='relu'))\n",
    "# model.add(Dense(144, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(101, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.compile(loss='categorical_crossentropy', metrics=['acc'],optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GradientBoostingClassifier' object has no attribute 'load_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-6e588b6fec5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'GradientBoostingClassifier' object has no attribute 'load_weights'"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "model.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1429 samples, validate on 477 samples\n",
      "Epoch 1/500\n",
      "1429/1429 [==============================] - 0s 128us/step - loss: 3.2654 - accuracy: 0.2533 - val_loss: 3.4693 - val_accuracy: 0.2327\n",
      "Epoch 2/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 3.1991 - accuracy: 0.2624 - val_loss: 3.4819 - val_accuracy: 0.2201\n",
      "Epoch 3/500\n",
      "  32/1429 [..............................] - ETA: 0s - loss: 2.7852 - accuracy: 0.3438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kanishk\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\callbacks\\callbacks.py:707: RuntimeWarning: Can save best model only with acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 107us/step - loss: 3.1694 - accuracy: 0.2596 - val_loss: 3.5043 - val_accuracy: 0.2222\n",
      "Epoch 4/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 3.1308 - accuracy: 0.2631 - val_loss: 3.5302 - val_accuracy: 0.2117\n",
      "Epoch 5/500\n",
      "1429/1429 [==============================] - 0s 126us/step - loss: 3.1034 - accuracy: 0.2547 - val_loss: 3.5170 - val_accuracy: 0.2075\n",
      "Epoch 6/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 3.0932 - accuracy: 0.2687 - val_loss: 3.5281 - val_accuracy: 0.2034\n",
      "Epoch 7/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 3.0771 - accuracy: 0.2624 - val_loss: 3.5436 - val_accuracy: 0.1950\n",
      "Epoch 8/500\n",
      "1429/1429 [==============================] - 0s 143us/step - loss: 3.0575 - accuracy: 0.2582 - val_loss: 3.5627 - val_accuracy: 0.2055\n",
      "Epoch 9/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 3.0504 - accuracy: 0.2694 - val_loss: 3.5604 - val_accuracy: 0.1971\n",
      "Epoch 10/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 3.0339 - accuracy: 0.2701 - val_loss: 3.5701 - val_accuracy: 0.1887\n",
      "Epoch 11/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 3.0224 - accuracy: 0.2631 - val_loss: 3.5736 - val_accuracy: 0.1845\n",
      "Epoch 12/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 3.0279 - accuracy: 0.2680 - val_loss: 3.5830 - val_accuracy: 0.1803\n",
      "Epoch 13/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 3.0062 - accuracy: 0.2729 - val_loss: 3.5832 - val_accuracy: 0.1866\n",
      "Epoch 14/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 3.0011 - accuracy: 0.2722 - val_loss: 3.5854 - val_accuracy: 0.1887\n",
      "Epoch 15/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.9956 - accuracy: 0.2799 - val_loss: 3.5875 - val_accuracy: 0.1803\n",
      "Epoch 16/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.9898 - accuracy: 0.2792 - val_loss: 3.6077 - val_accuracy: 0.1971\n",
      "Epoch 17/500\n",
      "1429/1429 [==============================] - 0s 120us/step - loss: 2.9800 - accuracy: 0.2736 - val_loss: 3.6315 - val_accuracy: 0.1677\n",
      "Epoch 18/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.9842 - accuracy: 0.2624 - val_loss: 3.6266 - val_accuracy: 0.1887\n",
      "Epoch 19/500\n",
      "1429/1429 [==============================] - 0s 138us/step - loss: 2.9622 - accuracy: 0.2813 - val_loss: 3.6476 - val_accuracy: 0.1698\n",
      "Epoch 20/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.9745 - accuracy: 0.2715 - val_loss: 3.6390 - val_accuracy: 0.1677\n",
      "Epoch 21/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.9726 - accuracy: 0.2722 - val_loss: 3.6401 - val_accuracy: 0.1698\n",
      "Epoch 22/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.9626 - accuracy: 0.2729 - val_loss: 3.6252 - val_accuracy: 0.1782\n",
      "Epoch 23/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.9576 - accuracy: 0.2785 - val_loss: 3.6583 - val_accuracy: 0.1572\n",
      "Epoch 24/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.9514 - accuracy: 0.2771 - val_loss: 3.6505 - val_accuracy: 0.1971\n",
      "Epoch 25/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.9470 - accuracy: 0.2827 - val_loss: 3.6504 - val_accuracy: 0.1803\n",
      "Epoch 26/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.9412 - accuracy: 0.2792 - val_loss: 3.6654 - val_accuracy: 0.1740\n",
      "Epoch 27/500\n",
      "1429/1429 [==============================] - 0s 120us/step - loss: 2.9426 - accuracy: 0.2743 - val_loss: 3.6657 - val_accuracy: 0.1719\n",
      "Epoch 28/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.9354 - accuracy: 0.2778 - val_loss: 3.6546 - val_accuracy: 0.1719\n",
      "Epoch 29/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.9269 - accuracy: 0.2855 - val_loss: 3.6889 - val_accuracy: 0.1593\n",
      "Epoch 30/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.9369 - accuracy: 0.2820 - val_loss: 3.7013 - val_accuracy: 0.1572\n",
      "Epoch 31/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.9273 - accuracy: 0.2806 - val_loss: 3.7143 - val_accuracy: 0.1426\n",
      "Epoch 32/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.9213 - accuracy: 0.2827 - val_loss: 3.6843 - val_accuracy: 0.1719\n",
      "Epoch 33/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.9216 - accuracy: 0.2813 - val_loss: 3.6961 - val_accuracy: 0.1740\n",
      "Epoch 34/500\n",
      "1429/1429 [==============================] - 0s 118us/step - loss: 2.9141 - accuracy: 0.2841 - val_loss: 3.6872 - val_accuracy: 0.1635\n",
      "Epoch 35/500\n",
      "1429/1429 [==============================] - 0s 115us/step - loss: 2.9117 - accuracy: 0.2827 - val_loss: 3.7037 - val_accuracy: 0.1551\n",
      "Epoch 36/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.9106 - accuracy: 0.2883 - val_loss: 3.7115 - val_accuracy: 0.1614\n",
      "Epoch 37/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.9057 - accuracy: 0.2785 - val_loss: 3.7099 - val_accuracy: 0.1677\n",
      "Epoch 38/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.9043 - accuracy: 0.2855 - val_loss: 3.7199 - val_accuracy: 0.1509\n",
      "Epoch 39/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.9039 - accuracy: 0.2862 - val_loss: 3.7492 - val_accuracy: 0.1677\n",
      "Epoch 40/500\n",
      "1429/1429 [==============================] - 0s 128us/step - loss: 2.9028 - accuracy: 0.2939 - val_loss: 3.7125 - val_accuracy: 0.1530\n",
      "Epoch 41/500\n",
      "1429/1429 [==============================] - 0s 154us/step - loss: 2.8980 - accuracy: 0.2890 - val_loss: 3.7226 - val_accuracy: 0.1551\n",
      "Epoch 42/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.8987 - accuracy: 0.2785 - val_loss: 3.7481 - val_accuracy: 0.1405\n",
      "Epoch 43/500\n",
      "1429/1429 [==============================] - 0s 125us/step - loss: 2.8900 - accuracy: 0.2918 - val_loss: 3.7359 - val_accuracy: 0.1468\n",
      "Epoch 44/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.8959 - accuracy: 0.2806 - val_loss: 3.7387 - val_accuracy: 0.1530\n",
      "Epoch 45/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.8978 - accuracy: 0.2820 - val_loss: 3.7621 - val_accuracy: 0.1447\n",
      "Epoch 46/500\n",
      "1429/1429 [==============================] - 0s 140us/step - loss: 2.8952 - accuracy: 0.2960 - val_loss: 3.7482 - val_accuracy: 0.1468\n",
      "Epoch 47/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.8912 - accuracy: 0.2869 - val_loss: 3.7515 - val_accuracy: 0.1509\n",
      "Epoch 48/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.8898 - accuracy: 0.2827 - val_loss: 3.7636 - val_accuracy: 0.1426\n",
      "Epoch 49/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.8849 - accuracy: 0.2925 - val_loss: 3.7884 - val_accuracy: 0.1551\n",
      "Epoch 50/500\n",
      "1429/1429 [==============================] - 0s 118us/step - loss: 2.8830 - accuracy: 0.2876 - val_loss: 3.7714 - val_accuracy: 0.1635\n",
      "Epoch 51/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.8801 - accuracy: 0.2960 - val_loss: 3.7752 - val_accuracy: 0.1488\n",
      "Epoch 52/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.8864 - accuracy: 0.2827 - val_loss: 3.7973 - val_accuracy: 0.1530\n",
      "Epoch 53/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.8751 - accuracy: 0.2918 - val_loss: 3.7818 - val_accuracy: 0.1384\n",
      "Epoch 54/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.8749 - accuracy: 0.2890 - val_loss: 3.7752 - val_accuracy: 0.1447\n",
      "Epoch 55/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.8776 - accuracy: 0.2862 - val_loss: 3.7924 - val_accuracy: 0.1405\n",
      "Epoch 56/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.8701 - accuracy: 0.2932 - val_loss: 3.7891 - val_accuracy: 0.1468\n",
      "Epoch 57/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.8727 - accuracy: 0.2974 - val_loss: 3.7912 - val_accuracy: 0.1488\n",
      "Epoch 58/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.8685 - accuracy: 0.2995 - val_loss: 3.7993 - val_accuracy: 0.1363\n",
      "Epoch 59/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.8667 - accuracy: 0.2953 - val_loss: 3.8094 - val_accuracy: 0.1426\n",
      "Epoch 60/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.8655 - accuracy: 0.2848 - val_loss: 3.7993 - val_accuracy: 0.1572\n",
      "Epoch 61/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.8687 - accuracy: 0.2953 - val_loss: 3.8196 - val_accuracy: 0.1551\n",
      "Epoch 62/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.8716 - accuracy: 0.2890 - val_loss: 3.8154 - val_accuracy: 0.1509\n",
      "Epoch 63/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.8621 - accuracy: 0.2946 - val_loss: 3.8161 - val_accuracy: 0.1447\n",
      "Epoch 64/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.8502 - accuracy: 0.2960 - val_loss: 3.8160 - val_accuracy: 0.1447\n",
      "Epoch 65/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.8548 - accuracy: 0.2925 - val_loss: 3.8171 - val_accuracy: 0.1530\n",
      "Epoch 66/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.8582 - accuracy: 0.2939 - val_loss: 3.8366 - val_accuracy: 0.1447\n",
      "Epoch 67/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.8518 - accuracy: 0.2946 - val_loss: 3.8435 - val_accuracy: 0.1447\n",
      "Epoch 68/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.8516 - accuracy: 0.2911 - val_loss: 3.8487 - val_accuracy: 0.1509\n",
      "Epoch 69/500\n",
      "1429/1429 [==============================] - 0s 125us/step - loss: 2.8438 - accuracy: 0.2960 - val_loss: 3.8408 - val_accuracy: 0.1509\n",
      "Epoch 70/500\n",
      "1429/1429 [==============================] - 0s 124us/step - loss: 2.8624 - accuracy: 0.2918 - val_loss: 3.8658 - val_accuracy: 0.1572\n",
      "Epoch 71/500\n",
      "1429/1429 [==============================] - 0s 133us/step - loss: 2.8502 - accuracy: 0.2939 - val_loss: 3.8471 - val_accuracy: 0.1405\n",
      "Epoch 72/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.8426 - accuracy: 0.2918 - val_loss: 3.8521 - val_accuracy: 0.1405\n",
      "Epoch 73/500\n",
      "1429/1429 [==============================] - 0s 138us/step - loss: 2.8454 - accuracy: 0.2932 - val_loss: 3.8623 - val_accuracy: 0.1509\n",
      "Epoch 74/500\n",
      "1429/1429 [==============================] - 0s 135us/step - loss: 2.8516 - accuracy: 0.3002 - val_loss: 3.8625 - val_accuracy: 0.1426\n",
      "Epoch 75/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.8421 - accuracy: 0.2890 - val_loss: 3.8731 - val_accuracy: 0.1384\n",
      "Epoch 76/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.8379 - accuracy: 0.2925 - val_loss: 3.8790 - val_accuracy: 0.1363\n",
      "Epoch 77/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.8315 - accuracy: 0.2967 - val_loss: 3.8763 - val_accuracy: 0.1468\n",
      "Epoch 78/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.8442 - accuracy: 0.2967 - val_loss: 3.8742 - val_accuracy: 0.1405\n",
      "Epoch 79/500\n",
      "1429/1429 [==============================] - 0s 128us/step - loss: 2.8511 - accuracy: 0.2925 - val_loss: 3.8756 - val_accuracy: 0.1384\n",
      "Epoch 80/500\n",
      "1429/1429 [==============================] - 0s 125us/step - loss: 2.8391 - accuracy: 0.2883 - val_loss: 3.8793 - val_accuracy: 0.1488\n",
      "Epoch 81/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.8311 - accuracy: 0.2988 - val_loss: 3.8834 - val_accuracy: 0.1530\n",
      "Epoch 82/500\n",
      "1429/1429 [==============================] - 0s 121us/step - loss: 2.8317 - accuracy: 0.2876 - val_loss: 3.8733 - val_accuracy: 0.1488\n",
      "Epoch 83/500\n",
      "1429/1429 [==============================] - 0s 118us/step - loss: 2.8352 - accuracy: 0.2876 - val_loss: 3.8916 - val_accuracy: 0.1509\n",
      "Epoch 84/500\n",
      "1429/1429 [==============================] - 0s 125us/step - loss: 2.8293 - accuracy: 0.3086 - val_loss: 3.9015 - val_accuracy: 0.1321\n",
      "Epoch 85/500\n",
      "1429/1429 [==============================] - 0s 125us/step - loss: 2.8283 - accuracy: 0.3058 - val_loss: 3.9323 - val_accuracy: 0.1426\n",
      "Epoch 86/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.8324 - accuracy: 0.2869 - val_loss: 3.8902 - val_accuracy: 0.1447\n",
      "Epoch 87/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.8266 - accuracy: 0.3037 - val_loss: 3.9041 - val_accuracy: 0.1447\n",
      "Epoch 88/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.8266 - accuracy: 0.2995 - val_loss: 3.9179 - val_accuracy: 0.1426\n",
      "Epoch 89/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.8290 - accuracy: 0.2869 - val_loss: 3.9136 - val_accuracy: 0.1321\n",
      "Epoch 90/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.8182 - accuracy: 0.2995 - val_loss: 3.9135 - val_accuracy: 0.1321\n",
      "Epoch 91/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.8189 - accuracy: 0.3051 - val_loss: 3.9310 - val_accuracy: 0.1321\n",
      "Epoch 92/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.8198 - accuracy: 0.2939 - val_loss: 3.9162 - val_accuracy: 0.1363\n",
      "Epoch 93/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.8204 - accuracy: 0.3016 - val_loss: 3.9310 - val_accuracy: 0.1426\n",
      "Epoch 94/500\n",
      "1429/1429 [==============================] - 0s 121us/step - loss: 2.8213 - accuracy: 0.2932 - val_loss: 3.9350 - val_accuracy: 0.1237\n",
      "Epoch 95/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.8200 - accuracy: 0.3023 - val_loss: 3.9476 - val_accuracy: 0.1363\n",
      "Epoch 96/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.8206 - accuracy: 0.3009 - val_loss: 3.9423 - val_accuracy: 0.1258\n",
      "Epoch 97/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.8117 - accuracy: 0.2946 - val_loss: 3.9479 - val_accuracy: 0.1321\n",
      "Epoch 98/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.8112 - accuracy: 0.3009 - val_loss: 3.9424 - val_accuracy: 0.1300\n",
      "Epoch 99/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.8097 - accuracy: 0.2974 - val_loss: 3.9442 - val_accuracy: 0.1342\n",
      "Epoch 100/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.8108 - accuracy: 0.3051 - val_loss: 3.9403 - val_accuracy: 0.1426\n",
      "Epoch 101/500\n",
      "1429/1429 [==============================] - 0s 130us/step - loss: 2.8153 - accuracy: 0.3016 - val_loss: 3.9471 - val_accuracy: 0.1279\n",
      "Epoch 102/500\n",
      "1429/1429 [==============================] - 0s 126us/step - loss: 2.8208 - accuracy: 0.2995 - val_loss: 3.9531 - val_accuracy: 0.1258\n",
      "Epoch 103/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.8093 - accuracy: 0.2981 - val_loss: 3.9691 - val_accuracy: 0.1405\n",
      "Epoch 104/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.8045 - accuracy: 0.3093 - val_loss: 3.9632 - val_accuracy: 0.1342\n",
      "Epoch 105/500\n",
      "1429/1429 [==============================] - 0s 163us/step - loss: 2.8055 - accuracy: 0.2974 - val_loss: 3.9697 - val_accuracy: 0.1342\n",
      "Epoch 106/500\n",
      "1429/1429 [==============================] - 0s 124us/step - loss: 2.8074 - accuracy: 0.2988 - val_loss: 3.9787 - val_accuracy: 0.1300\n",
      "Epoch 107/500\n",
      "1429/1429 [==============================] - 0s 120us/step - loss: 2.8043 - accuracy: 0.3100 - val_loss: 3.9705 - val_accuracy: 0.1426\n",
      "Epoch 108/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.8004 - accuracy: 0.3107 - val_loss: 3.9759 - val_accuracy: 0.1279\n",
      "Epoch 109/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.8048 - accuracy: 0.3051 - val_loss: 4.0019 - val_accuracy: 0.1237\n",
      "Epoch 110/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.8031 - accuracy: 0.3023 - val_loss: 3.9918 - val_accuracy: 0.1300\n",
      "Epoch 111/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.7983 - accuracy: 0.3002 - val_loss: 3.9845 - val_accuracy: 0.1342\n",
      "Epoch 112/500\n",
      "1429/1429 [==============================] - 0s 121us/step - loss: 2.7997 - accuracy: 0.3023 - val_loss: 3.9971 - val_accuracy: 0.1342\n",
      "Epoch 113/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.7967 - accuracy: 0.2925 - val_loss: 4.0008 - val_accuracy: 0.1384\n",
      "Epoch 114/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.8025 - accuracy: 0.3009 - val_loss: 3.9912 - val_accuracy: 0.1342\n",
      "Epoch 115/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.8067 - accuracy: 0.3002 - val_loss: 4.0044 - val_accuracy: 0.1258\n",
      "Epoch 116/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.7973 - accuracy: 0.3086 - val_loss: 4.0117 - val_accuracy: 0.1321\n",
      "Epoch 117/500\n",
      "1429/1429 [==============================] - 0s 124us/step - loss: 2.7931 - accuracy: 0.3107 - val_loss: 4.0135 - val_accuracy: 0.1300\n",
      "Epoch 118/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.7996 - accuracy: 0.3023 - val_loss: 4.0310 - val_accuracy: 0.1132\n",
      "Epoch 119/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.7925 - accuracy: 0.2939 - val_loss: 4.0179 - val_accuracy: 0.1258\n",
      "Epoch 120/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.7901 - accuracy: 0.3037 - val_loss: 4.0129 - val_accuracy: 0.1321\n",
      "Epoch 121/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.7911 - accuracy: 0.3065 - val_loss: 4.0191 - val_accuracy: 0.1321\n",
      "Epoch 122/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.7890 - accuracy: 0.3149 - val_loss: 4.0434 - val_accuracy: 0.1237\n",
      "Epoch 123/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.7947 - accuracy: 0.2988 - val_loss: 4.0442 - val_accuracy: 0.1363\n",
      "Epoch 124/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.7913 - accuracy: 0.2939 - val_loss: 4.0381 - val_accuracy: 0.1279\n",
      "Epoch 125/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.7891 - accuracy: 0.3093 - val_loss: 4.0456 - val_accuracy: 0.1195\n",
      "Epoch 126/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7879 - accuracy: 0.3037 - val_loss: 4.0461 - val_accuracy: 0.1363\n",
      "Epoch 127/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.7988 - accuracy: 0.2995 - val_loss: 4.0343 - val_accuracy: 0.1321\n",
      "Epoch 128/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.7895 - accuracy: 0.3023 - val_loss: 4.0416 - val_accuracy: 0.1279\n",
      "Epoch 129/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.7883 - accuracy: 0.3100 - val_loss: 4.0442 - val_accuracy: 0.1258\n",
      "Epoch 130/500\n",
      "1429/1429 [==============================] - 0s 124us/step - loss: 2.7918 - accuracy: 0.3079 - val_loss: 4.0551 - val_accuracy: 0.1321\n",
      "Epoch 131/500\n",
      "1429/1429 [==============================] - 0s 125us/step - loss: 2.7878 - accuracy: 0.3009 - val_loss: 4.0562 - val_accuracy: 0.1279\n",
      "Epoch 132/500\n",
      "1429/1429 [==============================] - 0s 118us/step - loss: 2.7911 - accuracy: 0.3037 - val_loss: 4.0901 - val_accuracy: 0.1384\n",
      "Epoch 133/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.7892 - accuracy: 0.3093 - val_loss: 4.0745 - val_accuracy: 0.1258\n",
      "Epoch 134/500\n",
      "1429/1429 [==============================] - 0s 125us/step - loss: 2.7877 - accuracy: 0.3016 - val_loss: 4.0637 - val_accuracy: 0.1216\n",
      "Epoch 135/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.7807 - accuracy: 0.3044 - val_loss: 4.0765 - val_accuracy: 0.1468\n",
      "Epoch 136/500\n",
      "1429/1429 [==============================] - 0s 136us/step - loss: 2.7749 - accuracy: 0.3093 - val_loss: 4.0693 - val_accuracy: 0.1321\n",
      "Epoch 137/500\n",
      "1429/1429 [==============================] - 0s 135us/step - loss: 2.7830 - accuracy: 0.3016 - val_loss: 4.0807 - val_accuracy: 0.1342\n",
      "Epoch 138/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.7818 - accuracy: 0.3177 - val_loss: 4.0968 - val_accuracy: 0.1216\n",
      "Epoch 139/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.7812 - accuracy: 0.3051 - val_loss: 4.0896 - val_accuracy: 0.1195\n",
      "Epoch 140/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7754 - accuracy: 0.3037 - val_loss: 4.0879 - val_accuracy: 0.1195\n",
      "Epoch 141/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.7741 - accuracy: 0.3058 - val_loss: 4.0768 - val_accuracy: 0.1300\n",
      "Epoch 142/500\n",
      "1429/1429 [==============================] - 0s 128us/step - loss: 2.7737 - accuracy: 0.3044 - val_loss: 4.1021 - val_accuracy: 0.1237\n",
      "Epoch 143/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7720 - accuracy: 0.3114 - val_loss: 4.0995 - val_accuracy: 0.1279\n",
      "Epoch 144/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.7753 - accuracy: 0.2953 - val_loss: 4.1168 - val_accuracy: 0.1237\n",
      "Epoch 145/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7773 - accuracy: 0.3072 - val_loss: 4.1033 - val_accuracy: 0.1258\n",
      "Epoch 146/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7731 - accuracy: 0.3030 - val_loss: 4.1112 - val_accuracy: 0.1426\n",
      "Epoch 147/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.7749 - accuracy: 0.3009 - val_loss: 4.0987 - val_accuracy: 0.1447\n",
      "Epoch 148/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.7722 - accuracy: 0.3016 - val_loss: 4.1119 - val_accuracy: 0.1258\n",
      "Epoch 149/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.7654 - accuracy: 0.3128 - val_loss: 4.1181 - val_accuracy: 0.1321\n",
      "Epoch 150/500\n",
      "1429/1429 [==============================] - 0s 123us/step - loss: 2.7676 - accuracy: 0.3086 - val_loss: 4.1124 - val_accuracy: 0.1384\n",
      "Epoch 151/500\n",
      "1429/1429 [==============================] - 0s 122us/step - loss: 2.7655 - accuracy: 0.3065 - val_loss: 4.1434 - val_accuracy: 0.1216\n",
      "Epoch 152/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.7685 - accuracy: 0.3086 - val_loss: 4.1239 - val_accuracy: 0.1321\n",
      "Epoch 153/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.7685 - accuracy: 0.3072 - val_loss: 4.1196 - val_accuracy: 0.1342\n",
      "Epoch 154/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.7650 - accuracy: 0.3044 - val_loss: 4.1343 - val_accuracy: 0.1279\n",
      "Epoch 155/500\n",
      "1429/1429 [==============================] - 0s 131us/step - loss: 2.7661 - accuracy: 0.3114 - val_loss: 4.1455 - val_accuracy: 0.1321\n",
      "Epoch 156/500\n",
      "1429/1429 [==============================] - 0s 126us/step - loss: 2.7658 - accuracy: 0.2960 - val_loss: 4.1455 - val_accuracy: 0.1321\n",
      "Epoch 157/500\n",
      "1429/1429 [==============================] - 0s 135us/step - loss: 2.7691 - accuracy: 0.2974 - val_loss: 4.1515 - val_accuracy: 0.1279\n",
      "Epoch 158/500\n",
      "1429/1429 [==============================] - 0s 122us/step - loss: 2.7707 - accuracy: 0.3072 - val_loss: 4.1415 - val_accuracy: 0.1405\n",
      "Epoch 159/500\n",
      "1429/1429 [==============================] - 0s 121us/step - loss: 2.7670 - accuracy: 0.3009 - val_loss: 4.1556 - val_accuracy: 0.1237\n",
      "Epoch 160/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.7643 - accuracy: 0.3114 - val_loss: 4.1380 - val_accuracy: 0.1216\n",
      "Epoch 161/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.7569 - accuracy: 0.3114 - val_loss: 4.1583 - val_accuracy: 0.1363\n",
      "Epoch 162/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.7653 - accuracy: 0.3072 - val_loss: 4.1590 - val_accuracy: 0.1300\n",
      "Epoch 163/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.7611 - accuracy: 0.3030 - val_loss: 4.1625 - val_accuracy: 0.1195\n",
      "Epoch 164/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.7609 - accuracy: 0.3037 - val_loss: 4.1626 - val_accuracy: 0.1342\n",
      "Epoch 165/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.7608 - accuracy: 0.3037 - val_loss: 4.1788 - val_accuracy: 0.1216\n",
      "Epoch 166/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.7600 - accuracy: 0.3100 - val_loss: 4.1713 - val_accuracy: 0.1258\n",
      "Epoch 167/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.7607 - accuracy: 0.3121 - val_loss: 4.1815 - val_accuracy: 0.1216\n",
      "Epoch 168/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.7595 - accuracy: 0.3072 - val_loss: 4.2077 - val_accuracy: 0.1132\n",
      "Epoch 169/500\n",
      "1429/1429 [==============================] - 0s 131us/step - loss: 2.7551 - accuracy: 0.3107 - val_loss: 4.1839 - val_accuracy: 0.1405\n",
      "Epoch 170/500\n",
      "1429/1429 [==============================] - 0s 127us/step - loss: 2.7547 - accuracy: 0.3100 - val_loss: 4.1948 - val_accuracy: 0.1237\n",
      "Epoch 171/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.7521 - accuracy: 0.3163 - val_loss: 4.1917 - val_accuracy: 0.1321\n",
      "Epoch 172/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.7505 - accuracy: 0.3072 - val_loss: 4.1879 - val_accuracy: 0.1258\n",
      "Epoch 173/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.7513 - accuracy: 0.3051 - val_loss: 4.2077 - val_accuracy: 0.1363\n",
      "Epoch 174/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.7561 - accuracy: 0.3079 - val_loss: 4.1969 - val_accuracy: 0.1153\n",
      "Epoch 175/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.7934 - accuracy: 0.3107 - val_loss: 4.2095 - val_accuracy: 0.1342\n",
      "Epoch 176/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.7477 - accuracy: 0.3065 - val_loss: 4.2099 - val_accuracy: 0.1132\n",
      "Epoch 177/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.7497 - accuracy: 0.2988 - val_loss: 4.2124 - val_accuracy: 0.1216\n",
      "Epoch 178/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.7508 - accuracy: 0.3051 - val_loss: 4.2082 - val_accuracy: 0.1279\n",
      "Epoch 179/500\n",
      "1429/1429 [==============================] - 0s 120us/step - loss: 2.7544 - accuracy: 0.3114 - val_loss: 4.2093 - val_accuracy: 0.1258\n",
      "Epoch 180/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.7506 - accuracy: 0.3002 - val_loss: 4.2303 - val_accuracy: 0.1132\n",
      "Epoch 181/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.7480 - accuracy: 0.3128 - val_loss: 4.2355 - val_accuracy: 0.1258\n",
      "Epoch 182/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.7450 - accuracy: 0.3072 - val_loss: 4.2200 - val_accuracy: 0.1342\n",
      "Epoch 183/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.7456 - accuracy: 0.3128 - val_loss: 4.2416 - val_accuracy: 0.1321\n",
      "Epoch 184/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.7479 - accuracy: 0.3086 - val_loss: 4.2462 - val_accuracy: 0.1300\n",
      "Epoch 185/500\n",
      "1429/1429 [==============================] - 0s 140us/step - loss: 2.7453 - accuracy: 0.3142 - val_loss: 4.2461 - val_accuracy: 0.1216\n",
      "Epoch 186/500\n",
      "1429/1429 [==============================] - 0s 120us/step - loss: 2.7466 - accuracy: 0.3191 - val_loss: 4.2426 - val_accuracy: 0.1279\n",
      "Epoch 187/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.7414 - accuracy: 0.3114 - val_loss: 4.2474 - val_accuracy: 0.1258\n",
      "Epoch 188/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.7419 - accuracy: 0.3079 - val_loss: 4.2611 - val_accuracy: 0.1069\n",
      "Epoch 189/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.7464 - accuracy: 0.3128 - val_loss: 4.2915 - val_accuracy: 0.1195\n",
      "Epoch 190/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.7409 - accuracy: 0.3128 - val_loss: 4.2822 - val_accuracy: 0.1111\n",
      "Epoch 191/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.7396 - accuracy: 0.3107 - val_loss: 4.2590 - val_accuracy: 0.1279\n",
      "Epoch 192/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.7441 - accuracy: 0.3065 - val_loss: 4.2583 - val_accuracy: 0.1279\n",
      "Epoch 193/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.7581 - accuracy: 0.3023 - val_loss: 4.2730 - val_accuracy: 0.1132\n",
      "Epoch 194/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.7409 - accuracy: 0.3114 - val_loss: 4.2853 - val_accuracy: 0.1069\n",
      "Epoch 195/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.7456 - accuracy: 0.3086 - val_loss: 4.2760 - val_accuracy: 0.1300\n",
      "Epoch 196/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.7509 - accuracy: 0.3142 - val_loss: 4.2944 - val_accuracy: 0.1237\n",
      "Epoch 197/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.7462 - accuracy: 0.3135 - val_loss: 4.2858 - val_accuracy: 0.1279\n",
      "Epoch 198/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.7343 - accuracy: 0.3198 - val_loss: 4.3115 - val_accuracy: 0.1174\n",
      "Epoch 199/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.7379 - accuracy: 0.3065 - val_loss: 4.3027 - val_accuracy: 0.1258\n",
      "Epoch 200/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.7353 - accuracy: 0.3163 - val_loss: 4.2874 - val_accuracy: 0.1237\n",
      "Epoch 201/500\n",
      "1429/1429 [==============================] - 0s 139us/step - loss: 2.7366 - accuracy: 0.3121 - val_loss: 4.3033 - val_accuracy: 0.1216\n",
      "Epoch 202/500\n",
      "1429/1429 [==============================] - 0s 123us/step - loss: 2.7349 - accuracy: 0.3128 - val_loss: 4.3002 - val_accuracy: 0.1195\n",
      "Epoch 203/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.7361 - accuracy: 0.3044 - val_loss: 4.3052 - val_accuracy: 0.1321\n",
      "Epoch 204/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.7355 - accuracy: 0.3093 - val_loss: 4.3390 - val_accuracy: 0.1279\n",
      "Epoch 205/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.7420 - accuracy: 0.3135 - val_loss: 4.3081 - val_accuracy: 0.1195\n",
      "Epoch 206/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.7360 - accuracy: 0.3177 - val_loss: 4.3286 - val_accuracy: 0.1132\n",
      "Epoch 207/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.7345 - accuracy: 0.3163 - val_loss: 4.3342 - val_accuracy: 0.1111\n",
      "Epoch 208/500\n",
      "1429/1429 [==============================] - 0s 123us/step - loss: 2.7355 - accuracy: 0.3128 - val_loss: 4.3196 - val_accuracy: 0.1111\n",
      "Epoch 209/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.7354 - accuracy: 0.3135 - val_loss: 4.3489 - val_accuracy: 0.1048\n",
      "Epoch 210/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.7357 - accuracy: 0.3191 - val_loss: 4.3413 - val_accuracy: 0.1090\n",
      "Epoch 211/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.7251 - accuracy: 0.3184 - val_loss: 4.3399 - val_accuracy: 0.1216\n",
      "Epoch 212/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.7326 - accuracy: 0.3086 - val_loss: 4.3588 - val_accuracy: 0.1237\n",
      "Epoch 213/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.7306 - accuracy: 0.3177 - val_loss: 4.3357 - val_accuracy: 0.1195\n",
      "Epoch 214/500\n",
      "1429/1429 [==============================] - 0s 118us/step - loss: 2.7321 - accuracy: 0.3163 - val_loss: 4.3483 - val_accuracy: 0.1216\n",
      "Epoch 215/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.7261 - accuracy: 0.3114 - val_loss: 4.3518 - val_accuracy: 0.1111\n",
      "Epoch 216/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.7280 - accuracy: 0.3212 - val_loss: 4.3682 - val_accuracy: 0.1069\n",
      "Epoch 217/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.7304 - accuracy: 0.3177 - val_loss: 4.3761 - val_accuracy: 0.1153\n",
      "Epoch 218/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.7258 - accuracy: 0.3170 - val_loss: 4.3702 - val_accuracy: 0.1342\n",
      "Epoch 219/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.7233 - accuracy: 0.3198 - val_loss: 4.3819 - val_accuracy: 0.1090\n",
      "Epoch 220/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.7338 - accuracy: 0.3198 - val_loss: 4.3690 - val_accuracy: 0.1195\n",
      "Epoch 221/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.7409 - accuracy: 0.3051 - val_loss: 4.3870 - val_accuracy: 0.1279\n",
      "Epoch 222/500\n",
      "1429/1429 [==============================] - 0s 121us/step - loss: 2.7276 - accuracy: 0.3114 - val_loss: 4.4067 - val_accuracy: 0.1237\n",
      "Epoch 223/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.7304 - accuracy: 0.3212 - val_loss: 4.3842 - val_accuracy: 0.1216\n",
      "Epoch 224/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.7256 - accuracy: 0.3212 - val_loss: 4.4002 - val_accuracy: 0.1195\n",
      "Epoch 225/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.7288 - accuracy: 0.3198 - val_loss: 4.4026 - val_accuracy: 0.1258\n",
      "Epoch 226/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.7257 - accuracy: 0.3142 - val_loss: 4.4162 - val_accuracy: 0.1069\n",
      "Epoch 227/500\n",
      "1429/1429 [==============================] - 0s 118us/step - loss: 2.7254 - accuracy: 0.3149 - val_loss: 4.3877 - val_accuracy: 0.1279\n",
      "Epoch 228/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.7253 - accuracy: 0.3107 - val_loss: 4.3955 - val_accuracy: 0.1195\n",
      "Epoch 229/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.7189 - accuracy: 0.3086 - val_loss: 4.4278 - val_accuracy: 0.1153\n",
      "Epoch 230/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.7205 - accuracy: 0.3100 - val_loss: 4.4153 - val_accuracy: 0.1237\n",
      "Epoch 231/500\n",
      "1429/1429 [==============================] - 0s 115us/step - loss: 2.7223 - accuracy: 0.3198 - val_loss: 4.4272 - val_accuracy: 0.1153\n",
      "Epoch 232/500\n",
      "1429/1429 [==============================] - 0s 123us/step - loss: 2.7157 - accuracy: 0.3170 - val_loss: 4.4161 - val_accuracy: 0.1132\n",
      "Epoch 233/500\n",
      "1429/1429 [==============================] - 0s 151us/step - loss: 2.7236 - accuracy: 0.3156 - val_loss: 4.4314 - val_accuracy: 0.1363\n",
      "Epoch 234/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.7269 - accuracy: 0.3135 - val_loss: 4.4301 - val_accuracy: 0.1258\n",
      "Epoch 235/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.7365 - accuracy: 0.3184 - val_loss: 4.4365 - val_accuracy: 0.1132\n",
      "Epoch 236/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.7216 - accuracy: 0.3198 - val_loss: 4.4423 - val_accuracy: 0.1258\n",
      "Epoch 237/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.7270 - accuracy: 0.3149 - val_loss: 4.4388 - val_accuracy: 0.1132\n",
      "Epoch 238/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.7288 - accuracy: 0.3135 - val_loss: 4.4392 - val_accuracy: 0.1258\n",
      "Epoch 239/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.7248 - accuracy: 0.3128 - val_loss: 4.4474 - val_accuracy: 0.1258\n",
      "Epoch 240/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.7261 - accuracy: 0.3219 - val_loss: 4.4533 - val_accuracy: 0.1258\n",
      "Epoch 241/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.7200 - accuracy: 0.3149 - val_loss: 4.4569 - val_accuracy: 0.1153\n",
      "Epoch 242/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.7118 - accuracy: 0.3198 - val_loss: 4.4663 - val_accuracy: 0.1237\n",
      "Epoch 243/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.7202 - accuracy: 0.3163 - val_loss: 4.4629 - val_accuracy: 0.1216\n",
      "Epoch 244/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.7125 - accuracy: 0.3261 - val_loss: 4.4614 - val_accuracy: 0.1111\n",
      "Epoch 245/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.7189 - accuracy: 0.3142 - val_loss: 4.4846 - val_accuracy: 0.1048\n",
      "Epoch 246/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.7167 - accuracy: 0.3114 - val_loss: 4.4647 - val_accuracy: 0.1132\n",
      "Epoch 247/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.7123 - accuracy: 0.3205 - val_loss: 4.4747 - val_accuracy: 0.1216\n",
      "Epoch 248/500\n",
      "1429/1429 [==============================] - 0s 120us/step - loss: 2.7106 - accuracy: 0.3247 - val_loss: 4.4864 - val_accuracy: 0.1090\n",
      "Epoch 249/500\n",
      "1429/1429 [==============================] - 0s 115us/step - loss: 2.7156 - accuracy: 0.3233 - val_loss: 4.4850 - val_accuracy: 0.1174\n",
      "Epoch 250/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.7099 - accuracy: 0.3233 - val_loss: 4.5018 - val_accuracy: 0.1153\n",
      "Epoch 251/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.7106 - accuracy: 0.3233 - val_loss: 4.5053 - val_accuracy: 0.1258\n",
      "Epoch 252/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.7094 - accuracy: 0.3331 - val_loss: 4.5155 - val_accuracy: 0.1237\n",
      "Epoch 253/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.7148 - accuracy: 0.3177 - val_loss: 4.5068 - val_accuracy: 0.1237\n",
      "Epoch 254/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.7052 - accuracy: 0.3254 - val_loss: 4.5071 - val_accuracy: 0.1174\n",
      "Epoch 255/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.7112 - accuracy: 0.3177 - val_loss: 4.5216 - val_accuracy: 0.1321\n",
      "Epoch 256/500\n",
      "1429/1429 [==============================] - 0s 123us/step - loss: 2.7085 - accuracy: 0.3128 - val_loss: 4.5137 - val_accuracy: 0.1132\n",
      "Epoch 257/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.7067 - accuracy: 0.3240 - val_loss: 4.5238 - val_accuracy: 0.1111\n",
      "Epoch 258/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.7068 - accuracy: 0.3184 - val_loss: 4.5160 - val_accuracy: 0.1153\n",
      "Epoch 259/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.7057 - accuracy: 0.3226 - val_loss: 4.5251 - val_accuracy: 0.1237\n",
      "Epoch 260/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.7087 - accuracy: 0.3261 - val_loss: 4.5291 - val_accuracy: 0.1132\n",
      "Epoch 261/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.7087 - accuracy: 0.3240 - val_loss: 4.5450 - val_accuracy: 0.1090\n",
      "Epoch 262/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.7077 - accuracy: 0.3177 - val_loss: 4.5265 - val_accuracy: 0.1132\n",
      "Epoch 263/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.7019 - accuracy: 0.3205 - val_loss: 4.5523 - val_accuracy: 0.1090\n",
      "Epoch 264/500\n",
      "1429/1429 [==============================] - 0s 131us/step - loss: 2.7055 - accuracy: 0.3247 - val_loss: 4.5534 - val_accuracy: 0.1090\n",
      "Epoch 265/500\n",
      "1429/1429 [==============================] - 0s 148us/step - loss: 2.7021 - accuracy: 0.3212 - val_loss: 4.5614 - val_accuracy: 0.1132\n",
      "Epoch 266/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7052 - accuracy: 0.3177 - val_loss: 4.5666 - val_accuracy: 0.1090\n",
      "Epoch 267/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.7072 - accuracy: 0.3107 - val_loss: 4.5632 - val_accuracy: 0.1132\n",
      "Epoch 268/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.7065 - accuracy: 0.3142 - val_loss: 4.5740 - val_accuracy: 0.1153\n",
      "Epoch 269/500\n",
      "1429/1429 [==============================] - 0s 128us/step - loss: 2.7032 - accuracy: 0.3163 - val_loss: 4.5634 - val_accuracy: 0.1237\n",
      "Epoch 270/500\n",
      "1429/1429 [==============================] - 0s 118us/step - loss: 2.7025 - accuracy: 0.3156 - val_loss: 4.5791 - val_accuracy: 0.1342\n",
      "Epoch 271/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.7055 - accuracy: 0.3149 - val_loss: 4.5815 - val_accuracy: 0.1111\n",
      "Epoch 272/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.7061 - accuracy: 0.3107 - val_loss: 4.5764 - val_accuracy: 0.1090\n",
      "Epoch 273/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.6997 - accuracy: 0.3212 - val_loss: 4.5858 - val_accuracy: 0.1237\n",
      "Epoch 274/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.6962 - accuracy: 0.3317 - val_loss: 4.5951 - val_accuracy: 0.1111\n",
      "Epoch 275/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.6977 - accuracy: 0.3177 - val_loss: 4.5842 - val_accuracy: 0.1258\n",
      "Epoch 276/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.7042 - accuracy: 0.3198 - val_loss: 4.6003 - val_accuracy: 0.1237\n",
      "Epoch 277/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.7053 - accuracy: 0.3247 - val_loss: 4.5884 - val_accuracy: 0.1153\n",
      "Epoch 278/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.7013 - accuracy: 0.3282 - val_loss: 4.6022 - val_accuracy: 0.1300\n",
      "Epoch 279/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.7097 - accuracy: 0.3233 - val_loss: 4.6291 - val_accuracy: 0.1153\n",
      "Epoch 280/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.7298 - accuracy: 0.3163 - val_loss: 4.6186 - val_accuracy: 0.1216\n",
      "Epoch 281/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.6971 - accuracy: 0.3247 - val_loss: 4.6276 - val_accuracy: 0.1048\n",
      "Epoch 282/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.7100 - accuracy: 0.3163 - val_loss: 4.6091 - val_accuracy: 0.1153\n",
      "Epoch 283/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.7258 - accuracy: 0.3205 - val_loss: 4.6021 - val_accuracy: 0.1195\n",
      "Epoch 284/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.7133 - accuracy: 0.3226 - val_loss: 4.6297 - val_accuracy: 0.1132\n",
      "Epoch 285/500\n",
      "1429/1429 [==============================] - 0s 121us/step - loss: 2.7002 - accuracy: 0.3212 - val_loss: 4.6397 - val_accuracy: 0.1258\n",
      "Epoch 286/500\n",
      "1429/1429 [==============================] - 0s 124us/step - loss: 2.7027 - accuracy: 0.3184 - val_loss: 4.6607 - val_accuracy: 0.1279\n",
      "Epoch 287/500\n",
      "1429/1429 [==============================] - 0s 139us/step - loss: 2.7084 - accuracy: 0.3191 - val_loss: 4.6547 - val_accuracy: 0.1069\n",
      "Epoch 288/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.7026 - accuracy: 0.3226 - val_loss: 4.6323 - val_accuracy: 0.1216\n",
      "Epoch 289/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6942 - accuracy: 0.3198 - val_loss: 4.6594 - val_accuracy: 0.1216\n",
      "Epoch 290/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6928 - accuracy: 0.3254 - val_loss: 4.6455 - val_accuracy: 0.1153\n",
      "Epoch 291/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6958 - accuracy: 0.3254 - val_loss: 4.6536 - val_accuracy: 0.1237\n",
      "Epoch 292/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6931 - accuracy: 0.3261 - val_loss: 4.6592 - val_accuracy: 0.1111\n",
      "Epoch 293/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.6917 - accuracy: 0.3254 - val_loss: 4.6762 - val_accuracy: 0.1111\n",
      "Epoch 294/500\n",
      "1429/1429 [==============================] - 0s 115us/step - loss: 2.6998 - accuracy: 0.3198 - val_loss: 4.6980 - val_accuracy: 0.1363\n",
      "Epoch 295/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.6954 - accuracy: 0.3233 - val_loss: 4.6848 - val_accuracy: 0.1132\n",
      "Epoch 296/500\n",
      "1429/1429 [==============================] - 0s 150us/step - loss: 2.6963 - accuracy: 0.3212 - val_loss: 4.6857 - val_accuracy: 0.1153\n",
      "Epoch 297/500\n",
      "1429/1429 [==============================] - 0s 128us/step - loss: 2.6909 - accuracy: 0.3233 - val_loss: 4.6927 - val_accuracy: 0.1069\n",
      "Epoch 298/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.6895 - accuracy: 0.3184 - val_loss: 4.6803 - val_accuracy: 0.1132\n",
      "Epoch 299/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.6948 - accuracy: 0.3261 - val_loss: 4.6941 - val_accuracy: 0.1132\n",
      "Epoch 300/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.6926 - accuracy: 0.3219 - val_loss: 4.6934 - val_accuracy: 0.1111\n",
      "Epoch 301/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.6980 - accuracy: 0.3240 - val_loss: 4.6995 - val_accuracy: 0.1237\n",
      "Epoch 302/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.6910 - accuracy: 0.3296 - val_loss: 4.7105 - val_accuracy: 0.1153\n",
      "Epoch 303/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.6847 - accuracy: 0.3261 - val_loss: 4.7031 - val_accuracy: 0.1321\n",
      "Epoch 304/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.6913 - accuracy: 0.3331 - val_loss: 4.6988 - val_accuracy: 0.1216\n",
      "Epoch 305/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.6840 - accuracy: 0.3268 - val_loss: 4.7067 - val_accuracy: 0.1132\n",
      "Epoch 306/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.6860 - accuracy: 0.3163 - val_loss: 4.7178 - val_accuracy: 0.1027\n",
      "Epoch 307/500\n",
      "1429/1429 [==============================] - 0s 115us/step - loss: 2.6845 - accuracy: 0.3184 - val_loss: 4.7111 - val_accuracy: 0.1174\n",
      "Epoch 308/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.6839 - accuracy: 0.3268 - val_loss: 4.7167 - val_accuracy: 0.1195\n",
      "Epoch 309/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.6816 - accuracy: 0.3261 - val_loss: 4.7363 - val_accuracy: 0.1174\n",
      "Epoch 310/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.6814 - accuracy: 0.3233 - val_loss: 4.7451 - val_accuracy: 0.1174\n",
      "Epoch 311/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.6863 - accuracy: 0.3324 - val_loss: 4.7433 - val_accuracy: 0.1174\n",
      "Epoch 312/500\n",
      "1429/1429 [==============================] - 0s 127us/step - loss: 2.6877 - accuracy: 0.3177 - val_loss: 4.7527 - val_accuracy: 0.1300\n",
      "Epoch 313/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.6869 - accuracy: 0.3198 - val_loss: 4.7494 - val_accuracy: 0.1153\n",
      "Epoch 314/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.6859 - accuracy: 0.3296 - val_loss: 4.7414 - val_accuracy: 0.1111\n",
      "Epoch 315/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.6848 - accuracy: 0.3254 - val_loss: 4.7461 - val_accuracy: 0.1174\n",
      "Epoch 316/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.6847 - accuracy: 0.3338 - val_loss: 4.7520 - val_accuracy: 0.1132\n",
      "Epoch 317/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.6804 - accuracy: 0.3163 - val_loss: 4.7651 - val_accuracy: 0.1216\n",
      "Epoch 318/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.6911 - accuracy: 0.3261 - val_loss: 4.7621 - val_accuracy: 0.1174\n",
      "Epoch 319/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.6845 - accuracy: 0.3233 - val_loss: 4.7677 - val_accuracy: 0.1195\n",
      "Epoch 320/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.6828 - accuracy: 0.3240 - val_loss: 4.7702 - val_accuracy: 0.1111\n",
      "Epoch 321/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.6779 - accuracy: 0.3282 - val_loss: 4.7836 - val_accuracy: 0.1090\n",
      "Epoch 322/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.6798 - accuracy: 0.3240 - val_loss: 4.7983 - val_accuracy: 0.1111\n",
      "Epoch 323/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.6858 - accuracy: 0.3191 - val_loss: 4.7954 - val_accuracy: 0.1132\n",
      "Epoch 324/500\n",
      "1429/1429 [==============================] - 0s 130us/step - loss: 2.6806 - accuracy: 0.3226 - val_loss: 4.8016 - val_accuracy: 0.1153\n",
      "Epoch 325/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.6764 - accuracy: 0.3275 - val_loss: 4.8178 - val_accuracy: 0.1048\n",
      "Epoch 326/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.6753 - accuracy: 0.3212 - val_loss: 4.8053 - val_accuracy: 0.1153\n",
      "Epoch 327/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6813 - accuracy: 0.3268 - val_loss: 4.7947 - val_accuracy: 0.1111\n",
      "Epoch 328/500\n",
      "1429/1429 [==============================] - 0s 146us/step - loss: 2.6838 - accuracy: 0.3191 - val_loss: 4.8095 - val_accuracy: 0.1153\n",
      "Epoch 329/500\n",
      "1429/1429 [==============================] - 0s 125us/step - loss: 2.6752 - accuracy: 0.3317 - val_loss: 4.8019 - val_accuracy: 0.1174\n",
      "Epoch 330/500\n",
      "1429/1429 [==============================] - 0s 131us/step - loss: 2.6737 - accuracy: 0.3247 - val_loss: 4.8134 - val_accuracy: 0.1216\n",
      "Epoch 331/500\n",
      "1429/1429 [==============================] - 0s 133us/step - loss: 2.6782 - accuracy: 0.3233 - val_loss: 4.8185 - val_accuracy: 0.1216\n",
      "Epoch 332/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.6802 - accuracy: 0.3233 - val_loss: 4.8178 - val_accuracy: 0.1111\n",
      "Epoch 333/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.6733 - accuracy: 0.3268 - val_loss: 4.8278 - val_accuracy: 0.1153\n",
      "Epoch 334/500\n",
      "1429/1429 [==============================] - 0s 123us/step - loss: 2.6787 - accuracy: 0.3184 - val_loss: 4.8426 - val_accuracy: 0.1132\n",
      "Epoch 335/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6707 - accuracy: 0.3254 - val_loss: 4.8430 - val_accuracy: 0.1174\n",
      "Epoch 336/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6735 - accuracy: 0.3282 - val_loss: 4.8352 - val_accuracy: 0.1090\n",
      "Epoch 337/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6760 - accuracy: 0.3268 - val_loss: 4.8395 - val_accuracy: 0.1111\n",
      "Epoch 338/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6707 - accuracy: 0.3289 - val_loss: 4.8336 - val_accuracy: 0.1111\n",
      "Epoch 339/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6772 - accuracy: 0.3219 - val_loss: 4.8454 - val_accuracy: 0.1195\n",
      "Epoch 340/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6738 - accuracy: 0.3275 - val_loss: 4.8507 - val_accuracy: 0.1153\n",
      "Epoch 341/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6756 - accuracy: 0.3310 - val_loss: 4.8515 - val_accuracy: 0.1132\n",
      "Epoch 342/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.6728 - accuracy: 0.3310 - val_loss: 4.8525 - val_accuracy: 0.1153\n",
      "Epoch 343/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.6683 - accuracy: 0.3240 - val_loss: 4.8633 - val_accuracy: 0.1069\n",
      "Epoch 344/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6711 - accuracy: 0.3324 - val_loss: 4.8623 - val_accuracy: 0.1069\n",
      "Epoch 345/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6692 - accuracy: 0.3247 - val_loss: 4.8844 - val_accuracy: 0.1237\n",
      "Epoch 346/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6789 - accuracy: 0.3233 - val_loss: 4.8785 - val_accuracy: 0.1090\n",
      "Epoch 347/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.6729 - accuracy: 0.3212 - val_loss: 4.8815 - val_accuracy: 0.1132\n",
      "Epoch 348/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.6718 - accuracy: 0.3303 - val_loss: 4.8974 - val_accuracy: 0.1153\n",
      "Epoch 349/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.6688 - accuracy: 0.3282 - val_loss: 4.9031 - val_accuracy: 0.1090\n",
      "Epoch 350/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.6708 - accuracy: 0.3331 - val_loss: 4.8993 - val_accuracy: 0.1216\n",
      "Epoch 351/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6668 - accuracy: 0.3331 - val_loss: 4.9187 - val_accuracy: 0.1174\n",
      "Epoch 352/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6699 - accuracy: 0.3275 - val_loss: 4.9055 - val_accuracy: 0.1237\n",
      "Epoch 353/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6695 - accuracy: 0.3275 - val_loss: 4.9261 - val_accuracy: 0.1153\n",
      "Epoch 354/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6707 - accuracy: 0.3261 - val_loss: 4.9237 - val_accuracy: 0.1027\n",
      "Epoch 355/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6680 - accuracy: 0.3282 - val_loss: 4.9207 - val_accuracy: 0.1048\n",
      "Epoch 356/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6680 - accuracy: 0.3282 - val_loss: 4.9243 - val_accuracy: 0.1132\n",
      "Epoch 357/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6664 - accuracy: 0.3254 - val_loss: 4.9339 - val_accuracy: 0.1174\n",
      "Epoch 358/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6661 - accuracy: 0.3296 - val_loss: 4.9305 - val_accuracy: 0.1153\n",
      "Epoch 359/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6627 - accuracy: 0.3254 - val_loss: 4.9247 - val_accuracy: 0.1195\n",
      "Epoch 360/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6652 - accuracy: 0.3394 - val_loss: 4.9343 - val_accuracy: 0.1153\n",
      "Epoch 361/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6722 - accuracy: 0.3282 - val_loss: 4.9631 - val_accuracy: 0.1069\n",
      "Epoch 362/500\n",
      "1429/1429 [==============================] - 0s 124us/step - loss: 2.6930 - accuracy: 0.3254 - val_loss: 4.9428 - val_accuracy: 0.1132\n",
      "Epoch 363/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.6676 - accuracy: 0.3331 - val_loss: 4.9407 - val_accuracy: 0.1174\n",
      "Epoch 364/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6751 - accuracy: 0.3198 - val_loss: 4.9437 - val_accuracy: 0.1237\n",
      "Epoch 365/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.6692 - accuracy: 0.3268 - val_loss: 4.9474 - val_accuracy: 0.1111\n",
      "Epoch 366/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6612 - accuracy: 0.3373 - val_loss: 4.9643 - val_accuracy: 0.1174\n",
      "Epoch 367/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6618 - accuracy: 0.3289 - val_loss: 4.9625 - val_accuracy: 0.1132\n",
      "Epoch 368/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6667 - accuracy: 0.3331 - val_loss: 4.9721 - val_accuracy: 0.1090\n",
      "Epoch 369/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6618 - accuracy: 0.3233 - val_loss: 4.9833 - val_accuracy: 0.1153\n",
      "Epoch 370/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6613 - accuracy: 0.3310 - val_loss: 4.9908 - val_accuracy: 0.1027\n",
      "Epoch 371/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6671 - accuracy: 0.3247 - val_loss: 4.9721 - val_accuracy: 0.1132\n",
      "Epoch 372/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.6626 - accuracy: 0.3310 - val_loss: 4.9830 - val_accuracy: 0.1132\n",
      "Epoch 373/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6631 - accuracy: 0.3317 - val_loss: 4.9844 - val_accuracy: 0.1153\n",
      "Epoch 374/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6632 - accuracy: 0.3205 - val_loss: 5.0050 - val_accuracy: 0.1069\n",
      "Epoch 375/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6622 - accuracy: 0.3366 - val_loss: 5.0160 - val_accuracy: 0.1090\n",
      "Epoch 376/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6595 - accuracy: 0.3282 - val_loss: 5.0049 - val_accuracy: 0.1090\n",
      "Epoch 377/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6602 - accuracy: 0.3198 - val_loss: 5.0139 - val_accuracy: 0.1111\n",
      "Epoch 378/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6610 - accuracy: 0.3296 - val_loss: 5.0365 - val_accuracy: 0.1195\n",
      "Epoch 379/500\n",
      "1429/1429 [==============================] - 0s 92us/step - loss: 2.6574 - accuracy: 0.3331 - val_loss: 5.0129 - val_accuracy: 0.1111\n",
      "Epoch 380/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6621 - accuracy: 0.3317 - val_loss: 4.9905 - val_accuracy: 0.1027\n",
      "Epoch 381/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6527 - accuracy: 0.3310 - val_loss: 5.0258 - val_accuracy: 0.1174\n",
      "Epoch 382/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6597 - accuracy: 0.3331 - val_loss: 5.0251 - val_accuracy: 0.1048\n",
      "Epoch 383/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6579 - accuracy: 0.3380 - val_loss: 5.0170 - val_accuracy: 0.1090\n",
      "Epoch 384/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6586 - accuracy: 0.3240 - val_loss: 5.0418 - val_accuracy: 0.1111\n",
      "Epoch 385/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6506 - accuracy: 0.3359 - val_loss: 5.0233 - val_accuracy: 0.1132\n",
      "Epoch 386/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6575 - accuracy: 0.3254 - val_loss: 5.0418 - val_accuracy: 0.1090\n",
      "Epoch 387/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6568 - accuracy: 0.3352 - val_loss: 5.0470 - val_accuracy: 0.1069\n",
      "Epoch 388/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6590 - accuracy: 0.3289 - val_loss: 5.0356 - val_accuracy: 0.1069\n",
      "Epoch 389/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6548 - accuracy: 0.3247 - val_loss: 5.0631 - val_accuracy: 0.1006\n",
      "Epoch 390/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6535 - accuracy: 0.3324 - val_loss: 5.0599 - val_accuracy: 0.1090\n",
      "Epoch 391/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6598 - accuracy: 0.3275 - val_loss: 5.0644 - val_accuracy: 0.1048\n",
      "Epoch 392/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6548 - accuracy: 0.3289 - val_loss: 5.0858 - val_accuracy: 0.1027\n",
      "Epoch 393/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6549 - accuracy: 0.3387 - val_loss: 5.0644 - val_accuracy: 0.1069\n",
      "Epoch 394/500\n",
      "1429/1429 [==============================] - 0s 92us/step - loss: 2.6488 - accuracy: 0.3331 - val_loss: 5.0917 - val_accuracy: 0.1090\n",
      "Epoch 395/500\n",
      "1429/1429 [==============================] - 0s 115us/step - loss: 2.6553 - accuracy: 0.3345 - val_loss: 5.0558 - val_accuracy: 0.1153\n",
      "Epoch 396/500\n",
      "1429/1429 [==============================] - 0s 118us/step - loss: 2.6530 - accuracy: 0.3422 - val_loss: 5.0882 - val_accuracy: 0.1111\n",
      "Epoch 397/500\n",
      "1429/1429 [==============================] - 0s 131us/step - loss: 2.6531 - accuracy: 0.3331 - val_loss: 5.0892 - val_accuracy: 0.1048\n",
      "Epoch 398/500\n",
      "1429/1429 [==============================] - 0s 151us/step - loss: 2.6535 - accuracy: 0.3261 - val_loss: 5.0911 - val_accuracy: 0.1111\n",
      "Epoch 399/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6479 - accuracy: 0.3303 - val_loss: 5.0972 - val_accuracy: 0.1006\n",
      "Epoch 400/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6620 - accuracy: 0.3359 - val_loss: 5.0957 - val_accuracy: 0.1069\n",
      "Epoch 401/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6640 - accuracy: 0.3219 - val_loss: 5.1134 - val_accuracy: 0.1069\n",
      "Epoch 402/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.6554 - accuracy: 0.3359 - val_loss: 5.1031 - val_accuracy: 0.1006\n",
      "Epoch 403/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.6517 - accuracy: 0.3331 - val_loss: 5.1165 - val_accuracy: 0.1132\n",
      "Epoch 404/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6498 - accuracy: 0.3310 - val_loss: 5.1266 - val_accuracy: 0.1069\n",
      "Epoch 405/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6663 - accuracy: 0.3310 - val_loss: 5.1316 - val_accuracy: 0.0964\n",
      "Epoch 406/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6543 - accuracy: 0.3345 - val_loss: 5.1321 - val_accuracy: 0.1132\n",
      "Epoch 407/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6703 - accuracy: 0.3338 - val_loss: 5.1323 - val_accuracy: 0.1048\n",
      "Epoch 408/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.6596 - accuracy: 0.3317 - val_loss: 5.1281 - val_accuracy: 0.1111\n",
      "Epoch 409/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6536 - accuracy: 0.3303 - val_loss: 5.1306 - val_accuracy: 0.1069\n",
      "Epoch 410/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6448 - accuracy: 0.3212 - val_loss: 5.1348 - val_accuracy: 0.1132\n",
      "Epoch 411/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6459 - accuracy: 0.3317 - val_loss: 5.1408 - val_accuracy: 0.1069\n",
      "Epoch 412/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6502 - accuracy: 0.3303 - val_loss: 5.1560 - val_accuracy: 0.0964\n",
      "Epoch 413/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6518 - accuracy: 0.3296 - val_loss: 5.1490 - val_accuracy: 0.1132\n",
      "Epoch 414/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.6562 - accuracy: 0.3282 - val_loss: 5.1576 - val_accuracy: 0.1027\n",
      "Epoch 415/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.6454 - accuracy: 0.3310 - val_loss: 5.1671 - val_accuracy: 0.1048\n",
      "Epoch 416/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.6451 - accuracy: 0.3226 - val_loss: 5.1767 - val_accuracy: 0.1006\n",
      "Epoch 417/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.6442 - accuracy: 0.3352 - val_loss: 5.1701 - val_accuracy: 0.1006\n",
      "Epoch 418/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6461 - accuracy: 0.3331 - val_loss: 5.1651 - val_accuracy: 0.1090\n",
      "Epoch 419/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6461 - accuracy: 0.3275 - val_loss: 5.1729 - val_accuracy: 0.1027\n",
      "Epoch 420/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6428 - accuracy: 0.3296 - val_loss: 5.1802 - val_accuracy: 0.1069\n",
      "Epoch 421/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6450 - accuracy: 0.3345 - val_loss: 5.2173 - val_accuracy: 0.1048\n",
      "Epoch 422/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6485 - accuracy: 0.3226 - val_loss: 5.2059 - val_accuracy: 0.1090\n",
      "Epoch 423/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6489 - accuracy: 0.3261 - val_loss: 5.1913 - val_accuracy: 0.1090\n",
      "Epoch 424/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6398 - accuracy: 0.3380 - val_loss: 5.2123 - val_accuracy: 0.0985\n",
      "Epoch 425/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6389 - accuracy: 0.3345 - val_loss: 5.1974 - val_accuracy: 0.1132\n",
      "Epoch 426/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.6463 - accuracy: 0.3408 - val_loss: 5.2170 - val_accuracy: 0.1111\n",
      "Epoch 427/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6471 - accuracy: 0.3254 - val_loss: 5.2303 - val_accuracy: 0.1027\n",
      "Epoch 428/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.6395 - accuracy: 0.3345 - val_loss: 5.2151 - val_accuracy: 0.1069\n",
      "Epoch 429/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6390 - accuracy: 0.3261 - val_loss: 5.2153 - val_accuracy: 0.1111\n",
      "Epoch 430/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6375 - accuracy: 0.3331 - val_loss: 5.2332 - val_accuracy: 0.1153\n",
      "Epoch 431/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6433 - accuracy: 0.3268 - val_loss: 5.2322 - val_accuracy: 0.1069\n",
      "Epoch 432/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6362 - accuracy: 0.3331 - val_loss: 5.2154 - val_accuracy: 0.1027\n",
      "Epoch 433/500\n",
      "1429/1429 [==============================] - 0s 142us/step - loss: 2.6413 - accuracy: 0.3436 - val_loss: 5.2375 - val_accuracy: 0.1216\n",
      "Epoch 434/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6402 - accuracy: 0.3415 - val_loss: 5.2169 - val_accuracy: 0.1048\n",
      "Epoch 435/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6366 - accuracy: 0.3303 - val_loss: 5.2689 - val_accuracy: 0.0985\n",
      "Epoch 436/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6342 - accuracy: 0.3317 - val_loss: 5.2533 - val_accuracy: 0.0985\n",
      "Epoch 437/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6413 - accuracy: 0.3394 - val_loss: 5.2519 - val_accuracy: 0.1090\n",
      "Epoch 438/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 2.6350 - accuracy: 0.3233 - val_loss: 5.2592 - val_accuracy: 0.1090\n",
      "Epoch 439/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6409 - accuracy: 0.3366 - val_loss: 5.2720 - val_accuracy: 0.0964\n",
      "Epoch 440/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6434 - accuracy: 0.3296 - val_loss: 5.2529 - val_accuracy: 0.1174\n",
      "Epoch 441/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6370 - accuracy: 0.3317 - val_loss: 5.2692 - val_accuracy: 0.1027\n",
      "Epoch 442/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6336 - accuracy: 0.3289 - val_loss: 5.2810 - val_accuracy: 0.1132\n",
      "Epoch 443/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6368 - accuracy: 0.3289 - val_loss: 5.2782 - val_accuracy: 0.1111\n",
      "Epoch 444/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6366 - accuracy: 0.3296 - val_loss: 5.2892 - val_accuracy: 0.1069\n",
      "Epoch 445/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.6363 - accuracy: 0.3331 - val_loss: 5.2923 - val_accuracy: 0.1174\n",
      "Epoch 446/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.6385 - accuracy: 0.3247 - val_loss: 5.2808 - val_accuracy: 0.0985\n",
      "Epoch 447/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6406 - accuracy: 0.3324 - val_loss: 5.3010 - val_accuracy: 0.1090\n",
      "Epoch 448/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6362 - accuracy: 0.3282 - val_loss: 5.2812 - val_accuracy: 0.1111\n",
      "Epoch 449/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6342 - accuracy: 0.3359 - val_loss: 5.3204 - val_accuracy: 0.1006\n",
      "Epoch 450/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6448 - accuracy: 0.3317 - val_loss: 5.2984 - val_accuracy: 0.1048\n",
      "Epoch 451/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6305 - accuracy: 0.3331 - val_loss: 5.2913 - val_accuracy: 0.1153\n",
      "Epoch 452/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6354 - accuracy: 0.3345 - val_loss: 5.3099 - val_accuracy: 0.1174\n",
      "Epoch 453/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.6323 - accuracy: 0.3401 - val_loss: 5.3177 - val_accuracy: 0.1027\n",
      "Epoch 454/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6271 - accuracy: 0.3366 - val_loss: 5.3073 - val_accuracy: 0.1132\n",
      "Epoch 455/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6608 - accuracy: 0.3408 - val_loss: 5.3103 - val_accuracy: 0.1195\n",
      "Epoch 456/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6376 - accuracy: 0.3233 - val_loss: 5.3274 - val_accuracy: 0.1090\n",
      "Epoch 457/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6494 - accuracy: 0.3317 - val_loss: 5.3269 - val_accuracy: 0.1048\n",
      "Epoch 458/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6507 - accuracy: 0.3268 - val_loss: 5.3616 - val_accuracy: 0.1006\n",
      "Epoch 459/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6333 - accuracy: 0.3317 - val_loss: 5.3245 - val_accuracy: 0.1027\n",
      "Epoch 460/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6378 - accuracy: 0.3394 - val_loss: 5.3482 - val_accuracy: 0.1006\n",
      "Epoch 461/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6371 - accuracy: 0.3366 - val_loss: 5.3465 - val_accuracy: 0.1069\n",
      "Epoch 462/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6339 - accuracy: 0.3352 - val_loss: 5.3473 - val_accuracy: 0.1048\n",
      "Epoch 463/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6339 - accuracy: 0.3338 - val_loss: 5.3512 - val_accuracy: 0.1069\n",
      "Epoch 464/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6357 - accuracy: 0.3324 - val_loss: 5.3407 - val_accuracy: 0.1111\n",
      "Epoch 465/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6327 - accuracy: 0.3247 - val_loss: 5.3622 - val_accuracy: 0.1132\n",
      "Epoch 466/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.6336 - accuracy: 0.3352 - val_loss: 5.3842 - val_accuracy: 0.1027\n",
      "Epoch 467/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6285 - accuracy: 0.3450 - val_loss: 5.3664 - val_accuracy: 0.1027\n",
      "Epoch 468/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.6294 - accuracy: 0.3415 - val_loss: 5.3693 - val_accuracy: 0.1069\n",
      "Epoch 469/500\n",
      "1429/1429 [==============================] - 0s 135us/step - loss: 2.6256 - accuracy: 0.3338 - val_loss: 5.3794 - val_accuracy: 0.1216\n",
      "Epoch 470/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6272 - accuracy: 0.3331 - val_loss: 5.3778 - val_accuracy: 0.1048\n",
      "Epoch 471/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6244 - accuracy: 0.3324 - val_loss: 5.3724 - val_accuracy: 0.1006\n",
      "Epoch 472/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.6259 - accuracy: 0.3373 - val_loss: 5.3992 - val_accuracy: 0.1132\n",
      "Epoch 473/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6286 - accuracy: 0.3359 - val_loss: 5.3987 - val_accuracy: 0.1048\n",
      "Epoch 474/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6296 - accuracy: 0.3317 - val_loss: 5.4013 - val_accuracy: 0.0985\n",
      "Epoch 475/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6256 - accuracy: 0.3415 - val_loss: 5.3902 - val_accuracy: 0.1027\n",
      "Epoch 476/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6261 - accuracy: 0.3422 - val_loss: 5.4375 - val_accuracy: 0.1069\n",
      "Epoch 477/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6416 - accuracy: 0.3289 - val_loss: 5.4063 - val_accuracy: 0.1153\n",
      "Epoch 478/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6285 - accuracy: 0.3380 - val_loss: 5.4192 - val_accuracy: 0.0985\n",
      "Epoch 479/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6230 - accuracy: 0.3373 - val_loss: 5.4099 - val_accuracy: 0.1111\n",
      "Epoch 480/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6245 - accuracy: 0.3422 - val_loss: 5.4216 - val_accuracy: 0.1027\n",
      "Epoch 481/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6236 - accuracy: 0.3366 - val_loss: 5.4360 - val_accuracy: 0.1048\n",
      "Epoch 482/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.6209 - accuracy: 0.3366 - val_loss: 5.4282 - val_accuracy: 0.1048\n",
      "Epoch 483/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6245 - accuracy: 0.3478 - val_loss: 5.4468 - val_accuracy: 0.1027\n",
      "Epoch 484/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.6283 - accuracy: 0.3415 - val_loss: 5.4224 - val_accuracy: 0.1153\n",
      "Epoch 485/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6272 - accuracy: 0.3366 - val_loss: 5.4498 - val_accuracy: 0.1006\n",
      "Epoch 486/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6237 - accuracy: 0.3338 - val_loss: 5.4578 - val_accuracy: 0.1006\n",
      "Epoch 487/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6260 - accuracy: 0.3352 - val_loss: 5.4657 - val_accuracy: 0.0985\n",
      "Epoch 488/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6206 - accuracy: 0.3317 - val_loss: 5.4654 - val_accuracy: 0.1027\n",
      "Epoch 489/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6277 - accuracy: 0.3317 - val_loss: 5.4565 - val_accuracy: 0.1006\n",
      "Epoch 490/500\n",
      "1429/1429 [==============================] - 0s 90us/step - loss: 2.6262 - accuracy: 0.3380 - val_loss: 5.4595 - val_accuracy: 0.1027\n",
      "Epoch 491/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6211 - accuracy: 0.3331 - val_loss: 5.4629 - val_accuracy: 0.1048\n",
      "Epoch 492/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6211 - accuracy: 0.3324 - val_loss: 5.4690 - val_accuracy: 0.1153\n",
      "Epoch 493/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6240 - accuracy: 0.3387 - val_loss: 5.4686 - val_accuracy: 0.1048\n",
      "Epoch 494/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6198 - accuracy: 0.3366 - val_loss: 5.4835 - val_accuracy: 0.1195\n",
      "Epoch 495/500\n",
      "1429/1429 [==============================] - 0s 132us/step - loss: 2.6232 - accuracy: 0.3366 - val_loss: 5.4961 - val_accuracy: 0.1111\n",
      "Epoch 496/500\n",
      "1429/1429 [==============================] - 0s 126us/step - loss: 2.6188 - accuracy: 0.3394 - val_loss: 5.4811 - val_accuracy: 0.1132\n",
      "Epoch 497/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.6170 - accuracy: 0.3415 - val_loss: 5.4961 - val_accuracy: 0.0964\n",
      "Epoch 498/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.6175 - accuracy: 0.3338 - val_loss: 5.4915 - val_accuracy: 0.1048\n",
      "Epoch 499/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.6140 - accuracy: 0.3478 - val_loss: 5.5139 - val_accuracy: 0.1132\n",
      "Epoch 500/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.6173 - accuracy: 0.3436 - val_loss: 5.5096 - val_accuracy: 0.1174\n",
      "Train on 1429 samples, validate on 477 samples\n",
      "Epoch 1/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 3.2790 - accuracy: 0.2869 - val_loss: 3.5080 - val_accuracy: 0.2600\n",
      "Epoch 2/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 3.2263 - accuracy: 0.2848 - val_loss: 3.5836 - val_accuracy: 0.2600\n",
      "Epoch 3/500\n",
      "1429/1429 [==============================] - 0s 150us/step - loss: 3.2071 - accuracy: 0.2715 - val_loss: 3.5712 - val_accuracy: 0.2348\n",
      "Epoch 4/500\n",
      "1429/1429 [==============================] - 0s 125us/step - loss: 3.1789 - accuracy: 0.2855 - val_loss: 3.5851 - val_accuracy: 0.2327\n",
      "Epoch 5/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 3.1596 - accuracy: 0.2827 - val_loss: 3.5922 - val_accuracy: 0.2474\n",
      "Epoch 6/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 3.1448 - accuracy: 0.2848 - val_loss: 3.5874 - val_accuracy: 0.2474\n",
      "Epoch 7/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 3.1265 - accuracy: 0.2834 - val_loss: 3.6494 - val_accuracy: 0.2369\n",
      "Epoch 8/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 3.1343 - accuracy: 0.2827 - val_loss: 3.6189 - val_accuracy: 0.2264\n",
      "Epoch 9/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 3.1090 - accuracy: 0.2827 - val_loss: 3.6366 - val_accuracy: 0.2180\n",
      "Epoch 10/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 3.1190 - accuracy: 0.2848 - val_loss: 3.6392 - val_accuracy: 0.2243\n",
      "Epoch 11/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 3.1036 - accuracy: 0.2911 - val_loss: 3.6509 - val_accuracy: 0.2159\n",
      "Epoch 12/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 3.0769 - accuracy: 0.2897 - val_loss: 3.6498 - val_accuracy: 0.2075\n",
      "Epoch 13/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 3.0673 - accuracy: 0.2806 - val_loss: 3.6702 - val_accuracy: 0.2034\n",
      "Epoch 14/500\n",
      "1429/1429 [==============================] - 0s 163us/step - loss: 3.0601 - accuracy: 0.2855 - val_loss: 3.6680 - val_accuracy: 0.2096\n",
      "Epoch 15/500\n",
      "1429/1429 [==============================] - 0s 128us/step - loss: 3.0439 - accuracy: 0.3030 - val_loss: 3.6874 - val_accuracy: 0.2096\n",
      "Epoch 16/500\n",
      "1429/1429 [==============================] - 0s 130us/step - loss: 3.0420 - accuracy: 0.2925 - val_loss: 3.6880 - val_accuracy: 0.1971\n",
      "Epoch 17/500\n",
      "1429/1429 [==============================] - 0s 151us/step - loss: 3.0332 - accuracy: 0.2953 - val_loss: 3.7012 - val_accuracy: 0.2013\n",
      "Epoch 18/500\n",
      "1429/1429 [==============================] - 0s 133us/step - loss: 3.0256 - accuracy: 0.2848 - val_loss: 3.6957 - val_accuracy: 0.2117\n",
      "Epoch 19/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 3.0193 - accuracy: 0.2995 - val_loss: 3.7173 - val_accuracy: 0.1929\n",
      "Epoch 20/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 3.0161 - accuracy: 0.2925 - val_loss: 3.7143 - val_accuracy: 0.2034\n",
      "Epoch 21/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 3.0070 - accuracy: 0.2904 - val_loss: 3.7080 - val_accuracy: 0.1950\n",
      "Epoch 22/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 3.0058 - accuracy: 0.2932 - val_loss: 3.7201 - val_accuracy: 0.1761\n",
      "Epoch 23/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.9964 - accuracy: 0.2925 - val_loss: 3.7315 - val_accuracy: 0.1992\n",
      "Epoch 24/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.9987 - accuracy: 0.2988 - val_loss: 3.7415 - val_accuracy: 0.1761\n",
      "Epoch 25/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.9898 - accuracy: 0.2953 - val_loss: 3.7340 - val_accuracy: 0.1929\n",
      "Epoch 26/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.9854 - accuracy: 0.2946 - val_loss: 3.7361 - val_accuracy: 0.1992\n",
      "Epoch 27/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.9761 - accuracy: 0.3002 - val_loss: 3.7646 - val_accuracy: 0.1887\n",
      "Epoch 28/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.9743 - accuracy: 0.2918 - val_loss: 3.7463 - val_accuracy: 0.1803\n",
      "Epoch 29/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.9740 - accuracy: 0.2918 - val_loss: 3.7627 - val_accuracy: 0.2013\n",
      "Epoch 30/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.9741 - accuracy: 0.2967 - val_loss: 3.7526 - val_accuracy: 0.1950\n",
      "Epoch 31/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.9704 - accuracy: 0.2925 - val_loss: 3.7616 - val_accuracy: 0.1908\n",
      "Epoch 32/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.9635 - accuracy: 0.2960 - val_loss: 3.7775 - val_accuracy: 0.1929\n",
      "Epoch 33/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.9537 - accuracy: 0.2883 - val_loss: 3.7735 - val_accuracy: 0.1887\n",
      "Epoch 34/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.9451 - accuracy: 0.2967 - val_loss: 3.7683 - val_accuracy: 0.1887\n",
      "Epoch 35/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.9470 - accuracy: 0.2974 - val_loss: 3.7982 - val_accuracy: 0.1782\n",
      "Epoch 36/500\n",
      "1429/1429 [==============================] - 0s 135us/step - loss: 2.9465 - accuracy: 0.2939 - val_loss: 3.7725 - val_accuracy: 0.1719\n",
      "Epoch 37/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.9384 - accuracy: 0.2995 - val_loss: 3.8159 - val_accuracy: 0.1824\n",
      "Epoch 38/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.9425 - accuracy: 0.2925 - val_loss: 3.7850 - val_accuracy: 0.1803\n",
      "Epoch 39/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.9349 - accuracy: 0.2904 - val_loss: 3.7989 - val_accuracy: 0.1803\n",
      "Epoch 40/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.9234 - accuracy: 0.2981 - val_loss: 3.8004 - val_accuracy: 0.1782\n",
      "Epoch 41/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.9253 - accuracy: 0.2981 - val_loss: 3.8021 - val_accuracy: 0.1740\n",
      "Epoch 42/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.9174 - accuracy: 0.2988 - val_loss: 3.8058 - val_accuracy: 0.1740\n",
      "Epoch 43/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.9124 - accuracy: 0.2946 - val_loss: 3.8155 - val_accuracy: 0.1803\n",
      "Epoch 44/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.9226 - accuracy: 0.2953 - val_loss: 3.8361 - val_accuracy: 0.1719\n",
      "Epoch 45/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.9429 - accuracy: 0.2981 - val_loss: 3.8275 - val_accuracy: 0.1824\n",
      "Epoch 46/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.9137 - accuracy: 0.2981 - val_loss: 3.8161 - val_accuracy: 0.1782\n",
      "Epoch 47/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.9037 - accuracy: 0.2974 - val_loss: 3.8242 - val_accuracy: 0.1740\n",
      "Epoch 48/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.9034 - accuracy: 0.2939 - val_loss: 3.8214 - val_accuracy: 0.1593\n",
      "Epoch 49/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.9007 - accuracy: 0.3037 - val_loss: 3.8539 - val_accuracy: 0.1740\n",
      "Epoch 50/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.8977 - accuracy: 0.3023 - val_loss: 3.8511 - val_accuracy: 0.1677\n",
      "Epoch 51/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.8948 - accuracy: 0.3065 - val_loss: 3.8399 - val_accuracy: 0.1761\n",
      "Epoch 52/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.8870 - accuracy: 0.2974 - val_loss: 3.8498 - val_accuracy: 0.1740\n",
      "Epoch 53/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.8814 - accuracy: 0.3030 - val_loss: 3.8527 - val_accuracy: 0.1656\n",
      "Epoch 54/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.8850 - accuracy: 0.3023 - val_loss: 3.8723 - val_accuracy: 0.1656\n",
      "Epoch 55/500\n",
      "1429/1429 [==============================] - 0s 93us/step - loss: 2.8883 - accuracy: 0.3016 - val_loss: 3.8577 - val_accuracy: 0.1761\n",
      "Epoch 56/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.8783 - accuracy: 0.2995 - val_loss: 3.8600 - val_accuracy: 0.1551\n",
      "Epoch 57/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.8763 - accuracy: 0.3002 - val_loss: 3.8632 - val_accuracy: 0.1761\n",
      "Epoch 58/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.8734 - accuracy: 0.3044 - val_loss: 3.8729 - val_accuracy: 0.1719\n",
      "Epoch 59/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.8726 - accuracy: 0.2981 - val_loss: 3.8757 - val_accuracy: 0.1698\n",
      "Epoch 60/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.8694 - accuracy: 0.3009 - val_loss: 3.8800 - val_accuracy: 0.1677\n",
      "Epoch 61/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.8719 - accuracy: 0.3009 - val_loss: 3.8652 - val_accuracy: 0.1614\n",
      "Epoch 62/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.8646 - accuracy: 0.3065 - val_loss: 3.8764 - val_accuracy: 0.1614\n",
      "Epoch 63/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.8630 - accuracy: 0.2946 - val_loss: 3.8885 - val_accuracy: 0.1572\n",
      "Epoch 64/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.8559 - accuracy: 0.3030 - val_loss: 3.8814 - val_accuracy: 0.1719\n",
      "Epoch 65/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.8640 - accuracy: 0.2918 - val_loss: 3.8717 - val_accuracy: 0.1635\n",
      "Epoch 66/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.8626 - accuracy: 0.2960 - val_loss: 3.8980 - val_accuracy: 0.1656\n",
      "Epoch 67/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.8631 - accuracy: 0.2967 - val_loss: 3.8852 - val_accuracy: 0.1698\n",
      "Epoch 68/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.8773 - accuracy: 0.3051 - val_loss: 3.9070 - val_accuracy: 0.1593\n",
      "Epoch 69/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.8686 - accuracy: 0.2939 - val_loss: 3.8908 - val_accuracy: 0.1677\n",
      "Epoch 70/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.8474 - accuracy: 0.2988 - val_loss: 3.9178 - val_accuracy: 0.1635\n",
      "Epoch 71/500\n",
      "1429/1429 [==============================] - 0s 136us/step - loss: 2.8614 - accuracy: 0.3100 - val_loss: 3.9070 - val_accuracy: 0.1677\n",
      "Epoch 72/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.8456 - accuracy: 0.3037 - val_loss: 3.9191 - val_accuracy: 0.1551\n",
      "Epoch 73/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.8448 - accuracy: 0.3044 - val_loss: 3.9023 - val_accuracy: 0.1572\n",
      "Epoch 74/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.8457 - accuracy: 0.3058 - val_loss: 3.9273 - val_accuracy: 0.1677\n",
      "Epoch 75/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.8394 - accuracy: 0.3058 - val_loss: 3.9391 - val_accuracy: 0.1509\n",
      "Epoch 76/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.8368 - accuracy: 0.3100 - val_loss: 3.9280 - val_accuracy: 0.1656\n",
      "Epoch 77/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.8304 - accuracy: 0.3016 - val_loss: 3.9331 - val_accuracy: 0.1593\n",
      "Epoch 78/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.8336 - accuracy: 0.3065 - val_loss: 3.9447 - val_accuracy: 0.1572\n",
      "Epoch 79/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.8267 - accuracy: 0.3044 - val_loss: 3.9804 - val_accuracy: 0.1530\n",
      "Epoch 80/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.8248 - accuracy: 0.3086 - val_loss: 3.9507 - val_accuracy: 0.1614\n",
      "Epoch 81/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.8219 - accuracy: 0.3100 - val_loss: 3.9321 - val_accuracy: 0.1593\n",
      "Epoch 82/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.8222 - accuracy: 0.3114 - val_loss: 3.9465 - val_accuracy: 0.1614\n",
      "Epoch 83/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.8224 - accuracy: 0.2995 - val_loss: 3.9568 - val_accuracy: 0.1635\n",
      "Epoch 84/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.8210 - accuracy: 0.3030 - val_loss: 3.9562 - val_accuracy: 0.1677\n",
      "Epoch 85/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.8161 - accuracy: 0.3086 - val_loss: 3.9517 - val_accuracy: 0.1572\n",
      "Epoch 86/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.8197 - accuracy: 0.3016 - val_loss: 3.9626 - val_accuracy: 0.1656\n",
      "Epoch 87/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.8182 - accuracy: 0.3107 - val_loss: 3.9562 - val_accuracy: 0.1551\n",
      "Epoch 88/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.8150 - accuracy: 0.3072 - val_loss: 3.9695 - val_accuracy: 0.1572\n",
      "Epoch 89/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.8126 - accuracy: 0.3065 - val_loss: 3.9766 - val_accuracy: 0.1551\n",
      "Epoch 90/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.8129 - accuracy: 0.3023 - val_loss: 3.9752 - val_accuracy: 0.1593\n",
      "Epoch 91/500\n",
      "1429/1429 [==============================] - 0s 90us/step - loss: 2.8084 - accuracy: 0.3072 - val_loss: 3.9673 - val_accuracy: 0.1488\n",
      "Epoch 92/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.8080 - accuracy: 0.3100 - val_loss: 3.9695 - val_accuracy: 0.1593\n",
      "Epoch 93/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.8124 - accuracy: 0.3037 - val_loss: 3.9896 - val_accuracy: 0.1509\n",
      "Epoch 94/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.8019 - accuracy: 0.3023 - val_loss: 3.9830 - val_accuracy: 0.1572\n",
      "Epoch 95/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.8007 - accuracy: 0.3009 - val_loss: 3.9829 - val_accuracy: 0.1468\n",
      "Epoch 96/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7977 - accuracy: 0.3044 - val_loss: 4.0126 - val_accuracy: 0.1426\n",
      "Epoch 97/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.7971 - accuracy: 0.3079 - val_loss: 3.9969 - val_accuracy: 0.1593\n",
      "Epoch 98/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.7926 - accuracy: 0.3086 - val_loss: 4.0142 - val_accuracy: 0.1468\n",
      "Epoch 99/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.7968 - accuracy: 0.3093 - val_loss: 3.9943 - val_accuracy: 0.1468\n",
      "Epoch 100/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.7938 - accuracy: 0.3037 - val_loss: 4.0035 - val_accuracy: 0.1614\n",
      "Epoch 101/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7955 - accuracy: 0.3086 - val_loss: 4.0236 - val_accuracy: 0.1509\n",
      "Epoch 102/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.8068 - accuracy: 0.3023 - val_loss: 4.0083 - val_accuracy: 0.1447\n",
      "Epoch 103/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.7928 - accuracy: 0.3023 - val_loss: 4.0167 - val_accuracy: 0.1551\n",
      "Epoch 104/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.7939 - accuracy: 0.3170 - val_loss: 4.0177 - val_accuracy: 0.1488\n",
      "Epoch 105/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7907 - accuracy: 0.3072 - val_loss: 4.0364 - val_accuracy: 0.1468\n",
      "Epoch 106/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.7923 - accuracy: 0.3114 - val_loss: 4.0308 - val_accuracy: 0.1468\n",
      "Epoch 107/500\n",
      "1429/1429 [==============================] - 0s 139us/step - loss: 2.7883 - accuracy: 0.3100 - val_loss: 4.0158 - val_accuracy: 0.1468\n",
      "Epoch 108/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.7859 - accuracy: 0.3072 - val_loss: 4.0395 - val_accuracy: 0.1488\n",
      "Epoch 109/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.7908 - accuracy: 0.3072 - val_loss: 4.0275 - val_accuracy: 0.1363\n",
      "Epoch 110/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7802 - accuracy: 0.3107 - val_loss: 4.0292 - val_accuracy: 0.1405\n",
      "Epoch 111/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.7847 - accuracy: 0.3114 - val_loss: 4.0388 - val_accuracy: 0.1509\n",
      "Epoch 112/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.8048 - accuracy: 0.3079 - val_loss: 4.0621 - val_accuracy: 0.1426\n",
      "Epoch 113/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.7964 - accuracy: 0.3079 - val_loss: 4.0335 - val_accuracy: 0.1468\n",
      "Epoch 114/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.7772 - accuracy: 0.3149 - val_loss: 4.0447 - val_accuracy: 0.1488\n",
      "Epoch 115/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.7704 - accuracy: 0.3128 - val_loss: 4.0556 - val_accuracy: 0.1405\n",
      "Epoch 116/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7845 - accuracy: 0.3100 - val_loss: 4.0380 - val_accuracy: 0.1447\n",
      "Epoch 117/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7789 - accuracy: 0.3051 - val_loss: 4.0505 - val_accuracy: 0.1488\n",
      "Epoch 118/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.7754 - accuracy: 0.3093 - val_loss: 4.0493 - val_accuracy: 0.1509\n",
      "Epoch 119/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.7691 - accuracy: 0.3114 - val_loss: 4.0837 - val_accuracy: 0.1384\n",
      "Epoch 120/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7680 - accuracy: 0.3072 - val_loss: 4.0592 - val_accuracy: 0.1468\n",
      "Epoch 121/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.7699 - accuracy: 0.3135 - val_loss: 4.0744 - val_accuracy: 0.1405\n",
      "Epoch 122/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.7708 - accuracy: 0.3107 - val_loss: 4.0802 - val_accuracy: 0.1342\n",
      "Epoch 123/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7693 - accuracy: 0.3191 - val_loss: 4.0675 - val_accuracy: 0.1447\n",
      "Epoch 124/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.7654 - accuracy: 0.3121 - val_loss: 4.0915 - val_accuracy: 0.1468\n",
      "Epoch 125/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7661 - accuracy: 0.3156 - val_loss: 4.0792 - val_accuracy: 0.1447\n",
      "Epoch 126/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7638 - accuracy: 0.3114 - val_loss: 4.0820 - val_accuracy: 0.1488\n",
      "Epoch 127/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7640 - accuracy: 0.3121 - val_loss: 4.0834 - val_accuracy: 0.1363\n",
      "Epoch 128/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7626 - accuracy: 0.3177 - val_loss: 4.1015 - val_accuracy: 0.1468\n",
      "Epoch 129/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.7660 - accuracy: 0.3198 - val_loss: 4.1088 - val_accuracy: 0.1384\n",
      "Epoch 130/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 2.7558 - accuracy: 0.3149 - val_loss: 4.0843 - val_accuracy: 0.1405\n",
      "Epoch 131/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7581 - accuracy: 0.3142 - val_loss: 4.1032 - val_accuracy: 0.1447\n",
      "Epoch 132/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.7530 - accuracy: 0.3142 - val_loss: 4.1109 - val_accuracy: 0.1447\n",
      "Epoch 133/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7621 - accuracy: 0.3065 - val_loss: 4.0983 - val_accuracy: 0.1426\n",
      "Epoch 134/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.7521 - accuracy: 0.3163 - val_loss: 4.1196 - val_accuracy: 0.1405\n",
      "Epoch 135/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7487 - accuracy: 0.3128 - val_loss: 4.1168 - val_accuracy: 0.1426\n",
      "Epoch 136/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7542 - accuracy: 0.3149 - val_loss: 4.1384 - val_accuracy: 0.1363\n",
      "Epoch 137/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7565 - accuracy: 0.3163 - val_loss: 4.1145 - val_accuracy: 0.1384\n",
      "Epoch 138/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.7652 - accuracy: 0.3093 - val_loss: 4.1073 - val_accuracy: 0.1447\n",
      "Epoch 139/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.7561 - accuracy: 0.3135 - val_loss: 4.1212 - val_accuracy: 0.1488\n",
      "Epoch 140/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.7513 - accuracy: 0.3191 - val_loss: 4.1342 - val_accuracy: 0.1447\n",
      "Epoch 141/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.7501 - accuracy: 0.3170 - val_loss: 4.1136 - val_accuracy: 0.1488\n",
      "Epoch 142/500\n",
      "1429/1429 [==============================] - 0s 130us/step - loss: 2.7448 - accuracy: 0.3233 - val_loss: 4.1392 - val_accuracy: 0.1363\n",
      "Epoch 143/500\n",
      "1429/1429 [==============================] - 0s 120us/step - loss: 2.7570 - accuracy: 0.3100 - val_loss: 4.1444 - val_accuracy: 0.1321\n",
      "Epoch 144/500\n",
      "1429/1429 [==============================] - 0s 92us/step - loss: 2.7557 - accuracy: 0.3170 - val_loss: 4.1408 - val_accuracy: 0.1405\n",
      "Epoch 145/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7653 - accuracy: 0.3093 - val_loss: 4.1456 - val_accuracy: 0.1488\n",
      "Epoch 146/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7446 - accuracy: 0.3135 - val_loss: 4.1481 - val_accuracy: 0.1384\n",
      "Epoch 147/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7450 - accuracy: 0.3093 - val_loss: 4.1376 - val_accuracy: 0.1509\n",
      "Epoch 148/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7399 - accuracy: 0.3114 - val_loss: 4.1426 - val_accuracy: 0.1447\n",
      "Epoch 149/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.7420 - accuracy: 0.3093 - val_loss: 4.1554 - val_accuracy: 0.1321\n",
      "Epoch 150/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7516 - accuracy: 0.3107 - val_loss: 4.1580 - val_accuracy: 0.1468\n",
      "Epoch 151/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.7382 - accuracy: 0.3212 - val_loss: 4.1672 - val_accuracy: 0.1405\n",
      "Epoch 152/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7414 - accuracy: 0.3128 - val_loss: 4.1566 - val_accuracy: 0.1468\n",
      "Epoch 153/500\n",
      "1429/1429 [==============================] - 0s 115us/step - loss: 2.7470 - accuracy: 0.3086 - val_loss: 4.1659 - val_accuracy: 0.1384\n",
      "Epoch 154/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7441 - accuracy: 0.3086 - val_loss: 4.1729 - val_accuracy: 0.1426\n",
      "Epoch 155/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.7347 - accuracy: 0.3163 - val_loss: 4.1760 - val_accuracy: 0.1342\n",
      "Epoch 156/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.7343 - accuracy: 0.3191 - val_loss: 4.1824 - val_accuracy: 0.1405\n",
      "Epoch 157/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.7382 - accuracy: 0.3191 - val_loss: 4.2103 - val_accuracy: 0.1384\n",
      "Epoch 158/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7292 - accuracy: 0.3121 - val_loss: 4.1775 - val_accuracy: 0.1342\n",
      "Epoch 159/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.7297 - accuracy: 0.3184 - val_loss: 4.1945 - val_accuracy: 0.1468\n",
      "Epoch 160/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.7299 - accuracy: 0.3191 - val_loss: 4.1990 - val_accuracy: 0.1384\n",
      "Epoch 161/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.7317 - accuracy: 0.3212 - val_loss: 4.2149 - val_accuracy: 0.1363\n",
      "Epoch 162/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7312 - accuracy: 0.3198 - val_loss: 4.2076 - val_accuracy: 0.1300\n",
      "Epoch 163/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7303 - accuracy: 0.3135 - val_loss: 4.2039 - val_accuracy: 0.1342\n",
      "Epoch 164/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7313 - accuracy: 0.3177 - val_loss: 4.1889 - val_accuracy: 0.1363\n",
      "Epoch 165/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7294 - accuracy: 0.3233 - val_loss: 4.1958 - val_accuracy: 0.1426\n",
      "Epoch 166/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7356 - accuracy: 0.3191 - val_loss: 4.2080 - val_accuracy: 0.1530\n",
      "Epoch 167/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.7232 - accuracy: 0.3142 - val_loss: 4.2204 - val_accuracy: 0.1405\n",
      "Epoch 168/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7233 - accuracy: 0.3240 - val_loss: 4.2144 - val_accuracy: 0.1363\n",
      "Epoch 169/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.7248 - accuracy: 0.3163 - val_loss: 4.2240 - val_accuracy: 0.1363\n",
      "Epoch 170/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.7312 - accuracy: 0.3142 - val_loss: 4.2185 - val_accuracy: 0.1363\n",
      "Epoch 171/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7244 - accuracy: 0.3205 - val_loss: 4.2354 - val_accuracy: 0.1384\n",
      "Epoch 172/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.7244 - accuracy: 0.3226 - val_loss: 4.2187 - val_accuracy: 0.1384\n",
      "Epoch 173/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7144 - accuracy: 0.3191 - val_loss: 4.2524 - val_accuracy: 0.1384\n",
      "Epoch 174/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.7182 - accuracy: 0.3163 - val_loss: 4.2856 - val_accuracy: 0.1342\n",
      "Epoch 175/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.7268 - accuracy: 0.3177 - val_loss: 4.2462 - val_accuracy: 0.1384\n",
      "Epoch 176/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7144 - accuracy: 0.3219 - val_loss: 4.2421 - val_accuracy: 0.1342\n",
      "Epoch 177/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.7159 - accuracy: 0.3156 - val_loss: 4.2473 - val_accuracy: 0.1342\n",
      "Epoch 178/500\n",
      "1429/1429 [==============================] - 0s 139us/step - loss: 2.7158 - accuracy: 0.3184 - val_loss: 4.2535 - val_accuracy: 0.1279\n",
      "Epoch 179/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.7170 - accuracy: 0.3233 - val_loss: 4.2531 - val_accuracy: 0.1300\n",
      "Epoch 180/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.7165 - accuracy: 0.3156 - val_loss: 4.2593 - val_accuracy: 0.1405\n",
      "Epoch 181/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.7081 - accuracy: 0.3205 - val_loss: 4.2730 - val_accuracy: 0.1321\n",
      "Epoch 182/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.7137 - accuracy: 0.3254 - val_loss: 4.2869 - val_accuracy: 0.1447\n",
      "Epoch 183/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.7280 - accuracy: 0.3114 - val_loss: 4.2555 - val_accuracy: 0.1447\n",
      "Epoch 184/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.7060 - accuracy: 0.3233 - val_loss: 4.2704 - val_accuracy: 0.1384\n",
      "Epoch 185/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7081 - accuracy: 0.3170 - val_loss: 4.2665 - val_accuracy: 0.1384\n",
      "Epoch 186/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7073 - accuracy: 0.3212 - val_loss: 4.2898 - val_accuracy: 0.1321\n",
      "Epoch 187/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.7101 - accuracy: 0.3226 - val_loss: 4.2803 - val_accuracy: 0.1342\n",
      "Epoch 188/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7172 - accuracy: 0.3310 - val_loss: 4.2860 - val_accuracy: 0.1321\n",
      "Epoch 189/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.7160 - accuracy: 0.3219 - val_loss: 4.2665 - val_accuracy: 0.1384\n",
      "Epoch 190/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7212 - accuracy: 0.3233 - val_loss: 4.2830 - val_accuracy: 0.1363\n",
      "Epoch 191/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7164 - accuracy: 0.3177 - val_loss: 4.3148 - val_accuracy: 0.1426\n",
      "Epoch 192/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7057 - accuracy: 0.3254 - val_loss: 4.3004 - val_accuracy: 0.1237\n",
      "Epoch 193/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.7176 - accuracy: 0.3240 - val_loss: 4.3035 - val_accuracy: 0.1342\n",
      "Epoch 194/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7022 - accuracy: 0.3212 - val_loss: 4.3115 - val_accuracy: 0.1363\n",
      "Epoch 195/500\n",
      "1429/1429 [==============================] - 0s 90us/step - loss: 2.7053 - accuracy: 0.3135 - val_loss: 4.3210 - val_accuracy: 0.1342\n",
      "Epoch 196/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 2.6986 - accuracy: 0.3247 - val_loss: 4.3136 - val_accuracy: 0.1300\n",
      "Epoch 197/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6994 - accuracy: 0.3303 - val_loss: 4.3293 - val_accuracy: 0.1258\n",
      "Epoch 198/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7008 - accuracy: 0.3247 - val_loss: 4.3238 - val_accuracy: 0.1363\n",
      "Epoch 199/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6989 - accuracy: 0.3205 - val_loss: 4.3149 - val_accuracy: 0.1468\n",
      "Epoch 200/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6999 - accuracy: 0.3247 - val_loss: 4.3433 - val_accuracy: 0.1342\n",
      "Epoch 201/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6949 - accuracy: 0.3233 - val_loss: 4.3360 - val_accuracy: 0.1363\n",
      "Epoch 202/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.7000 - accuracy: 0.3282 - val_loss: 4.3416 - val_accuracy: 0.1321\n",
      "Epoch 203/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6989 - accuracy: 0.3331 - val_loss: 4.3422 - val_accuracy: 0.1405\n",
      "Epoch 204/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6973 - accuracy: 0.3149 - val_loss: 4.3515 - val_accuracy: 0.1216\n",
      "Epoch 205/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6990 - accuracy: 0.3198 - val_loss: 4.3465 - val_accuracy: 0.1258\n",
      "Epoch 206/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 2.7086 - accuracy: 0.3240 - val_loss: 4.3550 - val_accuracy: 0.1384\n",
      "Epoch 207/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6962 - accuracy: 0.3247 - val_loss: 4.3374 - val_accuracy: 0.1363\n",
      "Epoch 208/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6958 - accuracy: 0.3184 - val_loss: 4.3413 - val_accuracy: 0.1300\n",
      "Epoch 209/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6965 - accuracy: 0.3170 - val_loss: 4.3538 - val_accuracy: 0.1342\n",
      "Epoch 210/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.6986 - accuracy: 0.3177 - val_loss: 4.3668 - val_accuracy: 0.1321\n",
      "Epoch 211/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6936 - accuracy: 0.3149 - val_loss: 4.3882 - val_accuracy: 0.1237\n",
      "Epoch 212/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6931 - accuracy: 0.3226 - val_loss: 4.3594 - val_accuracy: 0.1237\n",
      "Epoch 213/500\n",
      "1429/1429 [==============================] - 0s 90us/step - loss: 2.6886 - accuracy: 0.3268 - val_loss: 4.3690 - val_accuracy: 0.1405\n",
      "Epoch 214/500\n",
      "1429/1429 [==============================] - 0s 139us/step - loss: 2.6891 - accuracy: 0.3282 - val_loss: 4.3913 - val_accuracy: 0.1363\n",
      "Epoch 215/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.6938 - accuracy: 0.3289 - val_loss: 4.3742 - val_accuracy: 0.1426\n",
      "Epoch 216/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6852 - accuracy: 0.3366 - val_loss: 4.3877 - val_accuracy: 0.1279\n",
      "Epoch 217/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6866 - accuracy: 0.3212 - val_loss: 4.3942 - val_accuracy: 0.1321\n",
      "Epoch 218/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6864 - accuracy: 0.3212 - val_loss: 4.4032 - val_accuracy: 0.1300\n",
      "Epoch 219/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.6909 - accuracy: 0.3128 - val_loss: 4.3767 - val_accuracy: 0.1279\n",
      "Epoch 220/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.6888 - accuracy: 0.3163 - val_loss: 4.3996 - val_accuracy: 0.1363\n",
      "Epoch 221/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6937 - accuracy: 0.3261 - val_loss: 4.4132 - val_accuracy: 0.1258\n",
      "Epoch 222/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6907 - accuracy: 0.3233 - val_loss: 4.3872 - val_accuracy: 0.1405\n",
      "Epoch 223/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.7104 - accuracy: 0.3156 - val_loss: 4.4173 - val_accuracy: 0.1258\n",
      "Epoch 224/500\n",
      "1429/1429 [==============================] - 0s 120us/step - loss: 2.6892 - accuracy: 0.3163 - val_loss: 4.4273 - val_accuracy: 0.1321\n",
      "Epoch 225/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6891 - accuracy: 0.3212 - val_loss: 4.4180 - val_accuracy: 0.1321\n",
      "Epoch 226/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 2.6876 - accuracy: 0.3191 - val_loss: 4.4351 - val_accuracy: 0.1321\n",
      "Epoch 227/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6828 - accuracy: 0.3226 - val_loss: 4.4346 - val_accuracy: 0.1258\n",
      "Epoch 228/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6857 - accuracy: 0.3184 - val_loss: 4.4438 - val_accuracy: 0.1300\n",
      "Epoch 229/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6896 - accuracy: 0.3233 - val_loss: 4.4415 - val_accuracy: 0.1363\n",
      "Epoch 230/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6835 - accuracy: 0.3184 - val_loss: 4.4512 - val_accuracy: 0.1258\n",
      "Epoch 231/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.6925 - accuracy: 0.3331 - val_loss: 4.4311 - val_accuracy: 0.1279\n",
      "Epoch 232/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6842 - accuracy: 0.3205 - val_loss: 4.4426 - val_accuracy: 0.1237\n",
      "Epoch 233/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.6839 - accuracy: 0.3233 - val_loss: 4.4352 - val_accuracy: 0.1237\n",
      "Epoch 234/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.6759 - accuracy: 0.3275 - val_loss: 4.4389 - val_accuracy: 0.1258\n",
      "Epoch 235/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6816 - accuracy: 0.3240 - val_loss: 4.4726 - val_accuracy: 0.1300\n",
      "Epoch 236/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6800 - accuracy: 0.3226 - val_loss: 4.4587 - val_accuracy: 0.1342\n",
      "Epoch 237/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6851 - accuracy: 0.3219 - val_loss: 4.4628 - val_accuracy: 0.1321\n",
      "Epoch 238/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.6809 - accuracy: 0.3240 - val_loss: 4.4752 - val_accuracy: 0.1300\n",
      "Epoch 239/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6770 - accuracy: 0.3275 - val_loss: 4.4586 - val_accuracy: 0.1426\n",
      "Epoch 240/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6712 - accuracy: 0.3226 - val_loss: 4.4768 - val_accuracy: 0.1237\n",
      "Epoch 241/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6756 - accuracy: 0.3198 - val_loss: 4.4710 - val_accuracy: 0.1237\n",
      "Epoch 242/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6715 - accuracy: 0.3247 - val_loss: 4.4794 - val_accuracy: 0.1384\n",
      "Epoch 243/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6745 - accuracy: 0.3254 - val_loss: 4.4766 - val_accuracy: 0.1342\n",
      "Epoch 244/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6750 - accuracy: 0.3135 - val_loss: 4.4898 - val_accuracy: 0.1258\n",
      "Epoch 245/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6762 - accuracy: 0.3240 - val_loss: 4.5002 - val_accuracy: 0.1321\n",
      "Epoch 246/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6768 - accuracy: 0.3205 - val_loss: 4.4997 - val_accuracy: 0.1363\n",
      "Epoch 247/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6717 - accuracy: 0.3275 - val_loss: 4.5139 - val_accuracy: 0.1279\n",
      "Epoch 248/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6780 - accuracy: 0.3240 - val_loss: 4.5014 - val_accuracy: 0.1237\n",
      "Epoch 249/500\n",
      "1429/1429 [==============================] - 0s 125us/step - loss: 2.6779 - accuracy: 0.3163 - val_loss: 4.5260 - val_accuracy: 0.1258\n",
      "Epoch 250/500\n",
      "1429/1429 [==============================] - 0s 137us/step - loss: 2.6796 - accuracy: 0.3191 - val_loss: 4.5304 - val_accuracy: 0.1300\n",
      "Epoch 251/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6684 - accuracy: 0.3247 - val_loss: 4.5122 - val_accuracy: 0.1216\n",
      "Epoch 252/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6649 - accuracy: 0.3296 - val_loss: 4.5239 - val_accuracy: 0.1174\n",
      "Epoch 253/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 2.6724 - accuracy: 0.3261 - val_loss: 4.5150 - val_accuracy: 0.1300\n",
      "Epoch 254/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6732 - accuracy: 0.3149 - val_loss: 4.5288 - val_accuracy: 0.1321\n",
      "Epoch 255/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6670 - accuracy: 0.3233 - val_loss: 4.5327 - val_accuracy: 0.1258\n",
      "Epoch 256/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6728 - accuracy: 0.3282 - val_loss: 4.5351 - val_accuracy: 0.1216\n",
      "Epoch 257/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6611 - accuracy: 0.3289 - val_loss: 4.5276 - val_accuracy: 0.1321\n",
      "Epoch 258/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6618 - accuracy: 0.3303 - val_loss: 4.5404 - val_accuracy: 0.1216\n",
      "Epoch 259/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6647 - accuracy: 0.3268 - val_loss: 4.5513 - val_accuracy: 0.1258\n",
      "Epoch 260/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6691 - accuracy: 0.3233 - val_loss: 4.5269 - val_accuracy: 0.1384\n",
      "Epoch 261/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6630 - accuracy: 0.3261 - val_loss: 4.5391 - val_accuracy: 0.1342\n",
      "Epoch 262/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6605 - accuracy: 0.3338 - val_loss: 4.5640 - val_accuracy: 0.1300\n",
      "Epoch 263/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6584 - accuracy: 0.3275 - val_loss: 4.5534 - val_accuracy: 0.1237\n",
      "Epoch 264/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6582 - accuracy: 0.3268 - val_loss: 4.5623 - val_accuracy: 0.1237\n",
      "Epoch 265/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6582 - accuracy: 0.3212 - val_loss: 4.5442 - val_accuracy: 0.1279\n",
      "Epoch 266/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.6608 - accuracy: 0.3254 - val_loss: 4.5620 - val_accuracy: 0.1258\n",
      "Epoch 267/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6638 - accuracy: 0.3303 - val_loss: 4.5826 - val_accuracy: 0.1258\n",
      "Epoch 268/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6639 - accuracy: 0.3282 - val_loss: 4.5605 - val_accuracy: 0.1384\n",
      "Epoch 269/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6585 - accuracy: 0.3338 - val_loss: 4.5660 - val_accuracy: 0.1258\n",
      "Epoch 270/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6598 - accuracy: 0.3289 - val_loss: 4.5586 - val_accuracy: 0.1321\n",
      "Epoch 271/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.6560 - accuracy: 0.3310 - val_loss: 4.5956 - val_accuracy: 0.1342\n",
      "Epoch 272/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6603 - accuracy: 0.3254 - val_loss: 4.5968 - val_accuracy: 0.1195\n",
      "Epoch 273/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.6558 - accuracy: 0.3184 - val_loss: 4.5736 - val_accuracy: 0.1321\n",
      "Epoch 274/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6567 - accuracy: 0.3324 - val_loss: 4.6041 - val_accuracy: 0.1174\n",
      "Epoch 275/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6622 - accuracy: 0.3268 - val_loss: 4.6128 - val_accuracy: 0.1216\n",
      "Epoch 276/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6538 - accuracy: 0.3303 - val_loss: 4.6002 - val_accuracy: 0.1279\n",
      "Epoch 277/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6523 - accuracy: 0.3282 - val_loss: 4.5974 - val_accuracy: 0.1321\n",
      "Epoch 278/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6606 - accuracy: 0.3247 - val_loss: 4.6100 - val_accuracy: 0.1237\n",
      "Epoch 279/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6535 - accuracy: 0.3296 - val_loss: 4.6287 - val_accuracy: 0.1237\n",
      "Epoch 280/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.6504 - accuracy: 0.3240 - val_loss: 4.6154 - val_accuracy: 0.1174\n",
      "Epoch 281/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.6530 - accuracy: 0.3303 - val_loss: 4.6110 - val_accuracy: 0.1279\n",
      "Epoch 282/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6485 - accuracy: 0.3303 - val_loss: 4.6185 - val_accuracy: 0.1258\n",
      "Epoch 283/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6573 - accuracy: 0.3233 - val_loss: 4.6269 - val_accuracy: 0.1321\n",
      "Epoch 284/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.6532 - accuracy: 0.3289 - val_loss: 4.6404 - val_accuracy: 0.1237\n",
      "Epoch 285/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.6504 - accuracy: 0.3226 - val_loss: 4.6515 - val_accuracy: 0.1279\n",
      "Epoch 286/500\n",
      "1429/1429 [==============================] - 0s 136us/step - loss: 2.6496 - accuracy: 0.3275 - val_loss: 4.6529 - val_accuracy: 0.1279\n",
      "Epoch 287/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6487 - accuracy: 0.3240 - val_loss: 4.6408 - val_accuracy: 0.1153\n",
      "Epoch 288/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.6496 - accuracy: 0.3205 - val_loss: 4.6419 - val_accuracy: 0.1237\n",
      "Epoch 289/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6457 - accuracy: 0.3338 - val_loss: 4.6458 - val_accuracy: 0.1279\n",
      "Epoch 290/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6478 - accuracy: 0.3296 - val_loss: 4.6730 - val_accuracy: 0.1195\n",
      "Epoch 291/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6481 - accuracy: 0.3317 - val_loss: 4.6613 - val_accuracy: 0.1237\n",
      "Epoch 292/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6484 - accuracy: 0.3317 - val_loss: 4.6645 - val_accuracy: 0.1237\n",
      "Epoch 293/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.6467 - accuracy: 0.3198 - val_loss: 4.6717 - val_accuracy: 0.1237\n",
      "Epoch 294/500\n",
      "1429/1429 [==============================] - 0s 125us/step - loss: 2.6444 - accuracy: 0.3324 - val_loss: 4.6788 - val_accuracy: 0.1237\n",
      "Epoch 295/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6442 - accuracy: 0.3331 - val_loss: 4.6981 - val_accuracy: 0.1258\n",
      "Epoch 296/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6429 - accuracy: 0.3233 - val_loss: 4.7085 - val_accuracy: 0.1048\n",
      "Epoch 297/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.6419 - accuracy: 0.3310 - val_loss: 4.6723 - val_accuracy: 0.1216\n",
      "Epoch 298/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.6423 - accuracy: 0.3268 - val_loss: 4.6809 - val_accuracy: 0.1153\n",
      "Epoch 299/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6415 - accuracy: 0.3303 - val_loss: 4.6898 - val_accuracy: 0.1279\n",
      "Epoch 300/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.6432 - accuracy: 0.3366 - val_loss: 4.6847 - val_accuracy: 0.1300\n",
      "Epoch 301/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6423 - accuracy: 0.3352 - val_loss: 4.6885 - val_accuracy: 0.1258\n",
      "Epoch 302/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6443 - accuracy: 0.3268 - val_loss: 4.6884 - val_accuracy: 0.1237\n",
      "Epoch 303/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6485 - accuracy: 0.3352 - val_loss: 4.7074 - val_accuracy: 0.1237\n",
      "Epoch 304/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6427 - accuracy: 0.3331 - val_loss: 4.6998 - val_accuracy: 0.1237\n",
      "Epoch 305/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6377 - accuracy: 0.3338 - val_loss: 4.7006 - val_accuracy: 0.1153\n",
      "Epoch 306/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6415 - accuracy: 0.3303 - val_loss: 4.7106 - val_accuracy: 0.1279\n",
      "Epoch 307/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.6415 - accuracy: 0.3380 - val_loss: 4.7174 - val_accuracy: 0.1174\n",
      "Epoch 308/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6375 - accuracy: 0.3191 - val_loss: 4.7157 - val_accuracy: 0.1279\n",
      "Epoch 309/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6382 - accuracy: 0.3345 - val_loss: 4.7008 - val_accuracy: 0.1321\n",
      "Epoch 310/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6502 - accuracy: 0.3212 - val_loss: 4.7403 - val_accuracy: 0.1153\n",
      "Epoch 311/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.6572 - accuracy: 0.3345 - val_loss: 4.7216 - val_accuracy: 0.1279\n",
      "Epoch 312/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6377 - accuracy: 0.3324 - val_loss: 4.7203 - val_accuracy: 0.1321\n",
      "Epoch 313/500\n",
      "1429/1429 [==============================] - 0s 122us/step - loss: 2.6369 - accuracy: 0.3338 - val_loss: 4.7369 - val_accuracy: 0.1153\n",
      "Epoch 314/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6384 - accuracy: 0.3247 - val_loss: 4.7382 - val_accuracy: 0.1258\n",
      "Epoch 315/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6368 - accuracy: 0.3310 - val_loss: 4.7329 - val_accuracy: 0.1321\n",
      "Epoch 316/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6345 - accuracy: 0.3352 - val_loss: 4.7406 - val_accuracy: 0.1258\n",
      "Epoch 317/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.6315 - accuracy: 0.3324 - val_loss: 4.7403 - val_accuracy: 0.1090\n",
      "Epoch 318/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.6316 - accuracy: 0.3310 - val_loss: 4.7596 - val_accuracy: 0.1174\n",
      "Epoch 319/500\n",
      "1429/1429 [==============================] - 0s 123us/step - loss: 2.6422 - accuracy: 0.3226 - val_loss: 4.7507 - val_accuracy: 0.1195\n",
      "Epoch 320/500\n",
      "1429/1429 [==============================] - 0s 115us/step - loss: 2.6381 - accuracy: 0.3240 - val_loss: 4.7656 - val_accuracy: 0.1279\n",
      "Epoch 321/500\n",
      "1429/1429 [==============================] - 0s 132us/step - loss: 2.6387 - accuracy: 0.3338 - val_loss: 4.7667 - val_accuracy: 0.1300\n",
      "Epoch 322/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.6323 - accuracy: 0.3191 - val_loss: 4.7681 - val_accuracy: 0.1237\n",
      "Epoch 323/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.6353 - accuracy: 0.3359 - val_loss: 4.7869 - val_accuracy: 0.1279\n",
      "Epoch 324/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6358 - accuracy: 0.3352 - val_loss: 4.7694 - val_accuracy: 0.1153\n",
      "Epoch 325/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6379 - accuracy: 0.3268 - val_loss: 4.7945 - val_accuracy: 0.1090\n",
      "Epoch 326/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6340 - accuracy: 0.3254 - val_loss: 4.7939 - val_accuracy: 0.1216\n",
      "Epoch 327/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6316 - accuracy: 0.3338 - val_loss: 4.7863 - val_accuracy: 0.1216\n",
      "Epoch 328/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6473 - accuracy: 0.3268 - val_loss: 4.7956 - val_accuracy: 0.1216\n",
      "Epoch 329/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.6401 - accuracy: 0.3240 - val_loss: 4.7962 - val_accuracy: 0.1279\n",
      "Epoch 330/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.6483 - accuracy: 0.3310 - val_loss: 4.8066 - val_accuracy: 0.1279\n",
      "Epoch 331/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6283 - accuracy: 0.3380 - val_loss: 4.8018 - val_accuracy: 0.1216\n",
      "Epoch 332/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6471 - accuracy: 0.3247 - val_loss: 4.8259 - val_accuracy: 0.1258\n",
      "Epoch 333/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6294 - accuracy: 0.3310 - val_loss: 4.8061 - val_accuracy: 0.1174\n",
      "Epoch 334/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6472 - accuracy: 0.3429 - val_loss: 4.8147 - val_accuracy: 0.1279\n",
      "Epoch 335/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6353 - accuracy: 0.3261 - val_loss: 4.8082 - val_accuracy: 0.1279\n",
      "Epoch 336/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6368 - accuracy: 0.3338 - val_loss: 4.8295 - val_accuracy: 0.1237\n",
      "Epoch 337/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6285 - accuracy: 0.3219 - val_loss: 4.8305 - val_accuracy: 0.1216\n",
      "Epoch 338/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6241 - accuracy: 0.3366 - val_loss: 4.8323 - val_accuracy: 0.1258\n",
      "Epoch 339/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6319 - accuracy: 0.3331 - val_loss: 4.8380 - val_accuracy: 0.1216\n",
      "Epoch 340/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6254 - accuracy: 0.3373 - val_loss: 4.8236 - val_accuracy: 0.1279\n",
      "Epoch 341/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6294 - accuracy: 0.3331 - val_loss: 4.8441 - val_accuracy: 0.1174\n",
      "Epoch 342/500\n",
      "1429/1429 [==============================] - 0s 93us/step - loss: 2.6254 - accuracy: 0.3338 - val_loss: 4.8400 - val_accuracy: 0.1237\n",
      "Epoch 343/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.6226 - accuracy: 0.3310 - val_loss: 4.8596 - val_accuracy: 0.1153\n",
      "Epoch 344/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6229 - accuracy: 0.3289 - val_loss: 4.8426 - val_accuracy: 0.1216\n",
      "Epoch 345/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6273 - accuracy: 0.3359 - val_loss: 4.8466 - val_accuracy: 0.1258\n",
      "Epoch 346/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6196 - accuracy: 0.3296 - val_loss: 4.8424 - val_accuracy: 0.1216\n",
      "Epoch 347/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6242 - accuracy: 0.3352 - val_loss: 4.8636 - val_accuracy: 0.1111\n",
      "Epoch 348/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6269 - accuracy: 0.3212 - val_loss: 4.8772 - val_accuracy: 0.1153\n",
      "Epoch 349/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6224 - accuracy: 0.3338 - val_loss: 4.8527 - val_accuracy: 0.1216\n",
      "Epoch 350/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6172 - accuracy: 0.3303 - val_loss: 4.8675 - val_accuracy: 0.1216\n",
      "Epoch 351/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6171 - accuracy: 0.3373 - val_loss: 4.8975 - val_accuracy: 0.1027\n",
      "Epoch 352/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6265 - accuracy: 0.3289 - val_loss: 4.8601 - val_accuracy: 0.1216\n",
      "Epoch 353/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6223 - accuracy: 0.3338 - val_loss: 4.8951 - val_accuracy: 0.1153\n",
      "Epoch 354/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6251 - accuracy: 0.3338 - val_loss: 4.8799 - val_accuracy: 0.1237\n",
      "Epoch 355/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.6245 - accuracy: 0.3408 - val_loss: 4.8808 - val_accuracy: 0.1237\n",
      "Epoch 356/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6165 - accuracy: 0.3408 - val_loss: 4.8745 - val_accuracy: 0.1153\n",
      "Epoch 357/500\n",
      "1429/1429 [==============================] - 0s 140us/step - loss: 2.6192 - accuracy: 0.3296 - val_loss: 4.8862 - val_accuracy: 0.1216\n",
      "Epoch 358/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6175 - accuracy: 0.3366 - val_loss: 4.8895 - val_accuracy: 0.1216\n",
      "Epoch 359/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6198 - accuracy: 0.3310 - val_loss: 4.9004 - val_accuracy: 0.1258\n",
      "Epoch 360/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6233 - accuracy: 0.3366 - val_loss: 4.9302 - val_accuracy: 0.1132\n",
      "Epoch 361/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6208 - accuracy: 0.3373 - val_loss: 4.9017 - val_accuracy: 0.1216\n",
      "Epoch 362/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6165 - accuracy: 0.3373 - val_loss: 4.9314 - val_accuracy: 0.1258\n",
      "Epoch 363/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6210 - accuracy: 0.3359 - val_loss: 4.9109 - val_accuracy: 0.1174\n",
      "Epoch 364/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6137 - accuracy: 0.3317 - val_loss: 4.9233 - val_accuracy: 0.1153\n",
      "Epoch 365/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6145 - accuracy: 0.3296 - val_loss: 4.9254 - val_accuracy: 0.1153\n",
      "Epoch 366/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6149 - accuracy: 0.3422 - val_loss: 4.9172 - val_accuracy: 0.1174\n",
      "Epoch 367/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.6180 - accuracy: 0.3275 - val_loss: 4.9409 - val_accuracy: 0.1300\n",
      "Epoch 368/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.6142 - accuracy: 0.3366 - val_loss: 4.9348 - val_accuracy: 0.1174\n",
      "Epoch 369/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6105 - accuracy: 0.3359 - val_loss: 4.9464 - val_accuracy: 0.1195\n",
      "Epoch 370/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.6174 - accuracy: 0.3366 - val_loss: 4.9307 - val_accuracy: 0.1195\n",
      "Epoch 371/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6114 - accuracy: 0.3408 - val_loss: 4.9472 - val_accuracy: 0.1258\n",
      "Epoch 372/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.6182 - accuracy: 0.3352 - val_loss: 4.9408 - val_accuracy: 0.1279\n",
      "Epoch 373/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6117 - accuracy: 0.3296 - val_loss: 4.9380 - val_accuracy: 0.1237\n",
      "Epoch 374/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6130 - accuracy: 0.3310 - val_loss: 4.9493 - val_accuracy: 0.1258\n",
      "Epoch 375/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6134 - accuracy: 0.3303 - val_loss: 4.9514 - val_accuracy: 0.1195\n",
      "Epoch 376/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6097 - accuracy: 0.3401 - val_loss: 4.9622 - val_accuracy: 0.1195\n",
      "Epoch 377/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6116 - accuracy: 0.3331 - val_loss: 4.9710 - val_accuracy: 0.1132\n",
      "Epoch 378/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6094 - accuracy: 0.3422 - val_loss: 4.9747 - val_accuracy: 0.1111\n",
      "Epoch 379/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6093 - accuracy: 0.3401 - val_loss: 4.9581 - val_accuracy: 0.1237\n",
      "Epoch 380/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6091 - accuracy: 0.3317 - val_loss: 4.9737 - val_accuracy: 0.1195\n",
      "Epoch 381/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6181 - accuracy: 0.3331 - val_loss: 4.9812 - val_accuracy: 0.1258\n",
      "Epoch 382/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6106 - accuracy: 0.3317 - val_loss: 4.9779 - val_accuracy: 0.1321\n",
      "Epoch 383/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6075 - accuracy: 0.3310 - val_loss: 5.0165 - val_accuracy: 0.1153\n",
      "Epoch 384/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6153 - accuracy: 0.3338 - val_loss: 4.9738 - val_accuracy: 0.1321\n",
      "Epoch 385/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.6086 - accuracy: 0.3380 - val_loss: 4.9886 - val_accuracy: 0.1258\n",
      "Epoch 386/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.6118 - accuracy: 0.3352 - val_loss: 5.0010 - val_accuracy: 0.1132\n",
      "Epoch 387/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.6060 - accuracy: 0.3303 - val_loss: 5.0131 - val_accuracy: 0.1111\n",
      "Epoch 388/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6203 - accuracy: 0.3499 - val_loss: 5.0055 - val_accuracy: 0.1258\n",
      "Epoch 389/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6288 - accuracy: 0.3289 - val_loss: 5.0090 - val_accuracy: 0.1174\n",
      "Epoch 390/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6215 - accuracy: 0.3380 - val_loss: 5.0067 - val_accuracy: 0.1174\n",
      "Epoch 391/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6074 - accuracy: 0.3352 - val_loss: 5.0071 - val_accuracy: 0.1153\n",
      "Epoch 392/500\n",
      "1429/1429 [==============================] - 0s 126us/step - loss: 2.6004 - accuracy: 0.3373 - val_loss: 5.0081 - val_accuracy: 0.1216\n",
      "Epoch 393/500\n",
      "1429/1429 [==============================] - 0s 121us/step - loss: 2.6026 - accuracy: 0.3366 - val_loss: 5.0062 - val_accuracy: 0.1258\n",
      "Epoch 394/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6125 - accuracy: 0.3408 - val_loss: 5.0422 - val_accuracy: 0.1174\n",
      "Epoch 395/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6101 - accuracy: 0.3394 - val_loss: 5.0331 - val_accuracy: 0.1195\n",
      "Epoch 396/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6110 - accuracy: 0.3345 - val_loss: 5.0186 - val_accuracy: 0.1237\n",
      "Epoch 397/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6190 - accuracy: 0.3296 - val_loss: 5.0228 - val_accuracy: 0.1258\n",
      "Epoch 398/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5998 - accuracy: 0.3464 - val_loss: 5.0492 - val_accuracy: 0.1111\n",
      "Epoch 399/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6079 - accuracy: 0.3457 - val_loss: 5.0329 - val_accuracy: 0.1132\n",
      "Epoch 400/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.6127 - accuracy: 0.3415 - val_loss: 5.0393 - val_accuracy: 0.1216\n",
      "Epoch 401/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6052 - accuracy: 0.3324 - val_loss: 5.0539 - val_accuracy: 0.1132\n",
      "Epoch 402/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6019 - accuracy: 0.3317 - val_loss: 5.0565 - val_accuracy: 0.1153\n",
      "Epoch 403/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6024 - accuracy: 0.3359 - val_loss: 5.0802 - val_accuracy: 0.1153\n",
      "Epoch 404/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6067 - accuracy: 0.3366 - val_loss: 5.0593 - val_accuracy: 0.1090\n",
      "Epoch 405/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6046 - accuracy: 0.3303 - val_loss: 5.0848 - val_accuracy: 0.1132\n",
      "Epoch 406/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6035 - accuracy: 0.3247 - val_loss: 5.0753 - val_accuracy: 0.1216\n",
      "Epoch 407/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6022 - accuracy: 0.3359 - val_loss: 5.0674 - val_accuracy: 0.1216\n",
      "Epoch 408/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6011 - accuracy: 0.3450 - val_loss: 5.0708 - val_accuracy: 0.1132\n",
      "Epoch 409/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5974 - accuracy: 0.3359 - val_loss: 5.0793 - val_accuracy: 0.1132\n",
      "Epoch 410/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6010 - accuracy: 0.3352 - val_loss: 5.0749 - val_accuracy: 0.1195\n",
      "Epoch 411/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5989 - accuracy: 0.3317 - val_loss: 5.0931 - val_accuracy: 0.1090\n",
      "Epoch 412/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5970 - accuracy: 0.3296 - val_loss: 5.0942 - val_accuracy: 0.1195\n",
      "Epoch 413/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5996 - accuracy: 0.3380 - val_loss: 5.1321 - val_accuracy: 0.1111\n",
      "Epoch 414/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6036 - accuracy: 0.3422 - val_loss: 5.1018 - val_accuracy: 0.1279\n",
      "Epoch 415/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.5971 - accuracy: 0.3394 - val_loss: 5.1048 - val_accuracy: 0.1195\n",
      "Epoch 416/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.5966 - accuracy: 0.3366 - val_loss: 5.1155 - val_accuracy: 0.1279\n",
      "Epoch 417/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.5949 - accuracy: 0.3443 - val_loss: 5.1052 - val_accuracy: 0.1153\n",
      "Epoch 418/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5950 - accuracy: 0.3331 - val_loss: 5.1180 - val_accuracy: 0.1195\n",
      "Epoch 419/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6039 - accuracy: 0.3310 - val_loss: 5.1146 - val_accuracy: 0.1174\n",
      "Epoch 420/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5958 - accuracy: 0.3408 - val_loss: 5.1193 - val_accuracy: 0.1132\n",
      "Epoch 421/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5907 - accuracy: 0.3443 - val_loss: 5.1259 - val_accuracy: 0.1111\n",
      "Epoch 422/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5938 - accuracy: 0.3380 - val_loss: 5.1026 - val_accuracy: 0.1174\n",
      "Epoch 423/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5901 - accuracy: 0.3422 - val_loss: 5.1481 - val_accuracy: 0.1153\n",
      "Epoch 424/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5946 - accuracy: 0.3331 - val_loss: 5.1286 - val_accuracy: 0.1195\n",
      "Epoch 425/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.5992 - accuracy: 0.3366 - val_loss: 5.1373 - val_accuracy: 0.1111\n",
      "Epoch 426/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5945 - accuracy: 0.3429 - val_loss: 5.1826 - val_accuracy: 0.1153\n",
      "Epoch 427/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5970 - accuracy: 0.3268 - val_loss: 5.1735 - val_accuracy: 0.1132\n",
      "Epoch 428/500\n",
      "1429/1429 [==============================] - 0s 142us/step - loss: 2.5941 - accuracy: 0.3415 - val_loss: 5.1443 - val_accuracy: 0.1111\n",
      "Epoch 429/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5896 - accuracy: 0.3331 - val_loss: 5.1461 - val_accuracy: 0.1195\n",
      "Epoch 430/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5931 - accuracy: 0.3422 - val_loss: 5.1699 - val_accuracy: 0.1132\n",
      "Epoch 431/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.5872 - accuracy: 0.3338 - val_loss: 5.1506 - val_accuracy: 0.1153\n",
      "Epoch 432/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.5882 - accuracy: 0.3366 - val_loss: 5.1812 - val_accuracy: 0.1069\n",
      "Epoch 433/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.5916 - accuracy: 0.3436 - val_loss: 5.1724 - val_accuracy: 0.1216\n",
      "Epoch 434/500\n",
      "1429/1429 [==============================] - 0s 120us/step - loss: 2.5920 - accuracy: 0.3275 - val_loss: 5.1745 - val_accuracy: 0.1111\n",
      "Epoch 435/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.5893 - accuracy: 0.3436 - val_loss: 5.1732 - val_accuracy: 0.1174\n",
      "Epoch 436/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.5913 - accuracy: 0.3331 - val_loss: 5.1620 - val_accuracy: 0.1174\n",
      "Epoch 437/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5871 - accuracy: 0.3359 - val_loss: 5.2078 - val_accuracy: 0.1090\n",
      "Epoch 438/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5951 - accuracy: 0.3359 - val_loss: 5.1929 - val_accuracy: 0.1069\n",
      "Epoch 439/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5879 - accuracy: 0.3485 - val_loss: 5.1931 - val_accuracy: 0.1048\n",
      "Epoch 440/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.5867 - accuracy: 0.3317 - val_loss: 5.1868 - val_accuracy: 0.1195\n",
      "Epoch 441/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5849 - accuracy: 0.3408 - val_loss: 5.1986 - val_accuracy: 0.1111\n",
      "Epoch 442/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.5869 - accuracy: 0.3387 - val_loss: 5.2088 - val_accuracy: 0.1216\n",
      "Epoch 443/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5892 - accuracy: 0.3485 - val_loss: 5.1926 - val_accuracy: 0.1174\n",
      "Epoch 444/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.5872 - accuracy: 0.3478 - val_loss: 5.1858 - val_accuracy: 0.1195\n",
      "Epoch 445/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.5930 - accuracy: 0.3380 - val_loss: 5.1963 - val_accuracy: 0.1153\n",
      "Epoch 446/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5892 - accuracy: 0.3366 - val_loss: 5.1970 - val_accuracy: 0.1279\n",
      "Epoch 447/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.6047 - accuracy: 0.3387 - val_loss: 5.2137 - val_accuracy: 0.1069\n",
      "Epoch 448/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5888 - accuracy: 0.3443 - val_loss: 5.2099 - val_accuracy: 0.1216\n",
      "Epoch 449/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.5830 - accuracy: 0.3450 - val_loss: 5.1984 - val_accuracy: 0.1132\n",
      "Epoch 450/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5962 - accuracy: 0.3443 - val_loss: 5.2046 - val_accuracy: 0.1342\n",
      "Epoch 451/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.6068 - accuracy: 0.3352 - val_loss: 5.2171 - val_accuracy: 0.1174\n",
      "Epoch 452/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5847 - accuracy: 0.3457 - val_loss: 5.2316 - val_accuracy: 0.1195\n",
      "Epoch 453/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.5824 - accuracy: 0.3415 - val_loss: 5.2301 - val_accuracy: 0.1153\n",
      "Epoch 454/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5874 - accuracy: 0.3408 - val_loss: 5.2320 - val_accuracy: 0.1132\n",
      "Epoch 455/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5867 - accuracy: 0.3394 - val_loss: 5.2113 - val_accuracy: 0.1132\n",
      "Epoch 456/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5843 - accuracy: 0.3478 - val_loss: 5.2725 - val_accuracy: 0.1237\n",
      "Epoch 457/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5807 - accuracy: 0.3373 - val_loss: 5.2392 - val_accuracy: 0.1237\n",
      "Epoch 458/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.5854 - accuracy: 0.3422 - val_loss: 5.2622 - val_accuracy: 0.1069\n",
      "Epoch 459/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5835 - accuracy: 0.3317 - val_loss: 5.2636 - val_accuracy: 0.1153\n",
      "Epoch 460/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.5815 - accuracy: 0.3471 - val_loss: 5.2499 - val_accuracy: 0.1216\n",
      "Epoch 461/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5844 - accuracy: 0.3569 - val_loss: 5.2430 - val_accuracy: 0.1195\n",
      "Epoch 462/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.5809 - accuracy: 0.3415 - val_loss: 5.2686 - val_accuracy: 0.1195\n",
      "Epoch 463/500\n",
      "1429/1429 [==============================] - 0s 136us/step - loss: 2.5836 - accuracy: 0.3359 - val_loss: 5.2600 - val_accuracy: 0.1174\n",
      "Epoch 464/500\n",
      "1429/1429 [==============================] - 0s 129us/step - loss: 2.5784 - accuracy: 0.3422 - val_loss: 5.2666 - val_accuracy: 0.1132\n",
      "Epoch 465/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.5891 - accuracy: 0.3366 - val_loss: 5.2521 - val_accuracy: 0.1174\n",
      "Epoch 466/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5774 - accuracy: 0.3492 - val_loss: 5.2647 - val_accuracy: 0.1132\n",
      "Epoch 467/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5780 - accuracy: 0.3401 - val_loss: 5.2980 - val_accuracy: 0.1069\n",
      "Epoch 468/500\n",
      "1429/1429 [==============================] - 0s 90us/step - loss: 2.5801 - accuracy: 0.3394 - val_loss: 5.2973 - val_accuracy: 0.1069\n",
      "Epoch 469/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.5793 - accuracy: 0.3394 - val_loss: 5.2744 - val_accuracy: 0.1216\n",
      "Epoch 470/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.5779 - accuracy: 0.3478 - val_loss: 5.2951 - val_accuracy: 0.1111\n",
      "Epoch 471/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.5806 - accuracy: 0.3415 - val_loss: 5.2878 - val_accuracy: 0.1132\n",
      "Epoch 472/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5783 - accuracy: 0.3429 - val_loss: 5.2958 - val_accuracy: 0.1111\n",
      "Epoch 473/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5731 - accuracy: 0.3457 - val_loss: 5.3045 - val_accuracy: 0.1216\n",
      "Epoch 474/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5792 - accuracy: 0.3359 - val_loss: 5.2923 - val_accuracy: 0.1132\n",
      "Epoch 475/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5748 - accuracy: 0.3478 - val_loss: 5.3133 - val_accuracy: 0.1216\n",
      "Epoch 476/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5781 - accuracy: 0.3436 - val_loss: 5.3053 - val_accuracy: 0.1237\n",
      "Epoch 477/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5739 - accuracy: 0.3408 - val_loss: 5.3025 - val_accuracy: 0.1174\n",
      "Epoch 478/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.5788 - accuracy: 0.3408 - val_loss: 5.3235 - val_accuracy: 0.1174\n",
      "Epoch 479/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5813 - accuracy: 0.3387 - val_loss: 5.3162 - val_accuracy: 0.1195\n",
      "Epoch 480/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.5807 - accuracy: 0.3457 - val_loss: 5.3198 - val_accuracy: 0.1048\n",
      "Epoch 481/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5796 - accuracy: 0.3380 - val_loss: 5.3367 - val_accuracy: 0.1090\n",
      "Epoch 482/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.5850 - accuracy: 0.3380 - val_loss: 5.3323 - val_accuracy: 0.1027\n",
      "Epoch 483/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.5847 - accuracy: 0.3373 - val_loss: 5.3412 - val_accuracy: 0.1216\n",
      "Epoch 484/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5882 - accuracy: 0.3415 - val_loss: 5.3622 - val_accuracy: 0.1174\n",
      "Epoch 485/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5760 - accuracy: 0.3485 - val_loss: 5.3433 - val_accuracy: 0.1090\n",
      "Epoch 486/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5768 - accuracy: 0.3366 - val_loss: 5.3706 - val_accuracy: 0.1090\n",
      "Epoch 487/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.5765 - accuracy: 0.3429 - val_loss: 5.3379 - val_accuracy: 0.1174\n",
      "Epoch 488/500\n",
      "1429/1429 [==============================] - 0s 90us/step - loss: 2.5837 - accuracy: 0.3345 - val_loss: 5.3505 - val_accuracy: 0.1258\n",
      "Epoch 489/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5684 - accuracy: 0.3513 - val_loss: 5.3607 - val_accuracy: 0.1048\n",
      "Epoch 490/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5696 - accuracy: 0.3380 - val_loss: 5.3881 - val_accuracy: 0.1111\n",
      "Epoch 491/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.5748 - accuracy: 0.3373 - val_loss: 5.3657 - val_accuracy: 0.1153\n",
      "Epoch 492/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.5716 - accuracy: 0.3450 - val_loss: 5.3744 - val_accuracy: 0.1174\n",
      "Epoch 493/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 92us/step - loss: 2.5712 - accuracy: 0.3478 - val_loss: 5.3567 - val_accuracy: 0.1216\n",
      "Epoch 494/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5714 - accuracy: 0.3443 - val_loss: 5.3806 - val_accuracy: 0.1069\n",
      "Epoch 495/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5688 - accuracy: 0.3408 - val_loss: 5.3857 - val_accuracy: 0.1132\n",
      "Epoch 496/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5797 - accuracy: 0.3331 - val_loss: 5.3693 - val_accuracy: 0.1111\n",
      "Epoch 497/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.5685 - accuracy: 0.3380 - val_loss: 5.3794 - val_accuracy: 0.1174\n",
      "Epoch 498/500\n",
      "1429/1429 [==============================] - 0s 141us/step - loss: 2.5675 - accuracy: 0.3450 - val_loss: 5.3918 - val_accuracy: 0.1090\n",
      "Epoch 499/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5768 - accuracy: 0.3387 - val_loss: 5.3784 - val_accuracy: 0.1006\n",
      "Epoch 500/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5700 - accuracy: 0.3457 - val_loss: 5.4082 - val_accuracy: 0.0964\n",
      "Train on 1429 samples, validate on 477 samples\n",
      "Epoch 1/500\n",
      "1429/1429 [==============================] - 0s 131us/step - loss: 3.1705 - accuracy: 0.2918 - val_loss: 3.5877 - val_accuracy: 0.2474\n",
      "Epoch 2/500\n",
      "1429/1429 [==============================] - 0s 115us/step - loss: 3.1209 - accuracy: 0.2995 - val_loss: 3.6160 - val_accuracy: 0.2390\n",
      "Epoch 3/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 3.0901 - accuracy: 0.2974 - val_loss: 3.6339 - val_accuracy: 0.2327\n",
      "Epoch 4/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 3.0751 - accuracy: 0.2918 - val_loss: 3.6703 - val_accuracy: 0.2138\n",
      "Epoch 5/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 3.0607 - accuracy: 0.2918 - val_loss: 3.6811 - val_accuracy: 0.2013\n",
      "Epoch 6/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 3.0438 - accuracy: 0.2869 - val_loss: 3.6701 - val_accuracy: 0.2201\n",
      "Epoch 7/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 3.0292 - accuracy: 0.2855 - val_loss: 3.7076 - val_accuracy: 0.2075\n",
      "Epoch 8/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 3.0170 - accuracy: 0.2841 - val_loss: 3.6875 - val_accuracy: 0.2096\n",
      "Epoch 9/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 3.0111 - accuracy: 0.2974 - val_loss: 3.7139 - val_accuracy: 0.2034\n",
      "Epoch 10/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 3.0009 - accuracy: 0.2890 - val_loss: 3.7343 - val_accuracy: 0.2034\n",
      "Epoch 11/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.9887 - accuracy: 0.2988 - val_loss: 3.7359 - val_accuracy: 0.2075\n",
      "Epoch 12/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.9794 - accuracy: 0.2918 - val_loss: 3.7200 - val_accuracy: 0.1929\n",
      "Epoch 13/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.9748 - accuracy: 0.2939 - val_loss: 3.7478 - val_accuracy: 0.1866\n",
      "Epoch 14/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.9678 - accuracy: 0.2967 - val_loss: 3.7597 - val_accuracy: 0.2034\n",
      "Epoch 15/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.9616 - accuracy: 0.2953 - val_loss: 3.7603 - val_accuracy: 0.1845\n",
      "Epoch 16/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.9540 - accuracy: 0.2974 - val_loss: 3.7708 - val_accuracy: 0.1824\n",
      "Epoch 17/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.9536 - accuracy: 0.3002 - val_loss: 3.7788 - val_accuracy: 0.1908\n",
      "Epoch 18/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.9385 - accuracy: 0.2883 - val_loss: 3.7848 - val_accuracy: 0.1887\n",
      "Epoch 19/500\n",
      "1429/1429 [==============================] - 0s 115us/step - loss: 2.9384 - accuracy: 0.2995 - val_loss: 3.7871 - val_accuracy: 0.1845\n",
      "Epoch 20/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.9271 - accuracy: 0.3037 - val_loss: 3.8129 - val_accuracy: 0.1719\n",
      "Epoch 21/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.9246 - accuracy: 0.3037 - val_loss: 3.8115 - val_accuracy: 0.1803\n",
      "Epoch 22/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.9218 - accuracy: 0.2960 - val_loss: 3.8069 - val_accuracy: 0.1845\n",
      "Epoch 23/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.9148 - accuracy: 0.2995 - val_loss: 3.8076 - val_accuracy: 0.1761\n",
      "Epoch 24/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.9068 - accuracy: 0.3177 - val_loss: 3.8341 - val_accuracy: 0.1908\n",
      "Epoch 25/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.9036 - accuracy: 0.2897 - val_loss: 3.8280 - val_accuracy: 0.1803\n",
      "Epoch 26/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.9042 - accuracy: 0.2918 - val_loss: 3.8380 - val_accuracy: 0.1719\n",
      "Epoch 27/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.9068 - accuracy: 0.2988 - val_loss: 3.8436 - val_accuracy: 0.1761\n",
      "Epoch 28/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.8899 - accuracy: 0.3114 - val_loss: 3.8566 - val_accuracy: 0.1824\n",
      "Epoch 29/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.8893 - accuracy: 0.3023 - val_loss: 3.8409 - val_accuracy: 0.1656\n",
      "Epoch 30/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.8853 - accuracy: 0.3065 - val_loss: 3.8562 - val_accuracy: 0.1656\n",
      "Epoch 31/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.8886 - accuracy: 0.3023 - val_loss: 3.8665 - val_accuracy: 0.1593\n",
      "Epoch 32/500\n",
      "1429/1429 [==============================] - 0s 136us/step - loss: 2.8799 - accuracy: 0.3030 - val_loss: 3.8647 - val_accuracy: 0.1761\n",
      "Epoch 33/500\n",
      "1429/1429 [==============================] - 0s 128us/step - loss: 2.8770 - accuracy: 0.2967 - val_loss: 3.8770 - val_accuracy: 0.1635\n",
      "Epoch 34/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.8743 - accuracy: 0.3002 - val_loss: 3.8870 - val_accuracy: 0.1572\n",
      "Epoch 35/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.8693 - accuracy: 0.3086 - val_loss: 3.8804 - val_accuracy: 0.1677\n",
      "Epoch 36/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.8642 - accuracy: 0.2995 - val_loss: 3.8954 - val_accuracy: 0.1635\n",
      "Epoch 37/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.8626 - accuracy: 0.3072 - val_loss: 3.9194 - val_accuracy: 0.1677\n",
      "Epoch 38/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.8633 - accuracy: 0.2988 - val_loss: 3.9011 - val_accuracy: 0.1656\n",
      "Epoch 39/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.8615 - accuracy: 0.2932 - val_loss: 3.9150 - val_accuracy: 0.1635\n",
      "Epoch 40/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.8508 - accuracy: 0.3023 - val_loss: 3.8991 - val_accuracy: 0.1572\n",
      "Epoch 41/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.8496 - accuracy: 0.3093 - val_loss: 3.9274 - val_accuracy: 0.1635\n",
      "Epoch 42/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.8491 - accuracy: 0.3058 - val_loss: 3.9337 - val_accuracy: 0.1677\n",
      "Epoch 43/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.8439 - accuracy: 0.3058 - val_loss: 3.9235 - val_accuracy: 0.1614\n",
      "Epoch 44/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.8478 - accuracy: 0.3051 - val_loss: 3.9287 - val_accuracy: 0.1635\n",
      "Epoch 45/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.8416 - accuracy: 0.3037 - val_loss: 3.9274 - val_accuracy: 0.1530\n",
      "Epoch 46/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.8370 - accuracy: 0.3128 - val_loss: 3.9406 - val_accuracy: 0.1593\n",
      "Epoch 47/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.8324 - accuracy: 0.3100 - val_loss: 3.9353 - val_accuracy: 0.1509\n",
      "Epoch 48/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.8364 - accuracy: 0.3079 - val_loss: 3.9560 - val_accuracy: 0.1572\n",
      "Epoch 49/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.8342 - accuracy: 0.3065 - val_loss: 3.9428 - val_accuracy: 0.1614\n",
      "Epoch 50/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.8323 - accuracy: 0.2995 - val_loss: 3.9520 - val_accuracy: 0.1572\n",
      "Epoch 51/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.8307 - accuracy: 0.3051 - val_loss: 3.9616 - val_accuracy: 0.1572\n",
      "Epoch 52/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.8290 - accuracy: 0.3044 - val_loss: 3.9793 - val_accuracy: 0.1488\n",
      "Epoch 53/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.8220 - accuracy: 0.3121 - val_loss: 3.9628 - val_accuracy: 0.1488\n",
      "Epoch 54/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.8188 - accuracy: 0.3072 - val_loss: 3.9638 - val_accuracy: 0.1593\n",
      "Epoch 55/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.8227 - accuracy: 0.3142 - val_loss: 3.9817 - val_accuracy: 0.1551\n",
      "Epoch 56/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.8151 - accuracy: 0.3065 - val_loss: 3.9787 - val_accuracy: 0.1426\n",
      "Epoch 57/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.8105 - accuracy: 0.3128 - val_loss: 4.0014 - val_accuracy: 0.1468\n",
      "Epoch 58/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.8122 - accuracy: 0.3135 - val_loss: 3.9803 - val_accuracy: 0.1447\n",
      "Epoch 59/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.8142 - accuracy: 0.3177 - val_loss: 3.9930 - val_accuracy: 0.1488\n",
      "Epoch 60/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.8235 - accuracy: 0.3156 - val_loss: 3.9763 - val_accuracy: 0.1782\n",
      "Epoch 61/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.8207 - accuracy: 0.3051 - val_loss: 4.0253 - val_accuracy: 0.1321\n",
      "Epoch 62/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.8295 - accuracy: 0.3093 - val_loss: 4.0084 - val_accuracy: 0.1488\n",
      "Epoch 63/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.8080 - accuracy: 0.3135 - val_loss: 4.0071 - val_accuracy: 0.1488\n",
      "Epoch 64/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.8180 - accuracy: 0.3058 - val_loss: 4.0216 - val_accuracy: 0.1384\n",
      "Epoch 65/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.8092 - accuracy: 0.3086 - val_loss: 4.0230 - val_accuracy: 0.1363\n",
      "Epoch 66/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.8008 - accuracy: 0.3170 - val_loss: 4.0048 - val_accuracy: 0.1551\n",
      "Epoch 67/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.7990 - accuracy: 0.3114 - val_loss: 4.0273 - val_accuracy: 0.1593\n",
      "Epoch 68/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.7947 - accuracy: 0.3156 - val_loss: 4.0224 - val_accuracy: 0.1447\n",
      "Epoch 69/500\n",
      "1429/1429 [==============================] - 0s 134us/step - loss: 2.7915 - accuracy: 0.3121 - val_loss: 4.0238 - val_accuracy: 0.1384\n",
      "Epoch 70/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.7970 - accuracy: 0.3079 - val_loss: 4.0246 - val_accuracy: 0.1488\n",
      "Epoch 71/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.7875 - accuracy: 0.3170 - val_loss: 4.0246 - val_accuracy: 0.1447\n",
      "Epoch 72/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7924 - accuracy: 0.3093 - val_loss: 4.0353 - val_accuracy: 0.1488\n",
      "Epoch 73/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.7867 - accuracy: 0.3170 - val_loss: 4.0336 - val_accuracy: 0.1468\n",
      "Epoch 74/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.7855 - accuracy: 0.3079 - val_loss: 4.0398 - val_accuracy: 0.1635\n",
      "Epoch 75/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7822 - accuracy: 0.3177 - val_loss: 4.0422 - val_accuracy: 0.1614\n",
      "Epoch 76/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7836 - accuracy: 0.3128 - val_loss: 4.0516 - val_accuracy: 0.1488\n",
      "Epoch 77/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7779 - accuracy: 0.3184 - val_loss: 4.0653 - val_accuracy: 0.1363\n",
      "Epoch 78/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7819 - accuracy: 0.3177 - val_loss: 4.0711 - val_accuracy: 0.1447\n",
      "Epoch 79/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.7790 - accuracy: 0.3198 - val_loss: 4.0715 - val_accuracy: 0.1405\n",
      "Epoch 80/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7810 - accuracy: 0.3121 - val_loss: 4.0712 - val_accuracy: 0.1488\n",
      "Epoch 81/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7754 - accuracy: 0.3142 - val_loss: 4.0635 - val_accuracy: 0.1509\n",
      "Epoch 82/500\n",
      "1429/1429 [==============================] - 0s 93us/step - loss: 2.7749 - accuracy: 0.3135 - val_loss: 4.0667 - val_accuracy: 0.1530\n",
      "Epoch 83/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.7723 - accuracy: 0.3233 - val_loss: 4.1069 - val_accuracy: 0.1279\n",
      "Epoch 84/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.7684 - accuracy: 0.3177 - val_loss: 4.0714 - val_accuracy: 0.1509\n",
      "Epoch 85/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.7701 - accuracy: 0.3163 - val_loss: 4.0866 - val_accuracy: 0.1405\n",
      "Epoch 86/500\n",
      "1429/1429 [==============================] - 0s 121us/step - loss: 2.7706 - accuracy: 0.3191 - val_loss: 4.0792 - val_accuracy: 0.1363\n",
      "Epoch 87/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.7641 - accuracy: 0.3128 - val_loss: 4.1108 - val_accuracy: 0.1405\n",
      "Epoch 88/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.7656 - accuracy: 0.3093 - val_loss: 4.0933 - val_accuracy: 0.1426\n",
      "Epoch 89/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7651 - accuracy: 0.3114 - val_loss: 4.1032 - val_accuracy: 0.1363\n",
      "Epoch 90/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.7690 - accuracy: 0.3149 - val_loss: 4.1077 - val_accuracy: 0.1342\n",
      "Epoch 91/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.7583 - accuracy: 0.3247 - val_loss: 4.1116 - val_accuracy: 0.1384\n",
      "Epoch 92/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7601 - accuracy: 0.3247 - val_loss: 4.0990 - val_accuracy: 0.1447\n",
      "Epoch 93/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7641 - accuracy: 0.3170 - val_loss: 4.1033 - val_accuracy: 0.1405\n",
      "Epoch 94/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7613 - accuracy: 0.3121 - val_loss: 4.1236 - val_accuracy: 0.1468\n",
      "Epoch 95/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7566 - accuracy: 0.3170 - val_loss: 4.1199 - val_accuracy: 0.1572\n",
      "Epoch 96/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.7602 - accuracy: 0.3177 - val_loss: 4.1358 - val_accuracy: 0.1342\n",
      "Epoch 97/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7609 - accuracy: 0.3058 - val_loss: 4.1373 - val_accuracy: 0.1342\n",
      "Epoch 98/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7565 - accuracy: 0.3156 - val_loss: 4.1509 - val_accuracy: 0.1426\n",
      "Epoch 99/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7528 - accuracy: 0.3226 - val_loss: 4.1387 - val_accuracy: 0.1426\n",
      "Epoch 100/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7532 - accuracy: 0.3156 - val_loss: 4.1437 - val_accuracy: 0.1488\n",
      "Epoch 101/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.7587 - accuracy: 0.3128 - val_loss: 4.1554 - val_accuracy: 0.1342\n",
      "Epoch 102/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.7555 - accuracy: 0.3233 - val_loss: 4.1470 - val_accuracy: 0.1426\n",
      "Epoch 103/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.7535 - accuracy: 0.3184 - val_loss: 4.1577 - val_accuracy: 0.1342\n",
      "Epoch 104/500\n",
      "1429/1429 [==============================] - 0s 143us/step - loss: 2.7560 - accuracy: 0.3107 - val_loss: 4.1482 - val_accuracy: 0.1426\n",
      "Epoch 105/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7509 - accuracy: 0.3156 - val_loss: 4.1605 - val_accuracy: 0.1468\n",
      "Epoch 106/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.7480 - accuracy: 0.3268 - val_loss: 4.1505 - val_accuracy: 0.1426\n",
      "Epoch 107/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.7389 - accuracy: 0.3177 - val_loss: 4.1673 - val_accuracy: 0.1258\n",
      "Epoch 108/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7429 - accuracy: 0.3114 - val_loss: 4.1696 - val_accuracy: 0.1468\n",
      "Epoch 109/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7457 - accuracy: 0.3191 - val_loss: 4.1814 - val_accuracy: 0.1321\n",
      "Epoch 110/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7477 - accuracy: 0.3191 - val_loss: 4.1811 - val_accuracy: 0.1363\n",
      "Epoch 111/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7410 - accuracy: 0.3198 - val_loss: 4.2002 - val_accuracy: 0.1488\n",
      "Epoch 112/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.7367 - accuracy: 0.3198 - val_loss: 4.1753 - val_accuracy: 0.1363\n",
      "Epoch 113/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 2.7433 - accuracy: 0.3135 - val_loss: 4.2046 - val_accuracy: 0.1509\n",
      "Epoch 114/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.7399 - accuracy: 0.3128 - val_loss: 4.1968 - val_accuracy: 0.1342\n",
      "Epoch 115/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.7345 - accuracy: 0.3212 - val_loss: 4.2047 - val_accuracy: 0.1426\n",
      "Epoch 116/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.7304 - accuracy: 0.3240 - val_loss: 4.1960 - val_accuracy: 0.1363\n",
      "Epoch 117/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7335 - accuracy: 0.3254 - val_loss: 4.2081 - val_accuracy: 0.1405\n",
      "Epoch 118/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.7289 - accuracy: 0.3093 - val_loss: 4.2096 - val_accuracy: 0.1321\n",
      "Epoch 119/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.7349 - accuracy: 0.3247 - val_loss: 4.2245 - val_accuracy: 0.1384\n",
      "Epoch 120/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 2.7346 - accuracy: 0.3184 - val_loss: 4.2281 - val_accuracy: 0.1258\n",
      "Epoch 121/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.7314 - accuracy: 0.3275 - val_loss: 4.2250 - val_accuracy: 0.1384\n",
      "Epoch 122/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.7329 - accuracy: 0.3226 - val_loss: 4.2530 - val_accuracy: 0.1342\n",
      "Epoch 123/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7454 - accuracy: 0.3184 - val_loss: 4.2346 - val_accuracy: 0.1258\n",
      "Epoch 124/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7430 - accuracy: 0.3275 - val_loss: 4.2298 - val_accuracy: 0.1321\n",
      "Epoch 125/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.7217 - accuracy: 0.3282 - val_loss: 4.2489 - val_accuracy: 0.1447\n",
      "Epoch 126/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.7267 - accuracy: 0.3261 - val_loss: 4.2390 - val_accuracy: 0.1363\n",
      "Epoch 127/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.7351 - accuracy: 0.3240 - val_loss: 4.2423 - val_accuracy: 0.1363\n",
      "Epoch 128/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7221 - accuracy: 0.3289 - val_loss: 4.2523 - val_accuracy: 0.1384\n",
      "Epoch 129/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7209 - accuracy: 0.3317 - val_loss: 4.2649 - val_accuracy: 0.1321\n",
      "Epoch 130/500\n",
      "1429/1429 [==============================] - 0s 121us/step - loss: 2.7176 - accuracy: 0.3268 - val_loss: 4.2701 - val_accuracy: 0.1300\n",
      "Epoch 131/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7217 - accuracy: 0.3205 - val_loss: 4.2587 - val_accuracy: 0.1321\n",
      "Epoch 132/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 2.7201 - accuracy: 0.3282 - val_loss: 4.2719 - val_accuracy: 0.1342\n",
      "Epoch 133/500\n",
      "1429/1429 [==============================] - 0s 88us/step - loss: 2.7202 - accuracy: 0.3226 - val_loss: 4.2730 - val_accuracy: 0.1216\n",
      "Epoch 134/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.7132 - accuracy: 0.3254 - val_loss: 4.2967 - val_accuracy: 0.1342\n",
      "Epoch 135/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.7180 - accuracy: 0.3275 - val_loss: 4.2920 - val_accuracy: 0.1300\n",
      "Epoch 136/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.7178 - accuracy: 0.3205 - val_loss: 4.2978 - val_accuracy: 0.1342\n",
      "Epoch 137/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.7126 - accuracy: 0.3331 - val_loss: 4.2825 - val_accuracy: 0.1300\n",
      "Epoch 138/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7159 - accuracy: 0.3184 - val_loss: 4.3160 - val_accuracy: 0.1300\n",
      "Epoch 139/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.7178 - accuracy: 0.3191 - val_loss: 4.2891 - val_accuracy: 0.1300\n",
      "Epoch 140/500\n",
      "1429/1429 [==============================] - 0s 144us/step - loss: 2.7129 - accuracy: 0.3275 - val_loss: 4.3130 - val_accuracy: 0.1237\n",
      "Epoch 141/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7150 - accuracy: 0.3275 - val_loss: 4.2984 - val_accuracy: 0.1363\n",
      "Epoch 142/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7089 - accuracy: 0.3240 - val_loss: 4.3116 - val_accuracy: 0.1342\n",
      "Epoch 143/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7139 - accuracy: 0.3310 - val_loss: 4.3195 - val_accuracy: 0.1342\n",
      "Epoch 144/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7120 - accuracy: 0.3212 - val_loss: 4.3116 - val_accuracy: 0.1321\n",
      "Epoch 145/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.7084 - accuracy: 0.3303 - val_loss: 4.3209 - val_accuracy: 0.1509\n",
      "Epoch 146/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.7076 - accuracy: 0.3240 - val_loss: 4.3519 - val_accuracy: 0.1300\n",
      "Epoch 147/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7054 - accuracy: 0.3289 - val_loss: 4.3243 - val_accuracy: 0.1363\n",
      "Epoch 148/500\n",
      "1429/1429 [==============================] - 0s 93us/step - loss: 2.7010 - accuracy: 0.3289 - val_loss: 4.3473 - val_accuracy: 0.1279\n",
      "Epoch 149/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7034 - accuracy: 0.3324 - val_loss: 4.3454 - val_accuracy: 0.1300\n",
      "Epoch 150/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7041 - accuracy: 0.3254 - val_loss: 4.3511 - val_accuracy: 0.1363\n",
      "Epoch 151/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.7007 - accuracy: 0.3324 - val_loss: 4.3539 - val_accuracy: 0.1258\n",
      "Epoch 152/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6979 - accuracy: 0.3296 - val_loss: 4.3508 - val_accuracy: 0.1342\n",
      "Epoch 153/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7015 - accuracy: 0.3268 - val_loss: 4.3680 - val_accuracy: 0.1363\n",
      "Epoch 154/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.7002 - accuracy: 0.3296 - val_loss: 4.3648 - val_accuracy: 0.1258\n",
      "Epoch 155/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.7014 - accuracy: 0.3296 - val_loss: 4.3774 - val_accuracy: 0.1405\n",
      "Epoch 156/500\n",
      "1429/1429 [==============================] - 0s 130us/step - loss: 2.7034 - accuracy: 0.3310 - val_loss: 4.3555 - val_accuracy: 0.1405\n",
      "Epoch 157/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.7006 - accuracy: 0.3282 - val_loss: 4.3652 - val_accuracy: 0.1363\n",
      "Epoch 158/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6991 - accuracy: 0.3324 - val_loss: 4.3788 - val_accuracy: 0.1342\n",
      "Epoch 159/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6969 - accuracy: 0.3282 - val_loss: 4.3814 - val_accuracy: 0.1300\n",
      "Epoch 160/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7000 - accuracy: 0.3331 - val_loss: 4.3892 - val_accuracy: 0.1237\n",
      "Epoch 161/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6880 - accuracy: 0.3380 - val_loss: 4.3826 - val_accuracy: 0.1300\n",
      "Epoch 162/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.6925 - accuracy: 0.3261 - val_loss: 4.3881 - val_accuracy: 0.1342\n",
      "Epoch 163/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6980 - accuracy: 0.3289 - val_loss: 4.3844 - val_accuracy: 0.1321\n",
      "Epoch 164/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6908 - accuracy: 0.3345 - val_loss: 4.4022 - val_accuracy: 0.1258\n",
      "Epoch 165/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6929 - accuracy: 0.3387 - val_loss: 4.4158 - val_accuracy: 0.1342\n",
      "Epoch 166/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6897 - accuracy: 0.3261 - val_loss: 4.4224 - val_accuracy: 0.1258\n",
      "Epoch 167/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6979 - accuracy: 0.3289 - val_loss: 4.4066 - val_accuracy: 0.1258\n",
      "Epoch 168/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6937 - accuracy: 0.3296 - val_loss: 4.4294 - val_accuracy: 0.1195\n",
      "Epoch 169/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6932 - accuracy: 0.3170 - val_loss: 4.4240 - val_accuracy: 0.1258\n",
      "Epoch 170/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6920 - accuracy: 0.3261 - val_loss: 4.4171 - val_accuracy: 0.1237\n",
      "Epoch 171/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6906 - accuracy: 0.3254 - val_loss: 4.4350 - val_accuracy: 0.1258\n",
      "Epoch 172/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 2.6914 - accuracy: 0.3282 - val_loss: 4.4426 - val_accuracy: 0.1321\n",
      "Epoch 173/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6840 - accuracy: 0.3226 - val_loss: 4.4443 - val_accuracy: 0.1258\n",
      "Epoch 174/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6867 - accuracy: 0.3331 - val_loss: 4.4442 - val_accuracy: 0.1174\n",
      "Epoch 175/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.6894 - accuracy: 0.3310 - val_loss: 4.4523 - val_accuracy: 0.1342\n",
      "Epoch 176/500\n",
      "1429/1429 [==============================] - 0s 132us/step - loss: 2.6937 - accuracy: 0.3282 - val_loss: 4.4523 - val_accuracy: 0.1363\n",
      "Epoch 177/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6807 - accuracy: 0.3429 - val_loss: 4.4512 - val_accuracy: 0.1132\n",
      "Epoch 178/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6778 - accuracy: 0.3254 - val_loss: 4.4770 - val_accuracy: 0.1195\n",
      "Epoch 179/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6879 - accuracy: 0.3226 - val_loss: 4.4796 - val_accuracy: 0.1216\n",
      "Epoch 180/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6826 - accuracy: 0.3422 - val_loss: 4.4797 - val_accuracy: 0.1132\n",
      "Epoch 181/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.6817 - accuracy: 0.3275 - val_loss: 4.4838 - val_accuracy: 0.1258\n",
      "Epoch 182/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6844 - accuracy: 0.3275 - val_loss: 4.4902 - val_accuracy: 0.1237\n",
      "Epoch 183/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.6795 - accuracy: 0.3240 - val_loss: 4.4868 - val_accuracy: 0.1195\n",
      "Epoch 184/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6776 - accuracy: 0.3317 - val_loss: 4.5055 - val_accuracy: 0.1216\n",
      "Epoch 185/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6732 - accuracy: 0.3401 - val_loss: 4.4920 - val_accuracy: 0.1216\n",
      "Epoch 186/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6738 - accuracy: 0.3436 - val_loss: 4.4924 - val_accuracy: 0.1321\n",
      "Epoch 187/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.6730 - accuracy: 0.3317 - val_loss: 4.5011 - val_accuracy: 0.1216\n",
      "Epoch 188/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.6742 - accuracy: 0.3275 - val_loss: 4.5168 - val_accuracy: 0.1363\n",
      "Epoch 189/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6748 - accuracy: 0.3366 - val_loss: 4.4971 - val_accuracy: 0.1300\n",
      "Epoch 190/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6755 - accuracy: 0.3282 - val_loss: 4.5088 - val_accuracy: 0.1237\n",
      "Epoch 191/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6713 - accuracy: 0.3373 - val_loss: 4.5069 - val_accuracy: 0.1195\n",
      "Epoch 192/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6793 - accuracy: 0.3261 - val_loss: 4.5431 - val_accuracy: 0.1258\n",
      "Epoch 193/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6719 - accuracy: 0.3310 - val_loss: 4.5208 - val_accuracy: 0.1237\n",
      "Epoch 194/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 2.6703 - accuracy: 0.3289 - val_loss: 4.5185 - val_accuracy: 0.1237\n",
      "Epoch 195/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6767 - accuracy: 0.3324 - val_loss: 4.5343 - val_accuracy: 0.1279\n",
      "Epoch 196/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6742 - accuracy: 0.3310 - val_loss: 4.5386 - val_accuracy: 0.1258\n",
      "Epoch 197/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6727 - accuracy: 0.3282 - val_loss: 4.5388 - val_accuracy: 0.1342\n",
      "Epoch 198/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7021 - accuracy: 0.3296 - val_loss: 4.5643 - val_accuracy: 0.1153\n",
      "Epoch 199/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6739 - accuracy: 0.3303 - val_loss: 4.5486 - val_accuracy: 0.1363\n",
      "Epoch 200/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6691 - accuracy: 0.3240 - val_loss: 4.5502 - val_accuracy: 0.1153\n",
      "Epoch 201/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 2.6668 - accuracy: 0.3352 - val_loss: 4.5756 - val_accuracy: 0.1216\n",
      "Epoch 202/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.6623 - accuracy: 0.3289 - val_loss: 4.5649 - val_accuracy: 0.1132\n",
      "Epoch 203/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6650 - accuracy: 0.3345 - val_loss: 4.5857 - val_accuracy: 0.1195\n",
      "Epoch 204/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6675 - accuracy: 0.3205 - val_loss: 4.5862 - val_accuracy: 0.1237\n",
      "Epoch 205/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6650 - accuracy: 0.3352 - val_loss: 4.5751 - val_accuracy: 0.1195\n",
      "Epoch 206/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6687 - accuracy: 0.3366 - val_loss: 4.5787 - val_accuracy: 0.1195\n",
      "Epoch 207/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6636 - accuracy: 0.3394 - val_loss: 4.5812 - val_accuracy: 0.1174\n",
      "Epoch 208/500\n",
      "1429/1429 [==============================] - 0s 90us/step - loss: 2.6687 - accuracy: 0.3366 - val_loss: 4.6067 - val_accuracy: 0.1237\n",
      "Epoch 209/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6654 - accuracy: 0.3352 - val_loss: 4.5867 - val_accuracy: 0.1153\n",
      "Epoch 210/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.6661 - accuracy: 0.3296 - val_loss: 4.6026 - val_accuracy: 0.1153\n",
      "Epoch 211/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6639 - accuracy: 0.3310 - val_loss: 4.5955 - val_accuracy: 0.1237\n",
      "Epoch 212/500\n",
      "1429/1429 [==============================] - 0s 142us/step - loss: 2.6645 - accuracy: 0.3359 - val_loss: 4.6113 - val_accuracy: 0.1237\n",
      "Epoch 213/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6635 - accuracy: 0.3387 - val_loss: 4.6109 - val_accuracy: 0.1216\n",
      "Epoch 214/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6611 - accuracy: 0.3275 - val_loss: 4.6125 - val_accuracy: 0.1111\n",
      "Epoch 215/500\n",
      "1429/1429 [==============================] - 0s 90us/step - loss: 2.6587 - accuracy: 0.3303 - val_loss: 4.6196 - val_accuracy: 0.1216\n",
      "Epoch 216/500\n",
      "1429/1429 [==============================] - 0s 90us/step - loss: 2.6576 - accuracy: 0.3408 - val_loss: 4.6119 - val_accuracy: 0.1258\n",
      "Epoch 217/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.6577 - accuracy: 0.3443 - val_loss: 4.6476 - val_accuracy: 0.1132\n",
      "Epoch 218/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6600 - accuracy: 0.3450 - val_loss: 4.6469 - val_accuracy: 0.1237\n",
      "Epoch 219/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6575 - accuracy: 0.3352 - val_loss: 4.6290 - val_accuracy: 0.1174\n",
      "Epoch 220/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.6589 - accuracy: 0.3338 - val_loss: 4.6361 - val_accuracy: 0.1069\n",
      "Epoch 221/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6523 - accuracy: 0.3380 - val_loss: 4.6552 - val_accuracy: 0.1153\n",
      "Epoch 222/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6596 - accuracy: 0.3352 - val_loss: 4.6565 - val_accuracy: 0.1090\n",
      "Epoch 223/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6553 - accuracy: 0.3415 - val_loss: 4.6562 - val_accuracy: 0.1132\n",
      "Epoch 224/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.6869 - accuracy: 0.3380 - val_loss: 4.6603 - val_accuracy: 0.1216\n",
      "Epoch 225/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.6519 - accuracy: 0.3338 - val_loss: 4.6607 - val_accuracy: 0.1300\n",
      "Epoch 226/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6581 - accuracy: 0.3359 - val_loss: 4.6799 - val_accuracy: 0.1258\n",
      "Epoch 227/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6486 - accuracy: 0.3226 - val_loss: 4.6721 - val_accuracy: 0.1237\n",
      "Epoch 228/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.6509 - accuracy: 0.3345 - val_loss: 4.6916 - val_accuracy: 0.1090\n",
      "Epoch 229/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6485 - accuracy: 0.3317 - val_loss: 4.6960 - val_accuracy: 0.1216\n",
      "Epoch 230/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.6484 - accuracy: 0.3408 - val_loss: 4.7248 - val_accuracy: 0.1132\n",
      "Epoch 231/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6499 - accuracy: 0.3324 - val_loss: 4.6892 - val_accuracy: 0.1216\n",
      "Epoch 232/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6460 - accuracy: 0.3352 - val_loss: 4.6956 - val_accuracy: 0.1237\n",
      "Epoch 233/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6488 - accuracy: 0.3373 - val_loss: 4.6850 - val_accuracy: 0.1090\n",
      "Epoch 234/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6549 - accuracy: 0.3282 - val_loss: 4.7093 - val_accuracy: 0.1153\n",
      "Epoch 235/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.6423 - accuracy: 0.3387 - val_loss: 4.7153 - val_accuracy: 0.1174\n",
      "Epoch 236/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6449 - accuracy: 0.3352 - val_loss: 4.7108 - val_accuracy: 0.1258\n",
      "Epoch 237/500\n",
      "1429/1429 [==============================] - 0s 90us/step - loss: 2.6450 - accuracy: 0.3317 - val_loss: 4.7116 - val_accuracy: 0.1279\n",
      "Epoch 238/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6468 - accuracy: 0.3373 - val_loss: 4.7190 - val_accuracy: 0.1237\n",
      "Epoch 239/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6452 - accuracy: 0.3450 - val_loss: 4.7113 - val_accuracy: 0.1153\n",
      "Epoch 240/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6435 - accuracy: 0.3338 - val_loss: 4.7255 - val_accuracy: 0.1174\n",
      "Epoch 241/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6393 - accuracy: 0.3408 - val_loss: 4.7299 - val_accuracy: 0.1237\n",
      "Epoch 242/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.6427 - accuracy: 0.3317 - val_loss: 4.7474 - val_accuracy: 0.1111\n",
      "Epoch 243/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6484 - accuracy: 0.3359 - val_loss: 4.7317 - val_accuracy: 0.1321\n",
      "Epoch 244/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6481 - accuracy: 0.3436 - val_loss: 4.7560 - val_accuracy: 0.1195\n",
      "Epoch 245/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6452 - accuracy: 0.3191 - val_loss: 4.7563 - val_accuracy: 0.1216\n",
      "Epoch 246/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6405 - accuracy: 0.3429 - val_loss: 4.7510 - val_accuracy: 0.1216\n",
      "Epoch 247/500\n",
      "1429/1429 [==============================] - 0s 115us/step - loss: 2.6385 - accuracy: 0.3352 - val_loss: 4.7643 - val_accuracy: 0.1216\n",
      "Epoch 248/500\n",
      "1429/1429 [==============================] - 0s 132us/step - loss: 2.6444 - accuracy: 0.3387 - val_loss: 4.7681 - val_accuracy: 0.1174\n",
      "Epoch 249/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6377 - accuracy: 0.3401 - val_loss: 4.7677 - val_accuracy: 0.1195\n",
      "Epoch 250/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6364 - accuracy: 0.3422 - val_loss: 4.7952 - val_accuracy: 0.1111\n",
      "Epoch 251/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6433 - accuracy: 0.3366 - val_loss: 4.7731 - val_accuracy: 0.1195\n",
      "Epoch 252/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6392 - accuracy: 0.3478 - val_loss: 4.8050 - val_accuracy: 0.1069\n",
      "Epoch 253/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6374 - accuracy: 0.3345 - val_loss: 4.7936 - val_accuracy: 0.1195\n",
      "Epoch 254/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6367 - accuracy: 0.3450 - val_loss: 4.7909 - val_accuracy: 0.1321\n",
      "Epoch 255/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6394 - accuracy: 0.3331 - val_loss: 4.8039 - val_accuracy: 0.1216\n",
      "Epoch 256/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6293 - accuracy: 0.3359 - val_loss: 4.7996 - val_accuracy: 0.1153\n",
      "Epoch 257/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 2.6363 - accuracy: 0.3359 - val_loss: 4.8170 - val_accuracy: 0.1258\n",
      "Epoch 258/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6357 - accuracy: 0.3436 - val_loss: 4.8113 - val_accuracy: 0.1069\n",
      "Epoch 259/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6363 - accuracy: 0.3352 - val_loss: 4.8274 - val_accuracy: 0.1216\n",
      "Epoch 260/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6333 - accuracy: 0.3310 - val_loss: 4.8181 - val_accuracy: 0.1237\n",
      "Epoch 261/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6287 - accuracy: 0.3387 - val_loss: 4.8122 - val_accuracy: 0.1258\n",
      "Epoch 262/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.6316 - accuracy: 0.3303 - val_loss: 4.8267 - val_accuracy: 0.1153\n",
      "Epoch 263/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6376 - accuracy: 0.3359 - val_loss: 4.8352 - val_accuracy: 0.1237\n",
      "Epoch 264/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6348 - accuracy: 0.3366 - val_loss: 4.8317 - val_accuracy: 0.1237\n",
      "Epoch 265/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6296 - accuracy: 0.3394 - val_loss: 4.8317 - val_accuracy: 0.1069\n",
      "Epoch 266/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6326 - accuracy: 0.3324 - val_loss: 4.8411 - val_accuracy: 0.1216\n",
      "Epoch 267/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6321 - accuracy: 0.3415 - val_loss: 4.8441 - val_accuracy: 0.1174\n",
      "Epoch 268/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6361 - accuracy: 0.3338 - val_loss: 4.8511 - val_accuracy: 0.1195\n",
      "Epoch 269/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6327 - accuracy: 0.3436 - val_loss: 4.8904 - val_accuracy: 0.1153\n",
      "Epoch 270/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6325 - accuracy: 0.3408 - val_loss: 4.8597 - val_accuracy: 0.1153\n",
      "Epoch 271/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6313 - accuracy: 0.3387 - val_loss: 4.8846 - val_accuracy: 0.1153\n",
      "Epoch 272/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.6290 - accuracy: 0.3380 - val_loss: 4.8624 - val_accuracy: 0.1132\n",
      "Epoch 273/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6259 - accuracy: 0.3429 - val_loss: 4.8762 - val_accuracy: 0.1195\n",
      "Epoch 274/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 2.6236 - accuracy: 0.3485 - val_loss: 4.8863 - val_accuracy: 0.1111\n",
      "Epoch 275/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6226 - accuracy: 0.3394 - val_loss: 4.8861 - val_accuracy: 0.1111\n",
      "Epoch 276/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6237 - accuracy: 0.3401 - val_loss: 4.8972 - val_accuracy: 0.1195\n",
      "Epoch 277/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6297 - accuracy: 0.3429 - val_loss: 4.8973 - val_accuracy: 0.1132\n",
      "Epoch 278/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6277 - accuracy: 0.3450 - val_loss: 4.8948 - val_accuracy: 0.1174\n",
      "Epoch 279/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6230 - accuracy: 0.3429 - val_loss: 4.9035 - val_accuracy: 0.1132\n",
      "Epoch 280/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.6262 - accuracy: 0.3457 - val_loss: 4.9051 - val_accuracy: 0.1195\n",
      "Epoch 281/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6275 - accuracy: 0.3317 - val_loss: 4.9038 - val_accuracy: 0.1048\n",
      "Epoch 282/500\n",
      "1429/1429 [==============================] - 0s 90us/step - loss: 2.6231 - accuracy: 0.3485 - val_loss: 4.9336 - val_accuracy: 0.1195\n",
      "Epoch 283/500\n",
      "1429/1429 [==============================] - 0s 154us/step - loss: 2.6234 - accuracy: 0.3415 - val_loss: 4.9334 - val_accuracy: 0.1216\n",
      "Epoch 284/500\n",
      "1429/1429 [==============================] - 0s 135us/step - loss: 2.6242 - accuracy: 0.3317 - val_loss: 4.9325 - val_accuracy: 0.1132\n",
      "Epoch 285/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.6196 - accuracy: 0.3471 - val_loss: 4.9440 - val_accuracy: 0.1216\n",
      "Epoch 286/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.6232 - accuracy: 0.3380 - val_loss: 4.9460 - val_accuracy: 0.1216\n",
      "Epoch 287/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.6234 - accuracy: 0.3387 - val_loss: 4.9466 - val_accuracy: 0.1132\n",
      "Epoch 288/500\n",
      "1429/1429 [==============================] - 0s 115us/step - loss: 2.6218 - accuracy: 0.3415 - val_loss: 4.9507 - val_accuracy: 0.1111\n",
      "Epoch 289/500\n",
      "1429/1429 [==============================] - 0s 115us/step - loss: 2.6192 - accuracy: 0.3310 - val_loss: 4.9376 - val_accuracy: 0.1132\n",
      "Epoch 290/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.6220 - accuracy: 0.3478 - val_loss: 4.9462 - val_accuracy: 0.1216\n",
      "Epoch 291/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.6183 - accuracy: 0.3394 - val_loss: 4.9695 - val_accuracy: 0.1195\n",
      "Epoch 292/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.6194 - accuracy: 0.3436 - val_loss: 4.9683 - val_accuracy: 0.1090\n",
      "Epoch 293/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.6168 - accuracy: 0.3380 - val_loss: 4.9740 - val_accuracy: 0.1174\n",
      "Epoch 294/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.6215 - accuracy: 0.3366 - val_loss: 4.9667 - val_accuracy: 0.1111\n",
      "Epoch 295/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6158 - accuracy: 0.3457 - val_loss: 4.9941 - val_accuracy: 0.1048\n",
      "Epoch 296/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6190 - accuracy: 0.3359 - val_loss: 4.9713 - val_accuracy: 0.1174\n",
      "Epoch 297/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6141 - accuracy: 0.3443 - val_loss: 4.9890 - val_accuracy: 0.1174\n",
      "Epoch 298/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6135 - accuracy: 0.3478 - val_loss: 4.9993 - val_accuracy: 0.1153\n",
      "Epoch 299/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6172 - accuracy: 0.3443 - val_loss: 4.9976 - val_accuracy: 0.1048\n",
      "Epoch 300/500\n",
      "1429/1429 [==============================] - 0s 115us/step - loss: 2.6537 - accuracy: 0.3324 - val_loss: 5.0122 - val_accuracy: 0.1048\n",
      "Epoch 301/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6163 - accuracy: 0.3443 - val_loss: 5.0031 - val_accuracy: 0.1153\n",
      "Epoch 302/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.6122 - accuracy: 0.3415 - val_loss: 5.0155 - val_accuracy: 0.1195\n",
      "Epoch 303/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6169 - accuracy: 0.3485 - val_loss: 5.0345 - val_accuracy: 0.1048\n",
      "Epoch 304/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6132 - accuracy: 0.3345 - val_loss: 5.0371 - val_accuracy: 0.1027\n",
      "Epoch 305/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6165 - accuracy: 0.3457 - val_loss: 5.0245 - val_accuracy: 0.1216\n",
      "Epoch 306/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6122 - accuracy: 0.3408 - val_loss: 5.0432 - val_accuracy: 0.1174\n",
      "Epoch 307/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6120 - accuracy: 0.3394 - val_loss: 5.0371 - val_accuracy: 0.1006\n",
      "Epoch 308/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6171 - accuracy: 0.3450 - val_loss: 5.0374 - val_accuracy: 0.1111\n",
      "Epoch 309/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.6140 - accuracy: 0.3380 - val_loss: 5.0530 - val_accuracy: 0.1237\n",
      "Epoch 310/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6117 - accuracy: 0.3527 - val_loss: 5.0417 - val_accuracy: 0.1132\n",
      "Epoch 311/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6126 - accuracy: 0.3373 - val_loss: 5.0573 - val_accuracy: 0.1195\n",
      "Epoch 312/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6094 - accuracy: 0.3450 - val_loss: 5.0649 - val_accuracy: 0.1195\n",
      "Epoch 313/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6102 - accuracy: 0.3317 - val_loss: 5.0812 - val_accuracy: 0.1111\n",
      "Epoch 314/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6050 - accuracy: 0.3394 - val_loss: 5.0776 - val_accuracy: 0.1153\n",
      "Epoch 315/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6078 - accuracy: 0.3401 - val_loss: 5.0809 - val_accuracy: 0.1195\n",
      "Epoch 316/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6066 - accuracy: 0.3471 - val_loss: 5.0938 - val_accuracy: 0.1195\n",
      "Epoch 317/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.6122 - accuracy: 0.3401 - val_loss: 5.0942 - val_accuracy: 0.1132\n",
      "Epoch 318/500\n",
      "1429/1429 [==============================] - 0s 132us/step - loss: 2.6114 - accuracy: 0.3471 - val_loss: 5.0940 - val_accuracy: 0.1237\n",
      "Epoch 319/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6063 - accuracy: 0.3436 - val_loss: 5.0808 - val_accuracy: 0.1153\n",
      "Epoch 320/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6095 - accuracy: 0.3457 - val_loss: 5.0879 - val_accuracy: 0.1216\n",
      "Epoch 321/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6068 - accuracy: 0.3499 - val_loss: 5.0990 - val_accuracy: 0.1174\n",
      "Epoch 322/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6069 - accuracy: 0.3373 - val_loss: 5.1067 - val_accuracy: 0.1132\n",
      "Epoch 323/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 93us/step - loss: 2.6098 - accuracy: 0.3415 - val_loss: 5.0981 - val_accuracy: 0.1174\n",
      "Epoch 324/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6017 - accuracy: 0.3478 - val_loss: 5.1278 - val_accuracy: 0.1132\n",
      "Epoch 325/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6088 - accuracy: 0.3436 - val_loss: 5.1223 - val_accuracy: 0.1111\n",
      "Epoch 326/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6041 - accuracy: 0.3457 - val_loss: 5.1294 - val_accuracy: 0.1111\n",
      "Epoch 327/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6007 - accuracy: 0.3513 - val_loss: 5.1459 - val_accuracy: 0.1153\n",
      "Epoch 328/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6011 - accuracy: 0.3422 - val_loss: 5.1221 - val_accuracy: 0.1111\n",
      "Epoch 329/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6121 - accuracy: 0.3380 - val_loss: 5.1627 - val_accuracy: 0.1153\n",
      "Epoch 330/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6059 - accuracy: 0.3352 - val_loss: 5.1599 - val_accuracy: 0.1048\n",
      "Epoch 331/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6066 - accuracy: 0.3422 - val_loss: 5.1519 - val_accuracy: 0.1174\n",
      "Epoch 332/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6024 - accuracy: 0.3450 - val_loss: 5.1536 - val_accuracy: 0.1237\n",
      "Epoch 333/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5993 - accuracy: 0.3443 - val_loss: 5.1543 - val_accuracy: 0.1132\n",
      "Epoch 334/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5990 - accuracy: 0.3450 - val_loss: 5.1844 - val_accuracy: 0.1153\n",
      "Epoch 335/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5956 - accuracy: 0.3471 - val_loss: 5.1460 - val_accuracy: 0.1090\n",
      "Epoch 336/500\n",
      "1429/1429 [==============================] - 0s 93us/step - loss: 2.6350 - accuracy: 0.3436 - val_loss: 5.1842 - val_accuracy: 0.1090\n",
      "Epoch 337/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6229 - accuracy: 0.3436 - val_loss: 5.1863 - val_accuracy: 0.1111\n",
      "Epoch 338/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.6000 - accuracy: 0.3436 - val_loss: 5.2053 - val_accuracy: 0.0985\n",
      "Epoch 339/500\n",
      "1429/1429 [==============================] - 0s 133us/step - loss: 2.6041 - accuracy: 0.3352 - val_loss: 5.1891 - val_accuracy: 0.1195\n",
      "Epoch 340/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.5996 - accuracy: 0.3534 - val_loss: 5.2099 - val_accuracy: 0.1174\n",
      "Epoch 341/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5958 - accuracy: 0.3513 - val_loss: 5.1911 - val_accuracy: 0.1153\n",
      "Epoch 342/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.6000 - accuracy: 0.3436 - val_loss: 5.1907 - val_accuracy: 0.1048\n",
      "Epoch 343/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.5999 - accuracy: 0.3485 - val_loss: 5.2108 - val_accuracy: 0.1153\n",
      "Epoch 344/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6020 - accuracy: 0.3478 - val_loss: 5.2251 - val_accuracy: 0.1132\n",
      "Epoch 345/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.6018 - accuracy: 0.3499 - val_loss: 5.1985 - val_accuracy: 0.1216\n",
      "Epoch 346/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5923 - accuracy: 0.3485 - val_loss: 5.2196 - val_accuracy: 0.1132\n",
      "Epoch 347/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5921 - accuracy: 0.3478 - val_loss: 5.2264 - val_accuracy: 0.1153\n",
      "Epoch 348/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5919 - accuracy: 0.3527 - val_loss: 5.2390 - val_accuracy: 0.1027\n",
      "Epoch 349/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.5996 - accuracy: 0.3485 - val_loss: 5.2410 - val_accuracy: 0.1279\n",
      "Epoch 350/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5956 - accuracy: 0.3408 - val_loss: 5.2369 - val_accuracy: 0.1237\n",
      "Epoch 351/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5928 - accuracy: 0.3555 - val_loss: 5.2503 - val_accuracy: 0.1132\n",
      "Epoch 352/500\n",
      "1429/1429 [==============================] - 0s 135us/step - loss: 2.5935 - accuracy: 0.3548 - val_loss: 5.2497 - val_accuracy: 0.1153\n",
      "Epoch 353/500\n",
      "1429/1429 [==============================] - 0s 118us/step - loss: 2.5968 - accuracy: 0.3457 - val_loss: 5.2667 - val_accuracy: 0.1132\n",
      "Epoch 354/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.5956 - accuracy: 0.3534 - val_loss: 5.2713 - val_accuracy: 0.1069\n",
      "Epoch 355/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.5873 - accuracy: 0.3569 - val_loss: 5.2746 - val_accuracy: 0.1153\n",
      "Epoch 356/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.5933 - accuracy: 0.3471 - val_loss: 5.2742 - val_accuracy: 0.1237\n",
      "Epoch 357/500\n",
      "1429/1429 [==============================] - 0s 140us/step - loss: 2.5916 - accuracy: 0.3450 - val_loss: 5.2867 - val_accuracy: 0.1111\n",
      "Epoch 358/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.5907 - accuracy: 0.3464 - val_loss: 5.2719 - val_accuracy: 0.1195\n",
      "Epoch 359/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.5949 - accuracy: 0.3527 - val_loss: 5.2790 - val_accuracy: 0.1132\n",
      "Epoch 360/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5942 - accuracy: 0.3450 - val_loss: 5.3034 - val_accuracy: 0.1216\n",
      "Epoch 361/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5910 - accuracy: 0.3478 - val_loss: 5.2942 - val_accuracy: 0.1006\n",
      "Epoch 362/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5912 - accuracy: 0.3415 - val_loss: 5.2965 - val_accuracy: 0.1069\n",
      "Epoch 363/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5930 - accuracy: 0.3541 - val_loss: 5.3106 - val_accuracy: 0.1216\n",
      "Epoch 364/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5929 - accuracy: 0.3415 - val_loss: 5.3037 - val_accuracy: 0.1111\n",
      "Epoch 365/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5868 - accuracy: 0.3401 - val_loss: 5.3087 - val_accuracy: 0.1153\n",
      "Epoch 366/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.5929 - accuracy: 0.3387 - val_loss: 5.3158 - val_accuracy: 0.1027\n",
      "Epoch 367/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5845 - accuracy: 0.3618 - val_loss: 5.3428 - val_accuracy: 0.1090\n",
      "Epoch 368/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.5875 - accuracy: 0.3422 - val_loss: 5.3311 - val_accuracy: 0.1111\n",
      "Epoch 369/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5866 - accuracy: 0.3555 - val_loss: 5.3356 - val_accuracy: 0.1111\n",
      "Epoch 370/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.5892 - accuracy: 0.3520 - val_loss: 5.3382 - val_accuracy: 0.1237\n",
      "Epoch 371/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5896 - accuracy: 0.3485 - val_loss: 5.3729 - val_accuracy: 0.1090\n",
      "Epoch 372/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5912 - accuracy: 0.3492 - val_loss: 5.3354 - val_accuracy: 0.1195\n",
      "Epoch 373/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5843 - accuracy: 0.3443 - val_loss: 5.3543 - val_accuracy: 0.1069\n",
      "Epoch 374/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5886 - accuracy: 0.3492 - val_loss: 5.3590 - val_accuracy: 0.1174\n",
      "Epoch 375/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5842 - accuracy: 0.3548 - val_loss: 5.3549 - val_accuracy: 0.1174\n",
      "Epoch 376/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.5889 - accuracy: 0.3478 - val_loss: 5.3507 - val_accuracy: 0.1153\n",
      "Epoch 377/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5914 - accuracy: 0.3422 - val_loss: 5.3765 - val_accuracy: 0.1153\n",
      "Epoch 378/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5881 - accuracy: 0.3471 - val_loss: 5.3689 - val_accuracy: 0.1132\n",
      "Epoch 379/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5826 - accuracy: 0.3520 - val_loss: 5.3932 - val_accuracy: 0.1153\n",
      "Epoch 380/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.5823 - accuracy: 0.3499 - val_loss: 5.3662 - val_accuracy: 0.1153\n",
      "Epoch 381/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5881 - accuracy: 0.3401 - val_loss: 5.3945 - val_accuracy: 0.1174\n",
      "Epoch 382/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.5821 - accuracy: 0.3443 - val_loss: 5.3881 - val_accuracy: 0.1111\n",
      "Epoch 383/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5833 - accuracy: 0.3513 - val_loss: 5.4008 - val_accuracy: 0.1174\n",
      "Epoch 384/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5875 - accuracy: 0.3478 - val_loss: 5.4082 - val_accuracy: 0.1174\n",
      "Epoch 385/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5817 - accuracy: 0.3464 - val_loss: 5.4252 - val_accuracy: 0.1111\n",
      "Epoch 386/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.5858 - accuracy: 0.3541 - val_loss: 5.4122 - val_accuracy: 0.1111\n",
      "Epoch 387/500\n",
      "1429/1429 [==============================] - 0s 141us/step - loss: 2.5822 - accuracy: 0.3555 - val_loss: 5.4217 - val_accuracy: 0.1174\n",
      "Epoch 388/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5814 - accuracy: 0.3478 - val_loss: 5.4195 - val_accuracy: 0.1174\n",
      "Epoch 389/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5827 - accuracy: 0.3415 - val_loss: 5.4261 - val_accuracy: 0.1195\n",
      "Epoch 390/500\n",
      "1429/1429 [==============================] - 0s 93us/step - loss: 2.5904 - accuracy: 0.3457 - val_loss: 5.4654 - val_accuracy: 0.1153\n",
      "Epoch 391/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5933 - accuracy: 0.3429 - val_loss: 5.4320 - val_accuracy: 0.1153\n",
      "Epoch 392/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5847 - accuracy: 0.3471 - val_loss: 5.4738 - val_accuracy: 0.1048\n",
      "Epoch 393/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5808 - accuracy: 0.3541 - val_loss: 5.4694 - val_accuracy: 0.1090\n",
      "Epoch 394/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5773 - accuracy: 0.3485 - val_loss: 5.4541 - val_accuracy: 0.1132\n",
      "Epoch 395/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5842 - accuracy: 0.3492 - val_loss: 5.4556 - val_accuracy: 0.1132\n",
      "Epoch 396/500\n",
      "1429/1429 [==============================] - 0s 93us/step - loss: 2.5816 - accuracy: 0.3485 - val_loss: 5.4494 - val_accuracy: 0.1111\n",
      "Epoch 397/500\n",
      "1429/1429 [==============================] - 0s 93us/step - loss: 2.5812 - accuracy: 0.3443 - val_loss: 5.4788 - val_accuracy: 0.1006\n",
      "Epoch 398/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.5778 - accuracy: 0.3527 - val_loss: 5.4669 - val_accuracy: 0.1174\n",
      "Epoch 399/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5794 - accuracy: 0.3492 - val_loss: 5.4751 - val_accuracy: 0.1069\n",
      "Epoch 400/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.5772 - accuracy: 0.3457 - val_loss: 5.4845 - val_accuracy: 0.1090\n",
      "Epoch 401/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5748 - accuracy: 0.3555 - val_loss: 5.4787 - val_accuracy: 0.1048\n",
      "Epoch 402/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5754 - accuracy: 0.3352 - val_loss: 5.5009 - val_accuracy: 0.1111\n",
      "Epoch 403/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5910 - accuracy: 0.3485 - val_loss: 5.4832 - val_accuracy: 0.1048\n",
      "Epoch 404/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6135 - accuracy: 0.3499 - val_loss: 5.4986 - val_accuracy: 0.1069\n",
      "Epoch 405/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5727 - accuracy: 0.3506 - val_loss: 5.4977 - val_accuracy: 0.1174\n",
      "Epoch 406/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5732 - accuracy: 0.3506 - val_loss: 5.5155 - val_accuracy: 0.1090\n",
      "Epoch 407/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5828 - accuracy: 0.3492 - val_loss: 5.5210 - val_accuracy: 0.1090\n",
      "Epoch 408/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5730 - accuracy: 0.3457 - val_loss: 5.5089 - val_accuracy: 0.1174\n",
      "Epoch 409/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5753 - accuracy: 0.3520 - val_loss: 5.5240 - val_accuracy: 0.1132\n",
      "Epoch 410/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.5729 - accuracy: 0.3576 - val_loss: 5.5317 - val_accuracy: 0.1153\n",
      "Epoch 411/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5782 - accuracy: 0.3492 - val_loss: 5.5293 - val_accuracy: 0.1174\n",
      "Epoch 412/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5794 - accuracy: 0.3478 - val_loss: 5.5196 - val_accuracy: 0.1153\n",
      "Epoch 413/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.5738 - accuracy: 0.3576 - val_loss: 5.5418 - val_accuracy: 0.1006\n",
      "Epoch 414/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5738 - accuracy: 0.3541 - val_loss: 5.5616 - val_accuracy: 0.1195\n",
      "Epoch 415/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.5703 - accuracy: 0.3443 - val_loss: 5.5618 - val_accuracy: 0.1027\n",
      "Epoch 416/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.5733 - accuracy: 0.3548 - val_loss: 5.5646 - val_accuracy: 0.1153\n",
      "Epoch 417/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5702 - accuracy: 0.3548 - val_loss: 5.5564 - val_accuracy: 0.1174\n",
      "Epoch 418/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5710 - accuracy: 0.3478 - val_loss: 5.5611 - val_accuracy: 0.1174\n",
      "Epoch 419/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.5742 - accuracy: 0.3450 - val_loss: 5.5623 - val_accuracy: 0.1048\n",
      "Epoch 420/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5691 - accuracy: 0.3513 - val_loss: 5.5882 - val_accuracy: 0.1153\n",
      "Epoch 421/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5677 - accuracy: 0.3625 - val_loss: 5.5866 - val_accuracy: 0.1048\n",
      "Epoch 422/500\n",
      "1429/1429 [==============================] - 0s 131us/step - loss: 2.5783 - accuracy: 0.3373 - val_loss: 5.5905 - val_accuracy: 0.1069\n",
      "Epoch 423/500\n",
      "1429/1429 [==============================] - 0s 133us/step - loss: 2.5701 - accuracy: 0.3492 - val_loss: 5.5750 - val_accuracy: 0.1090\n",
      "Epoch 424/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.5739 - accuracy: 0.3443 - val_loss: 5.5864 - val_accuracy: 0.1174\n",
      "Epoch 425/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5738 - accuracy: 0.3492 - val_loss: 5.5805 - val_accuracy: 0.1195\n",
      "Epoch 426/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.5682 - accuracy: 0.3478 - val_loss: 5.5970 - val_accuracy: 0.1153\n",
      "Epoch 427/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5696 - accuracy: 0.3478 - val_loss: 5.6265 - val_accuracy: 0.1069\n",
      "Epoch 428/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5792 - accuracy: 0.3471 - val_loss: 5.6187 - val_accuracy: 0.1048\n",
      "Epoch 429/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5656 - accuracy: 0.3485 - val_loss: 5.6309 - val_accuracy: 0.1090\n",
      "Epoch 430/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5742 - accuracy: 0.3485 - val_loss: 5.6189 - val_accuracy: 0.1090\n",
      "Epoch 431/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5642 - accuracy: 0.3625 - val_loss: 5.6169 - val_accuracy: 0.1216\n",
      "Epoch 432/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5642 - accuracy: 0.3492 - val_loss: 5.6478 - val_accuracy: 0.1048\n",
      "Epoch 433/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5663 - accuracy: 0.3457 - val_loss: 5.6353 - val_accuracy: 0.1090\n",
      "Epoch 434/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5666 - accuracy: 0.3583 - val_loss: 5.6404 - val_accuracy: 0.1069\n",
      "Epoch 435/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5658 - accuracy: 0.3499 - val_loss: 5.6272 - val_accuracy: 0.1174\n",
      "Epoch 436/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5673 - accuracy: 0.3492 - val_loss: 5.6495 - val_accuracy: 0.1048\n",
      "Epoch 437/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.5689 - accuracy: 0.3520 - val_loss: 5.6470 - val_accuracy: 0.1153\n",
      "Epoch 438/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.5691 - accuracy: 0.3415 - val_loss: 5.6662 - val_accuracy: 0.1174\n",
      "Epoch 439/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.5681 - accuracy: 0.3485 - val_loss: 5.6915 - val_accuracy: 0.1237\n",
      "Epoch 440/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5792 - accuracy: 0.3464 - val_loss: 5.7050 - val_accuracy: 0.1069\n",
      "Epoch 441/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5748 - accuracy: 0.3520 - val_loss: 5.6610 - val_accuracy: 0.1174\n",
      "Epoch 442/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5602 - accuracy: 0.3527 - val_loss: 5.6819 - val_accuracy: 0.1048\n",
      "Epoch 443/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5648 - accuracy: 0.3555 - val_loss: 5.6841 - val_accuracy: 0.1153\n",
      "Epoch 444/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5630 - accuracy: 0.3520 - val_loss: 5.6823 - val_accuracy: 0.1069\n",
      "Epoch 445/500\n",
      "1429/1429 [==============================] - 0s 93us/step - loss: 2.5614 - accuracy: 0.3408 - val_loss: 5.6960 - val_accuracy: 0.1153\n",
      "Epoch 446/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.5668 - accuracy: 0.3548 - val_loss: 5.7046 - val_accuracy: 0.1090\n",
      "Epoch 447/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.5644 - accuracy: 0.3534 - val_loss: 5.6962 - val_accuracy: 0.1069\n",
      "Epoch 448/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5583 - accuracy: 0.3457 - val_loss: 5.7236 - val_accuracy: 0.1111\n",
      "Epoch 449/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5924 - accuracy: 0.3450 - val_loss: 5.6946 - val_accuracy: 0.1111\n",
      "Epoch 450/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5752 - accuracy: 0.3450 - val_loss: 5.7287 - val_accuracy: 0.1090\n",
      "Epoch 451/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5647 - accuracy: 0.3394 - val_loss: 5.7229 - val_accuracy: 0.1132\n",
      "Epoch 452/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5707 - accuracy: 0.3534 - val_loss: 5.7074 - val_accuracy: 0.1006\n",
      "Epoch 453/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5786 - accuracy: 0.3506 - val_loss: 5.7481 - val_accuracy: 0.1090\n",
      "Epoch 454/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.5665 - accuracy: 0.3562 - val_loss: 5.7470 - val_accuracy: 0.1111\n",
      "Epoch 455/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.5656 - accuracy: 0.3569 - val_loss: 5.7439 - val_accuracy: 0.1048\n",
      "Epoch 456/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.5675 - accuracy: 0.3492 - val_loss: 5.7454 - val_accuracy: 0.1195\n",
      "Epoch 457/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5614 - accuracy: 0.3499 - val_loss: 5.7371 - val_accuracy: 0.1132\n",
      "Epoch 458/500\n",
      "1429/1429 [==============================] - 0s 138us/step - loss: 2.5581 - accuracy: 0.3534 - val_loss: 5.7522 - val_accuracy: 0.1069\n",
      "Epoch 459/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5610 - accuracy: 0.3604 - val_loss: 5.7484 - val_accuracy: 0.1069\n",
      "Epoch 460/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5599 - accuracy: 0.3464 - val_loss: 5.7707 - val_accuracy: 0.1111\n",
      "Epoch 461/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5635 - accuracy: 0.3485 - val_loss: 5.7756 - val_accuracy: 0.1069\n",
      "Epoch 462/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5578 - accuracy: 0.3534 - val_loss: 5.7807 - val_accuracy: 0.1132\n",
      "Epoch 463/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.5592 - accuracy: 0.3548 - val_loss: 5.7605 - val_accuracy: 0.1090\n",
      "Epoch 464/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5506 - accuracy: 0.3590 - val_loss: 5.7826 - val_accuracy: 0.1090\n",
      "Epoch 465/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5552 - accuracy: 0.3555 - val_loss: 5.7858 - val_accuracy: 0.1069\n",
      "Epoch 466/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5591 - accuracy: 0.3520 - val_loss: 5.7964 - val_accuracy: 0.1111\n",
      "Epoch 467/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5582 - accuracy: 0.3590 - val_loss: 5.7785 - val_accuracy: 0.1153\n",
      "Epoch 468/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5632 - accuracy: 0.3548 - val_loss: 5.7829 - val_accuracy: 0.0985\n",
      "Epoch 469/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.5588 - accuracy: 0.3576 - val_loss: 5.7994 - val_accuracy: 0.1048\n",
      "Epoch 470/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5556 - accuracy: 0.3513 - val_loss: 5.7977 - val_accuracy: 0.1216\n",
      "Epoch 471/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5555 - accuracy: 0.3513 - val_loss: 5.8170 - val_accuracy: 0.1174\n",
      "Epoch 472/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5609 - accuracy: 0.3520 - val_loss: 5.8476 - val_accuracy: 0.1048\n",
      "Epoch 473/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5664 - accuracy: 0.3499 - val_loss: 5.8287 - val_accuracy: 0.1090\n",
      "Epoch 474/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5532 - accuracy: 0.3513 - val_loss: 5.7984 - val_accuracy: 0.1153\n",
      "Epoch 475/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5488 - accuracy: 0.3534 - val_loss: 5.8367 - val_accuracy: 0.1195\n",
      "Epoch 476/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5517 - accuracy: 0.3562 - val_loss: 5.8274 - val_accuracy: 0.1111\n",
      "Epoch 477/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5524 - accuracy: 0.3485 - val_loss: 5.8418 - val_accuracy: 0.1006\n",
      "Epoch 478/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.5557 - accuracy: 0.3492 - val_loss: 5.8495 - val_accuracy: 0.1069\n",
      "Epoch 479/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5561 - accuracy: 0.3527 - val_loss: 5.8427 - val_accuracy: 0.1069\n",
      "Epoch 480/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5549 - accuracy: 0.3527 - val_loss: 5.8572 - val_accuracy: 0.1048\n",
      "Epoch 481/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.5556 - accuracy: 0.3562 - val_loss: 5.8559 - val_accuracy: 0.1111\n",
      "Epoch 482/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.5506 - accuracy: 0.3590 - val_loss: 5.8712 - val_accuracy: 0.1132\n",
      "Epoch 483/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5564 - accuracy: 0.3506 - val_loss: 5.8582 - val_accuracy: 0.1111\n",
      "Epoch 484/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5519 - accuracy: 0.3527 - val_loss: 5.8576 - val_accuracy: 0.1048\n",
      "Epoch 485/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5562 - accuracy: 0.3506 - val_loss: 5.8679 - val_accuracy: 0.1153\n",
      "Epoch 486/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5529 - accuracy: 0.3632 - val_loss: 5.8724 - val_accuracy: 0.1111\n",
      "Epoch 487/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5464 - accuracy: 0.3555 - val_loss: 5.8979 - val_accuracy: 0.1069\n",
      "Epoch 488/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.5624 - accuracy: 0.3457 - val_loss: 5.8954 - val_accuracy: 0.1132\n",
      "Epoch 489/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5477 - accuracy: 0.3569 - val_loss: 5.8930 - val_accuracy: 0.1132\n",
      "Epoch 490/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5488 - accuracy: 0.3513 - val_loss: 5.8793 - val_accuracy: 0.1195\n",
      "Epoch 491/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5481 - accuracy: 0.3443 - val_loss: 5.9103 - val_accuracy: 0.1027\n",
      "Epoch 492/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.5472 - accuracy: 0.3583 - val_loss: 5.8981 - val_accuracy: 0.1195\n",
      "Epoch 493/500\n",
      "1429/1429 [==============================] - 0s 143us/step - loss: 2.5468 - accuracy: 0.3569 - val_loss: 5.8960 - val_accuracy: 0.1153\n",
      "Epoch 494/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5450 - accuracy: 0.3513 - val_loss: 5.9233 - val_accuracy: 0.1195\n",
      "Epoch 495/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.5442 - accuracy: 0.3590 - val_loss: 5.9141 - val_accuracy: 0.1132\n",
      "Epoch 496/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5444 - accuracy: 0.3506 - val_loss: 5.9212 - val_accuracy: 0.1090\n",
      "Epoch 497/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.5509 - accuracy: 0.3506 - val_loss: 5.9390 - val_accuracy: 0.1069\n",
      "Epoch 498/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5456 - accuracy: 0.3576 - val_loss: 5.9307 - val_accuracy: 0.1132\n",
      "Epoch 499/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.5510 - accuracy: 0.3611 - val_loss: 5.9360 - val_accuracy: 0.1111\n",
      "Epoch 500/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.5530 - accuracy: 0.3527 - val_loss: 5.9310 - val_accuracy: 0.1174\n",
      "Train on 1429 samples, validate on 477 samples\n",
      "Epoch 1/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 3.3473 - accuracy: 0.3009 - val_loss: 3.5529 - val_accuracy: 0.2662\n",
      "Epoch 2/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 3.2634 - accuracy: 0.2890 - val_loss: 3.5831 - val_accuracy: 0.2704\n",
      "Epoch 3/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 3.2438 - accuracy: 0.2904 - val_loss: 3.6216 - val_accuracy: 0.2243\n",
      "Epoch 4/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 3.1828 - accuracy: 0.2918 - val_loss: 3.6516 - val_accuracy: 0.2327\n",
      "Epoch 5/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 3.1553 - accuracy: 0.2995 - val_loss: 3.6671 - val_accuracy: 0.2180\n",
      "Epoch 6/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 3.1317 - accuracy: 0.2953 - val_loss: 3.6612 - val_accuracy: 0.2243\n",
      "Epoch 7/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 3.1160 - accuracy: 0.2967 - val_loss: 3.6866 - val_accuracy: 0.2222\n",
      "Epoch 8/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 3.0945 - accuracy: 0.2953 - val_loss: 3.6912 - val_accuracy: 0.2201\n",
      "Epoch 9/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 3.0755 - accuracy: 0.3023 - val_loss: 3.7000 - val_accuracy: 0.2201\n",
      "Epoch 10/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 3.0613 - accuracy: 0.3051 - val_loss: 3.7025 - val_accuracy: 0.2159\n",
      "Epoch 11/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 3.0554 - accuracy: 0.2981 - val_loss: 3.7238 - val_accuracy: 0.2117\n",
      "Epoch 12/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 3.0391 - accuracy: 0.3002 - val_loss: 3.7078 - val_accuracy: 0.2180\n",
      "Epoch 13/500\n",
      "1429/1429 [==============================] - 0s 121us/step - loss: 3.0264 - accuracy: 0.3002 - val_loss: 3.7077 - val_accuracy: 0.2159\n",
      "Epoch 14/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 3.0168 - accuracy: 0.3023 - val_loss: 3.7195 - val_accuracy: 0.2096\n",
      "Epoch 15/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 3.0073 - accuracy: 0.3079 - val_loss: 3.7433 - val_accuracy: 0.2055\n",
      "Epoch 16/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.9947 - accuracy: 0.2953 - val_loss: 3.7218 - val_accuracy: 0.2096\n",
      "Epoch 17/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.9799 - accuracy: 0.3072 - val_loss: 3.7331 - val_accuracy: 0.2013\n",
      "Epoch 18/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.9760 - accuracy: 0.3037 - val_loss: 3.7466 - val_accuracy: 0.1950\n",
      "Epoch 19/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.9705 - accuracy: 0.3072 - val_loss: 3.7519 - val_accuracy: 0.1887\n",
      "Epoch 20/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.9618 - accuracy: 0.3079 - val_loss: 3.7733 - val_accuracy: 0.2055\n",
      "Epoch 21/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.9546 - accuracy: 0.3058 - val_loss: 3.7485 - val_accuracy: 0.2034\n",
      "Epoch 22/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.9460 - accuracy: 0.3037 - val_loss: 3.7543 - val_accuracy: 0.1929\n",
      "Epoch 23/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.9335 - accuracy: 0.3002 - val_loss: 3.7839 - val_accuracy: 0.1971\n",
      "Epoch 24/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.9286 - accuracy: 0.3072 - val_loss: 3.7734 - val_accuracy: 0.1908\n",
      "Epoch 25/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.9222 - accuracy: 0.3100 - val_loss: 3.7859 - val_accuracy: 0.2034\n",
      "Epoch 26/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.9184 - accuracy: 0.3121 - val_loss: 3.7707 - val_accuracy: 0.2075\n",
      "Epoch 27/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.9181 - accuracy: 0.3093 - val_loss: 3.7821 - val_accuracy: 0.2034\n",
      "Epoch 28/500\n",
      "1429/1429 [==============================] - 0s 131us/step - loss: 2.9120 - accuracy: 0.3065 - val_loss: 3.7962 - val_accuracy: 0.1992\n",
      "Epoch 29/500\n",
      "1429/1429 [==============================] - 0s 129us/step - loss: 2.9072 - accuracy: 0.3114 - val_loss: 3.7808 - val_accuracy: 0.1992\n",
      "Epoch 30/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.9126 - accuracy: 0.3121 - val_loss: 3.7999 - val_accuracy: 0.1887\n",
      "Epoch 31/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.9012 - accuracy: 0.3009 - val_loss: 3.7961 - val_accuracy: 0.2013\n",
      "Epoch 32/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.8918 - accuracy: 0.3086 - val_loss: 3.8058 - val_accuracy: 0.1887\n",
      "Epoch 33/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.8911 - accuracy: 0.3149 - val_loss: 3.8039 - val_accuracy: 0.1908\n",
      "Epoch 34/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.8900 - accuracy: 0.3058 - val_loss: 3.8171 - val_accuracy: 0.2013\n",
      "Epoch 35/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.8929 - accuracy: 0.3121 - val_loss: 3.8371 - val_accuracy: 0.1971\n",
      "Epoch 36/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.8750 - accuracy: 0.3135 - val_loss: 3.8371 - val_accuracy: 0.1824\n",
      "Epoch 37/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.8793 - accuracy: 0.3051 - val_loss: 3.8207 - val_accuracy: 0.1950\n",
      "Epoch 38/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.8691 - accuracy: 0.3184 - val_loss: 3.8329 - val_accuracy: 0.1950\n",
      "Epoch 39/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.8744 - accuracy: 0.3163 - val_loss: 3.8398 - val_accuracy: 0.2013\n",
      "Epoch 40/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.8643 - accuracy: 0.3163 - val_loss: 3.8395 - val_accuracy: 0.1866\n",
      "Epoch 41/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.8670 - accuracy: 0.3114 - val_loss: 3.8458 - val_accuracy: 0.1887\n",
      "Epoch 42/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.8630 - accuracy: 0.3135 - val_loss: 3.8484 - val_accuracy: 0.2013\n",
      "Epoch 43/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.8590 - accuracy: 0.3170 - val_loss: 3.8477 - val_accuracy: 0.1866\n",
      "Epoch 44/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.8580 - accuracy: 0.3212 - val_loss: 3.8388 - val_accuracy: 0.1866\n",
      "Epoch 45/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.8519 - accuracy: 0.3163 - val_loss: 3.8713 - val_accuracy: 0.1887\n",
      "Epoch 46/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.8508 - accuracy: 0.3163 - val_loss: 3.8693 - val_accuracy: 0.1824\n",
      "Epoch 47/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.8500 - accuracy: 0.3170 - val_loss: 3.8934 - val_accuracy: 0.1782\n",
      "Epoch 48/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.8486 - accuracy: 0.3023 - val_loss: 3.8691 - val_accuracy: 0.1824\n",
      "Epoch 49/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.8425 - accuracy: 0.3142 - val_loss: 3.8738 - val_accuracy: 0.1740\n",
      "Epoch 50/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.8398 - accuracy: 0.3023 - val_loss: 3.8960 - val_accuracy: 0.1824\n",
      "Epoch 51/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.8402 - accuracy: 0.3191 - val_loss: 3.8839 - val_accuracy: 0.1845\n",
      "Epoch 52/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.8336 - accuracy: 0.3149 - val_loss: 3.8722 - val_accuracy: 0.1677\n",
      "Epoch 53/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.8289 - accuracy: 0.3233 - val_loss: 3.8868 - val_accuracy: 0.1845\n",
      "Epoch 54/500\n",
      "1429/1429 [==============================] - 0s 93us/step - loss: 2.8292 - accuracy: 0.3233 - val_loss: 3.8841 - val_accuracy: 0.1761\n",
      "Epoch 55/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.8263 - accuracy: 0.3184 - val_loss: 3.9004 - val_accuracy: 0.1929\n",
      "Epoch 56/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.8187 - accuracy: 0.3184 - val_loss: 3.8963 - val_accuracy: 0.1803\n",
      "Epoch 57/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.8205 - accuracy: 0.3156 - val_loss: 3.9019 - val_accuracy: 0.1824\n",
      "Epoch 58/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.8208 - accuracy: 0.3177 - val_loss: 3.9058 - val_accuracy: 0.1803\n",
      "Epoch 59/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.8159 - accuracy: 0.3191 - val_loss: 3.8920 - val_accuracy: 0.1761\n",
      "Epoch 60/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.8122 - accuracy: 0.3198 - val_loss: 3.9260 - val_accuracy: 0.1677\n",
      "Epoch 61/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.8164 - accuracy: 0.3128 - val_loss: 3.9143 - val_accuracy: 0.1782\n",
      "Epoch 62/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.8118 - accuracy: 0.3226 - val_loss: 3.9151 - val_accuracy: 0.1761\n",
      "Epoch 63/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.8046 - accuracy: 0.3219 - val_loss: 3.9198 - val_accuracy: 0.1719\n",
      "Epoch 64/500\n",
      "1429/1429 [==============================] - 0s 141us/step - loss: 2.8058 - accuracy: 0.3191 - val_loss: 3.9147 - val_accuracy: 0.1866\n",
      "Epoch 65/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.8058 - accuracy: 0.3170 - val_loss: 3.9301 - val_accuracy: 0.1677\n",
      "Epoch 66/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.8002 - accuracy: 0.3240 - val_loss: 3.9180 - val_accuracy: 0.1761\n",
      "Epoch 67/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7964 - accuracy: 0.3191 - val_loss: 3.9170 - val_accuracy: 0.1761\n",
      "Epoch 68/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7948 - accuracy: 0.3240 - val_loss: 3.9485 - val_accuracy: 0.1761\n",
      "Epoch 69/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.7941 - accuracy: 0.3184 - val_loss: 3.9380 - val_accuracy: 0.1719\n",
      "Epoch 70/500\n",
      "1429/1429 [==============================] - 0s 90us/step - loss: 2.7928 - accuracy: 0.3156 - val_loss: 3.9220 - val_accuracy: 0.1761\n",
      "Epoch 71/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7948 - accuracy: 0.3184 - val_loss: 3.9528 - val_accuracy: 0.1782\n",
      "Epoch 72/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7947 - accuracy: 0.3149 - val_loss: 3.9545 - val_accuracy: 0.1677\n",
      "Epoch 73/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.7858 - accuracy: 0.3219 - val_loss: 3.9573 - val_accuracy: 0.1740\n",
      "Epoch 74/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7892 - accuracy: 0.3191 - val_loss: 3.9430 - val_accuracy: 0.1551\n",
      "Epoch 75/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7875 - accuracy: 0.3184 - val_loss: 3.9488 - val_accuracy: 0.1698\n",
      "Epoch 76/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7781 - accuracy: 0.3163 - val_loss: 3.9435 - val_accuracy: 0.1656\n",
      "Epoch 77/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.7809 - accuracy: 0.3205 - val_loss: 3.9591 - val_accuracy: 0.1698\n",
      "Epoch 78/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7747 - accuracy: 0.3149 - val_loss: 3.9732 - val_accuracy: 0.1677\n",
      "Epoch 79/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.7810 - accuracy: 0.3275 - val_loss: 3.9843 - val_accuracy: 0.1719\n",
      "Epoch 80/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.7800 - accuracy: 0.3219 - val_loss: 3.9625 - val_accuracy: 0.1698\n",
      "Epoch 81/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.7766 - accuracy: 0.3205 - val_loss: 3.9828 - val_accuracy: 0.1530\n",
      "Epoch 82/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.7695 - accuracy: 0.3212 - val_loss: 3.9615 - val_accuracy: 0.1635\n",
      "Epoch 83/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7715 - accuracy: 0.3247 - val_loss: 3.9626 - val_accuracy: 0.1635\n",
      "Epoch 84/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7689 - accuracy: 0.3163 - val_loss: 3.9611 - val_accuracy: 0.1719\n",
      "Epoch 85/500\n",
      "1429/1429 [==============================] - 0s 115us/step - loss: 2.7693 - accuracy: 0.3233 - val_loss: 3.9912 - val_accuracy: 0.1509\n",
      "Epoch 86/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.7651 - accuracy: 0.3240 - val_loss: 3.9889 - val_accuracy: 0.1614\n",
      "Epoch 87/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.7642 - accuracy: 0.3184 - val_loss: 3.9624 - val_accuracy: 0.1488\n",
      "Epoch 88/500\n",
      "1429/1429 [==============================] - 0s 93us/step - loss: 2.7558 - accuracy: 0.3247 - val_loss: 4.0014 - val_accuracy: 0.1530\n",
      "Epoch 89/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7700 - accuracy: 0.3254 - val_loss: 3.9834 - val_accuracy: 0.1572\n",
      "Epoch 90/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.7558 - accuracy: 0.3198 - val_loss: 3.9995 - val_accuracy: 0.1698\n",
      "Epoch 91/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.7543 - accuracy: 0.3170 - val_loss: 4.0037 - val_accuracy: 0.1656\n",
      "Epoch 92/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7535 - accuracy: 0.3247 - val_loss: 4.0005 - val_accuracy: 0.1593\n",
      "Epoch 93/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.7537 - accuracy: 0.3219 - val_loss: 4.0059 - val_accuracy: 0.1551\n",
      "Epoch 94/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7497 - accuracy: 0.3191 - val_loss: 4.0068 - val_accuracy: 0.1635\n",
      "Epoch 95/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.7578 - accuracy: 0.3205 - val_loss: 4.0250 - val_accuracy: 0.1551\n",
      "Epoch 96/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7508 - accuracy: 0.3212 - val_loss: 4.0146 - val_accuracy: 0.1530\n",
      "Epoch 97/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7513 - accuracy: 0.3128 - val_loss: 3.9987 - val_accuracy: 0.1593\n",
      "Epoch 98/500\n",
      "1429/1429 [==============================] - 0s 124us/step - loss: 2.7419 - accuracy: 0.3177 - val_loss: 4.0208 - val_accuracy: 0.1405\n",
      "Epoch 99/500\n",
      "1429/1429 [==============================] - 0s 139us/step - loss: 2.7422 - accuracy: 0.3233 - val_loss: 4.0155 - val_accuracy: 0.1656\n",
      "Epoch 100/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.7453 - accuracy: 0.3282 - val_loss: 4.0228 - val_accuracy: 0.1488\n",
      "Epoch 101/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.7438 - accuracy: 0.3247 - val_loss: 4.0425 - val_accuracy: 0.1530\n",
      "Epoch 102/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7404 - accuracy: 0.3198 - val_loss: 4.0304 - val_accuracy: 0.1677\n",
      "Epoch 103/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.7351 - accuracy: 0.3247 - val_loss: 4.0280 - val_accuracy: 0.1572\n",
      "Epoch 104/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.7366 - accuracy: 0.3212 - val_loss: 4.0304 - val_accuracy: 0.1656\n",
      "Epoch 105/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7301 - accuracy: 0.3296 - val_loss: 4.0252 - val_accuracy: 0.1509\n",
      "Epoch 106/500\n",
      "1429/1429 [==============================] - 0s 125us/step - loss: 2.7324 - accuracy: 0.3212 - val_loss: 4.0483 - val_accuracy: 0.1530\n",
      "Epoch 107/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7316 - accuracy: 0.3275 - val_loss: 4.0418 - val_accuracy: 0.1488\n",
      "Epoch 108/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7292 - accuracy: 0.3184 - val_loss: 4.0405 - val_accuracy: 0.1572\n",
      "Epoch 109/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.7248 - accuracy: 0.3184 - val_loss: 4.0504 - val_accuracy: 0.1677\n",
      "Epoch 110/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7255 - accuracy: 0.3282 - val_loss: 4.0420 - val_accuracy: 0.1530\n",
      "Epoch 111/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.7189 - accuracy: 0.3198 - val_loss: 4.0626 - val_accuracy: 0.1551\n",
      "Epoch 112/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7260 - accuracy: 0.3240 - val_loss: 4.0537 - val_accuracy: 0.1551\n",
      "Epoch 113/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7268 - accuracy: 0.3247 - val_loss: 4.0610 - val_accuracy: 0.1509\n",
      "Epoch 114/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.7219 - accuracy: 0.3282 - val_loss: 4.0656 - val_accuracy: 0.1593\n",
      "Epoch 115/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7149 - accuracy: 0.3226 - val_loss: 4.0632 - val_accuracy: 0.1593\n",
      "Epoch 116/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7183 - accuracy: 0.3275 - val_loss: 4.0459 - val_accuracy: 0.1530\n",
      "Epoch 117/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.7159 - accuracy: 0.3275 - val_loss: 4.0644 - val_accuracy: 0.1572\n",
      "Epoch 118/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.7147 - accuracy: 0.3226 - val_loss: 4.0707 - val_accuracy: 0.1384\n",
      "Epoch 119/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7164 - accuracy: 0.3254 - val_loss: 4.1025 - val_accuracy: 0.1488\n",
      "Epoch 120/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.7153 - accuracy: 0.3268 - val_loss: 4.0920 - val_accuracy: 0.1447\n",
      "Epoch 121/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7125 - accuracy: 0.3198 - val_loss: 4.0763 - val_accuracy: 0.1572\n",
      "Epoch 122/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7085 - accuracy: 0.3233 - val_loss: 4.0845 - val_accuracy: 0.1530\n",
      "Epoch 123/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.7063 - accuracy: 0.3310 - val_loss: 4.0758 - val_accuracy: 0.1530\n",
      "Epoch 124/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.7082 - accuracy: 0.3233 - val_loss: 4.0776 - val_accuracy: 0.1551\n",
      "Epoch 125/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.7068 - accuracy: 0.3205 - val_loss: 4.1017 - val_accuracy: 0.1405\n",
      "Epoch 126/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.7066 - accuracy: 0.3261 - val_loss: 4.0830 - val_accuracy: 0.1656\n",
      "Epoch 127/500\n",
      "1429/1429 [==============================] - 0s 118us/step - loss: 2.7031 - accuracy: 0.3128 - val_loss: 4.0954 - val_accuracy: 0.1426\n",
      "Epoch 128/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7001 - accuracy: 0.3254 - val_loss: 4.0978 - val_accuracy: 0.1384\n",
      "Epoch 129/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6998 - accuracy: 0.3331 - val_loss: 4.1240 - val_accuracy: 0.1468\n",
      "Epoch 130/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6973 - accuracy: 0.3219 - val_loss: 4.1065 - val_accuracy: 0.1509\n",
      "Epoch 131/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.7050 - accuracy: 0.3247 - val_loss: 4.1168 - val_accuracy: 0.1426\n",
      "Epoch 132/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.7039 - accuracy: 0.3254 - val_loss: 4.1230 - val_accuracy: 0.1488\n",
      "Epoch 133/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6986 - accuracy: 0.3268 - val_loss: 4.1459 - val_accuracy: 0.1426\n",
      "Epoch 134/500\n",
      "1429/1429 [==============================] - 0s 141us/step - loss: 2.6959 - accuracy: 0.3282 - val_loss: 4.1385 - val_accuracy: 0.1488\n",
      "Epoch 135/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.6906 - accuracy: 0.3303 - val_loss: 4.1397 - val_accuracy: 0.1321\n",
      "Epoch 136/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.6905 - accuracy: 0.3317 - val_loss: 4.1379 - val_accuracy: 0.1551\n",
      "Epoch 137/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.7015 - accuracy: 0.3233 - val_loss: 4.1403 - val_accuracy: 0.1405\n",
      "Epoch 138/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6901 - accuracy: 0.3226 - val_loss: 4.1527 - val_accuracy: 0.1426\n",
      "Epoch 139/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6856 - accuracy: 0.3261 - val_loss: 4.1516 - val_accuracy: 0.1384\n",
      "Epoch 140/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.6931 - accuracy: 0.3275 - val_loss: 4.1619 - val_accuracy: 0.1384\n",
      "Epoch 141/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6905 - accuracy: 0.3254 - val_loss: 4.1582 - val_accuracy: 0.1426\n",
      "Epoch 142/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6869 - accuracy: 0.3296 - val_loss: 4.1728 - val_accuracy: 0.1447\n",
      "Epoch 143/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6864 - accuracy: 0.3338 - val_loss: 4.1617 - val_accuracy: 0.1405\n",
      "Epoch 144/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6839 - accuracy: 0.3366 - val_loss: 4.1620 - val_accuracy: 0.1342\n",
      "Epoch 145/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6838 - accuracy: 0.3310 - val_loss: 4.1597 - val_accuracy: 0.1468\n",
      "Epoch 146/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6879 - accuracy: 0.3303 - val_loss: 4.1801 - val_accuracy: 0.1488\n",
      "Epoch 147/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6809 - accuracy: 0.3289 - val_loss: 4.1670 - val_accuracy: 0.1447\n",
      "Epoch 148/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6865 - accuracy: 0.3268 - val_loss: 4.1605 - val_accuracy: 0.1405\n",
      "Epoch 149/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6808 - accuracy: 0.3261 - val_loss: 4.1915 - val_accuracy: 0.1468\n",
      "Epoch 150/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6793 - accuracy: 0.3275 - val_loss: 4.1838 - val_accuracy: 0.1488\n",
      "Epoch 151/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.6739 - accuracy: 0.3373 - val_loss: 4.1985 - val_accuracy: 0.1342\n",
      "Epoch 152/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6794 - accuracy: 0.3268 - val_loss: 4.1977 - val_accuracy: 0.1468\n",
      "Epoch 153/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6789 - accuracy: 0.3282 - val_loss: 4.1729 - val_accuracy: 0.1468\n",
      "Epoch 154/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6768 - accuracy: 0.3233 - val_loss: 4.1932 - val_accuracy: 0.1447\n",
      "Epoch 155/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6830 - accuracy: 0.3282 - val_loss: 4.2116 - val_accuracy: 0.1426\n",
      "Epoch 156/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.6738 - accuracy: 0.3303 - val_loss: 4.2298 - val_accuracy: 0.1363\n",
      "Epoch 157/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.6750 - accuracy: 0.3380 - val_loss: 4.2178 - val_accuracy: 0.1468\n",
      "Epoch 158/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.6733 - accuracy: 0.3387 - val_loss: 4.2163 - val_accuracy: 0.1342\n",
      "Epoch 159/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6751 - accuracy: 0.3310 - val_loss: 4.1999 - val_accuracy: 0.1426\n",
      "Epoch 160/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6723 - accuracy: 0.3352 - val_loss: 4.2128 - val_accuracy: 0.1342\n",
      "Epoch 161/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.6687 - accuracy: 0.3282 - val_loss: 4.2402 - val_accuracy: 0.1426\n",
      "Epoch 162/500\n",
      "1429/1429 [==============================] - 0s 118us/step - loss: 2.6728 - accuracy: 0.3317 - val_loss: 4.2411 - val_accuracy: 0.1509\n",
      "Epoch 163/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.6703 - accuracy: 0.3352 - val_loss: 4.2379 - val_accuracy: 0.1363\n",
      "Epoch 164/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.6734 - accuracy: 0.3254 - val_loss: 4.2341 - val_accuracy: 0.1426\n",
      "Epoch 165/500\n",
      "1429/1429 [==============================] - 0s 122us/step - loss: 2.6707 - accuracy: 0.3289 - val_loss: 4.2339 - val_accuracy: 0.1426\n",
      "Epoch 166/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.6693 - accuracy: 0.3394 - val_loss: 4.2526 - val_accuracy: 0.1509\n",
      "Epoch 167/500\n",
      "1429/1429 [==============================] - 0s 115us/step - loss: 2.6707 - accuracy: 0.3324 - val_loss: 4.2615 - val_accuracy: 0.1488\n",
      "Epoch 168/500\n",
      "1429/1429 [==============================] - 0s 145us/step - loss: 2.6635 - accuracy: 0.3331 - val_loss: 4.2511 - val_accuracy: 0.1384\n",
      "Epoch 169/500\n",
      "1429/1429 [==============================] - 0s 126us/step - loss: 2.6643 - accuracy: 0.3429 - val_loss: 4.2517 - val_accuracy: 0.1405\n",
      "Epoch 170/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.6619 - accuracy: 0.3352 - val_loss: 4.2517 - val_accuracy: 0.1426\n",
      "Epoch 171/500\n",
      "1429/1429 [==============================] - 0s 133us/step - loss: 2.6699 - accuracy: 0.3289 - val_loss: 4.2782 - val_accuracy: 0.1405\n",
      "Epoch 172/500\n",
      "1429/1429 [==============================] - 0s 153us/step - loss: 2.6576 - accuracy: 0.3366 - val_loss: 4.2737 - val_accuracy: 0.1321\n",
      "Epoch 173/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.6617 - accuracy: 0.3198 - val_loss: 4.3056 - val_accuracy: 0.1405\n",
      "Epoch 174/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.6581 - accuracy: 0.3359 - val_loss: 4.2814 - val_accuracy: 0.1363\n",
      "Epoch 175/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.6643 - accuracy: 0.3331 - val_loss: 4.2496 - val_accuracy: 0.1447\n",
      "Epoch 176/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.6569 - accuracy: 0.3352 - val_loss: 4.2883 - val_accuracy: 0.1468\n",
      "Epoch 177/500\n",
      "1429/1429 [==============================] - 0s 123us/step - loss: 2.6589 - accuracy: 0.3296 - val_loss: 4.3121 - val_accuracy: 0.1447\n",
      "Epoch 178/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.6523 - accuracy: 0.3303 - val_loss: 4.3000 - val_accuracy: 0.1363\n",
      "Epoch 179/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.6596 - accuracy: 0.3254 - val_loss: 4.2947 - val_accuracy: 0.1321\n",
      "Epoch 180/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.6571 - accuracy: 0.3282 - val_loss: 4.2928 - val_accuracy: 0.1426\n",
      "Epoch 181/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6577 - accuracy: 0.3380 - val_loss: 4.3037 - val_accuracy: 0.1405\n",
      "Epoch 182/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6489 - accuracy: 0.3324 - val_loss: 4.3103 - val_accuracy: 0.1363\n",
      "Epoch 183/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6534 - accuracy: 0.3338 - val_loss: 4.3114 - val_accuracy: 0.1321\n",
      "Epoch 184/500\n",
      "1429/1429 [==============================] - 0s 130us/step - loss: 2.6510 - accuracy: 0.3310 - val_loss: 4.3316 - val_accuracy: 0.1300\n",
      "Epoch 185/500\n",
      "1429/1429 [==============================] - 0s 173us/step - loss: 2.6572 - accuracy: 0.3268 - val_loss: 4.3557 - val_accuracy: 0.1384\n",
      "Epoch 186/500\n",
      "1429/1429 [==============================] - 0s 132us/step - loss: 2.6524 - accuracy: 0.3296 - val_loss: 4.3275 - val_accuracy: 0.1405\n",
      "Epoch 187/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.6493 - accuracy: 0.3401 - val_loss: 4.3550 - val_accuracy: 0.1363\n",
      "Epoch 188/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.6508 - accuracy: 0.3506 - val_loss: 4.3255 - val_accuracy: 0.1384\n",
      "Epoch 189/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.6525 - accuracy: 0.3345 - val_loss: 4.3418 - val_accuracy: 0.1342\n",
      "Epoch 190/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.6491 - accuracy: 0.3352 - val_loss: 4.3556 - val_accuracy: 0.1342\n",
      "Epoch 191/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6514 - accuracy: 0.3352 - val_loss: 4.3522 - val_accuracy: 0.1216\n",
      "Epoch 192/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.6503 - accuracy: 0.3443 - val_loss: 4.3323 - val_accuracy: 0.1321\n",
      "Epoch 193/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6496 - accuracy: 0.3310 - val_loss: 4.3641 - val_accuracy: 0.1468\n",
      "Epoch 194/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6457 - accuracy: 0.3310 - val_loss: 4.3533 - val_accuracy: 0.1363\n",
      "Epoch 195/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6515 - accuracy: 0.3282 - val_loss: 4.3941 - val_accuracy: 0.1342\n",
      "Epoch 196/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6486 - accuracy: 0.3359 - val_loss: 4.3977 - val_accuracy: 0.1342\n",
      "Epoch 197/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6426 - accuracy: 0.3331 - val_loss: 4.3787 - val_accuracy: 0.1300\n",
      "Epoch 198/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.6362 - accuracy: 0.3289 - val_loss: 4.3731 - val_accuracy: 0.1321\n",
      "Epoch 199/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6394 - accuracy: 0.3359 - val_loss: 4.3990 - val_accuracy: 0.1342\n",
      "Epoch 200/500\n",
      "1429/1429 [==============================] - 0s 123us/step - loss: 2.6425 - accuracy: 0.3408 - val_loss: 4.4094 - val_accuracy: 0.1300\n",
      "Epoch 201/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.6483 - accuracy: 0.3352 - val_loss: 4.4049 - val_accuracy: 0.1321\n",
      "Epoch 202/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.6406 - accuracy: 0.3394 - val_loss: 4.3986 - val_accuracy: 0.1426\n",
      "Epoch 203/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6327 - accuracy: 0.3345 - val_loss: 4.3862 - val_accuracy: 0.1300\n",
      "Epoch 204/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 2.6332 - accuracy: 0.3401 - val_loss: 4.4230 - val_accuracy: 0.1300\n",
      "Epoch 205/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.6394 - accuracy: 0.3317 - val_loss: 4.4070 - val_accuracy: 0.1384\n",
      "Epoch 206/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6355 - accuracy: 0.3429 - val_loss: 4.4129 - val_accuracy: 0.1363\n",
      "Epoch 207/500\n",
      "1429/1429 [==============================] - 0s 87us/step - loss: 2.6324 - accuracy: 0.3352 - val_loss: 4.4249 - val_accuracy: 0.1279\n",
      "Epoch 208/500\n",
      "1429/1429 [==============================] - 0s 86us/step - loss: 2.6354 - accuracy: 0.3366 - val_loss: 4.4421 - val_accuracy: 0.1384\n",
      "Epoch 209/500\n",
      "1429/1429 [==============================] - 0s 88us/step - loss: 2.6328 - accuracy: 0.3415 - val_loss: 4.4555 - val_accuracy: 0.1279\n",
      "Epoch 210/500\n",
      "1429/1429 [==============================] - 0s 88us/step - loss: 2.6370 - accuracy: 0.3373 - val_loss: 4.4442 - val_accuracy: 0.1405\n",
      "Epoch 211/500\n",
      "1429/1429 [==============================] - 0s 88us/step - loss: 2.6383 - accuracy: 0.3303 - val_loss: 4.4443 - val_accuracy: 0.1342\n",
      "Epoch 212/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6285 - accuracy: 0.3408 - val_loss: 4.4383 - val_accuracy: 0.1237\n",
      "Epoch 213/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.6289 - accuracy: 0.3352 - val_loss: 4.4498 - val_accuracy: 0.1426\n",
      "Epoch 214/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.6268 - accuracy: 0.3373 - val_loss: 4.4674 - val_accuracy: 0.1237\n",
      "Epoch 215/500\n",
      "1429/1429 [==============================] - 0s 122us/step - loss: 2.6317 - accuracy: 0.3324 - val_loss: 4.4750 - val_accuracy: 0.1321\n",
      "Epoch 216/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6340 - accuracy: 0.3443 - val_loss: 4.4783 - val_accuracy: 0.1237\n",
      "Epoch 217/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.6341 - accuracy: 0.3331 - val_loss: 4.4674 - val_accuracy: 0.1300\n",
      "Epoch 218/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6271 - accuracy: 0.3422 - val_loss: 4.4624 - val_accuracy: 0.1279\n",
      "Epoch 219/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.6292 - accuracy: 0.3422 - val_loss: 4.4715 - val_accuracy: 0.1300\n",
      "Epoch 220/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6356 - accuracy: 0.3317 - val_loss: 4.4750 - val_accuracy: 0.1405\n",
      "Epoch 221/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.6291 - accuracy: 0.3296 - val_loss: 4.4875 - val_accuracy: 0.1279\n",
      "Epoch 222/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.6253 - accuracy: 0.3429 - val_loss: 4.5007 - val_accuracy: 0.1237\n",
      "Epoch 223/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.6232 - accuracy: 0.3471 - val_loss: 4.4950 - val_accuracy: 0.1237\n",
      "Epoch 224/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6221 - accuracy: 0.3443 - val_loss: 4.5132 - val_accuracy: 0.1300\n",
      "Epoch 225/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6219 - accuracy: 0.3478 - val_loss: 4.5215 - val_accuracy: 0.1258\n",
      "Epoch 226/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.6194 - accuracy: 0.3338 - val_loss: 4.5106 - val_accuracy: 0.1300\n",
      "Epoch 227/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.6212 - accuracy: 0.3436 - val_loss: 4.5390 - val_accuracy: 0.1300\n",
      "Epoch 228/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.6275 - accuracy: 0.3401 - val_loss: 4.5450 - val_accuracy: 0.1237\n",
      "Epoch 229/500\n",
      "1429/1429 [==============================] - 0s 93us/step - loss: 2.6236 - accuracy: 0.3324 - val_loss: 4.5404 - val_accuracy: 0.1279\n",
      "Epoch 230/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.6221 - accuracy: 0.3331 - val_loss: 4.5278 - val_accuracy: 0.1363\n",
      "Epoch 231/500\n",
      "1429/1429 [==============================] - 0s 87us/step - loss: 2.6186 - accuracy: 0.3345 - val_loss: 4.5529 - val_accuracy: 0.1342\n",
      "Epoch 232/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6176 - accuracy: 0.3366 - val_loss: 4.5528 - val_accuracy: 0.1363\n",
      "Epoch 233/500\n",
      "1429/1429 [==============================] - 0s 93us/step - loss: 2.6188 - accuracy: 0.3429 - val_loss: 4.5521 - val_accuracy: 0.1216\n",
      "Epoch 234/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.6191 - accuracy: 0.3436 - val_loss: 4.5577 - val_accuracy: 0.1321\n",
      "Epoch 235/500\n",
      "1429/1429 [==============================] - 0s 133us/step - loss: 2.6221 - accuracy: 0.3324 - val_loss: 4.5680 - val_accuracy: 0.1342\n",
      "Epoch 236/500\n",
      "1429/1429 [==============================] - 0s 126us/step - loss: 2.6178 - accuracy: 0.3401 - val_loss: 4.5705 - val_accuracy: 0.1405\n",
      "Epoch 237/500\n",
      "1429/1429 [==============================] - 0s 130us/step - loss: 2.6171 - accuracy: 0.3450 - val_loss: 4.5709 - val_accuracy: 0.1342\n",
      "Epoch 238/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.6217 - accuracy: 0.3471 - val_loss: 4.5916 - val_accuracy: 0.1321\n",
      "Epoch 239/500\n",
      "1429/1429 [==============================] - 0s 120us/step - loss: 2.6199 - accuracy: 0.3429 - val_loss: 4.5733 - val_accuracy: 0.1258\n",
      "Epoch 240/500\n",
      "1429/1429 [==============================] - 0s 148us/step - loss: 2.6137 - accuracy: 0.3485 - val_loss: 4.6138 - val_accuracy: 0.1174\n",
      "Epoch 241/500\n",
      "1429/1429 [==============================] - 0s 118us/step - loss: 2.6140 - accuracy: 0.3345 - val_loss: 4.5776 - val_accuracy: 0.1300\n",
      "Epoch 242/500\n",
      "1429/1429 [==============================] - 0s 124us/step - loss: 2.6124 - accuracy: 0.3380 - val_loss: 4.5909 - val_accuracy: 0.1300\n",
      "Epoch 243/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.6118 - accuracy: 0.3401 - val_loss: 4.6296 - val_accuracy: 0.1216\n",
      "Epoch 244/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6149 - accuracy: 0.3436 - val_loss: 4.6188 - val_accuracy: 0.1279\n",
      "Epoch 245/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6147 - accuracy: 0.3415 - val_loss: 4.6234 - val_accuracy: 0.1216\n",
      "Epoch 246/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6142 - accuracy: 0.3408 - val_loss: 4.6045 - val_accuracy: 0.1237\n",
      "Epoch 247/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6095 - accuracy: 0.3380 - val_loss: 4.6192 - val_accuracy: 0.1237\n",
      "Epoch 248/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 2.6125 - accuracy: 0.3492 - val_loss: 4.6604 - val_accuracy: 0.1258\n",
      "Epoch 249/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6184 - accuracy: 0.3485 - val_loss: 4.6211 - val_accuracy: 0.1216\n",
      "Epoch 250/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6079 - accuracy: 0.3408 - val_loss: 4.6377 - val_accuracy: 0.1300\n",
      "Epoch 251/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.6082 - accuracy: 0.3387 - val_loss: 4.6405 - val_accuracy: 0.1300\n",
      "Epoch 252/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6078 - accuracy: 0.3331 - val_loss: 4.6717 - val_accuracy: 0.1279\n",
      "Epoch 253/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6085 - accuracy: 0.3464 - val_loss: 4.6797 - val_accuracy: 0.1153\n",
      "Epoch 254/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.6078 - accuracy: 0.3408 - val_loss: 4.6815 - val_accuracy: 0.1279\n",
      "Epoch 255/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.6110 - accuracy: 0.3450 - val_loss: 4.6629 - val_accuracy: 0.1279\n",
      "Epoch 256/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.6117 - accuracy: 0.3401 - val_loss: 4.6822 - val_accuracy: 0.1195\n",
      "Epoch 257/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6084 - accuracy: 0.3443 - val_loss: 4.6878 - val_accuracy: 0.1174\n",
      "Epoch 258/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6042 - accuracy: 0.3373 - val_loss: 4.7029 - val_accuracy: 0.1174\n",
      "Epoch 259/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6090 - accuracy: 0.3499 - val_loss: 4.7033 - val_accuracy: 0.1300\n",
      "Epoch 260/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6026 - accuracy: 0.3429 - val_loss: 4.6748 - val_accuracy: 0.1258\n",
      "Epoch 261/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.6044 - accuracy: 0.3359 - val_loss: 4.6860 - val_accuracy: 0.1195\n",
      "Epoch 262/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6048 - accuracy: 0.3436 - val_loss: 4.7253 - val_accuracy: 0.1195\n",
      "Epoch 263/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.6003 - accuracy: 0.3436 - val_loss: 4.7039 - val_accuracy: 0.1342\n",
      "Epoch 264/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6104 - accuracy: 0.3408 - val_loss: 4.7170 - val_accuracy: 0.1174\n",
      "Epoch 265/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.6075 - accuracy: 0.3429 - val_loss: 4.7126 - val_accuracy: 0.1237\n",
      "Epoch 266/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.6091 - accuracy: 0.3373 - val_loss: 4.7105 - val_accuracy: 0.1363\n",
      "Epoch 267/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.5969 - accuracy: 0.3506 - val_loss: 4.7392 - val_accuracy: 0.1300\n",
      "Epoch 268/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6043 - accuracy: 0.3534 - val_loss: 4.7461 - val_accuracy: 0.1258\n",
      "Epoch 269/500\n",
      "1429/1429 [==============================] - 0s 118us/step - loss: 2.5905 - accuracy: 0.3457 - val_loss: 4.7379 - val_accuracy: 0.1216\n",
      "Epoch 270/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 2.5953 - accuracy: 0.3366 - val_loss: 4.7676 - val_accuracy: 0.1237\n",
      "Epoch 271/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6013 - accuracy: 0.3485 - val_loss: 4.7488 - val_accuracy: 0.1216\n",
      "Epoch 272/500\n",
      "1429/1429 [==============================] - 0s 133us/step - loss: 2.5996 - accuracy: 0.3380 - val_loss: 4.7539 - val_accuracy: 0.1258\n",
      "Epoch 273/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.6005 - accuracy: 0.3443 - val_loss: 4.7798 - val_accuracy: 0.1237\n",
      "Epoch 274/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.5935 - accuracy: 0.3436 - val_loss: 4.7837 - val_accuracy: 0.1237\n",
      "Epoch 275/500\n",
      "1429/1429 [==============================] - 0s 90us/step - loss: 2.5968 - accuracy: 0.3534 - val_loss: 4.7933 - val_accuracy: 0.1300\n",
      "Epoch 276/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 2.6006 - accuracy: 0.3478 - val_loss: 4.7965 - val_accuracy: 0.1237\n",
      "Epoch 277/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.5916 - accuracy: 0.3394 - val_loss: 4.8226 - val_accuracy: 0.1321\n",
      "Epoch 278/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.5957 - accuracy: 0.3541 - val_loss: 4.8158 - val_accuracy: 0.1258\n",
      "Epoch 279/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.5955 - accuracy: 0.3464 - val_loss: 4.8319 - val_accuracy: 0.1153\n",
      "Epoch 280/500\n",
      "1429/1429 [==============================] - 0s 90us/step - loss: 2.5969 - accuracy: 0.3415 - val_loss: 4.8298 - val_accuracy: 0.1153\n",
      "Epoch 281/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.6042 - accuracy: 0.3492 - val_loss: 4.8412 - val_accuracy: 0.1321\n",
      "Epoch 282/500\n",
      "1429/1429 [==============================] - 0s 93us/step - loss: 2.5926 - accuracy: 0.3443 - val_loss: 4.8403 - val_accuracy: 0.1258\n",
      "Epoch 283/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.5917 - accuracy: 0.3373 - val_loss: 4.8336 - val_accuracy: 0.1153\n",
      "Epoch 284/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.5957 - accuracy: 0.3450 - val_loss: 4.8457 - val_accuracy: 0.1174\n",
      "Epoch 285/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.5932 - accuracy: 0.3506 - val_loss: 4.8563 - val_accuracy: 0.1216\n",
      "Epoch 286/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 2.5961 - accuracy: 0.3520 - val_loss: 4.8725 - val_accuracy: 0.1237\n",
      "Epoch 287/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.5918 - accuracy: 0.3541 - val_loss: 4.8841 - val_accuracy: 0.1237\n",
      "Epoch 288/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.5887 - accuracy: 0.3499 - val_loss: 4.8895 - val_accuracy: 0.1111\n",
      "Epoch 289/500\n",
      "1429/1429 [==============================] - 0s 126us/step - loss: 2.5978 - accuracy: 0.3366 - val_loss: 4.8812 - val_accuracy: 0.1132\n",
      "Epoch 290/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.5906 - accuracy: 0.3387 - val_loss: 4.8968 - val_accuracy: 0.1258\n",
      "Epoch 291/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.5871 - accuracy: 0.3485 - val_loss: 4.9184 - val_accuracy: 0.1174\n",
      "Epoch 292/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5877 - accuracy: 0.3499 - val_loss: 4.9141 - val_accuracy: 0.1363\n",
      "Epoch 293/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.5862 - accuracy: 0.3506 - val_loss: 4.9056 - val_accuracy: 0.1174\n",
      "Epoch 294/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 2.5924 - accuracy: 0.3464 - val_loss: 4.9109 - val_accuracy: 0.1195\n",
      "Epoch 295/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.5893 - accuracy: 0.3485 - val_loss: 4.9471 - val_accuracy: 0.1195\n",
      "Epoch 296/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.5906 - accuracy: 0.3464 - val_loss: 4.9288 - val_accuracy: 0.1300\n",
      "Epoch 297/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.5893 - accuracy: 0.3471 - val_loss: 4.9317 - val_accuracy: 0.1237\n",
      "Epoch 298/500\n",
      "1429/1429 [==============================] - 0s 129us/step - loss: 2.5877 - accuracy: 0.3380 - val_loss: 4.9454 - val_accuracy: 0.1195\n",
      "Epoch 299/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5909 - accuracy: 0.3492 - val_loss: 4.9531 - val_accuracy: 0.1237\n",
      "Epoch 300/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.5828 - accuracy: 0.3478 - val_loss: 4.9694 - val_accuracy: 0.1237\n",
      "Epoch 301/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.5848 - accuracy: 0.3464 - val_loss: 4.9513 - val_accuracy: 0.1237\n",
      "Epoch 302/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.5909 - accuracy: 0.3436 - val_loss: 4.9540 - val_accuracy: 0.1237\n",
      "Epoch 303/500\n",
      "1429/1429 [==============================] - 0s 126us/step - loss: 2.5854 - accuracy: 0.3520 - val_loss: 4.9736 - val_accuracy: 0.1216\n",
      "Epoch 304/500\n",
      "1429/1429 [==============================] - 0s 122us/step - loss: 2.5891 - accuracy: 0.3415 - val_loss: 4.9985 - val_accuracy: 0.1237\n",
      "Epoch 305/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.5812 - accuracy: 0.3450 - val_loss: 4.9870 - val_accuracy: 0.1300\n",
      "Epoch 306/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.5807 - accuracy: 0.3534 - val_loss: 4.9848 - val_accuracy: 0.1174\n",
      "Epoch 307/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 2.5909 - accuracy: 0.3366 - val_loss: 5.0323 - val_accuracy: 0.1258\n",
      "Epoch 308/500\n",
      "1429/1429 [==============================] - 0s 142us/step - loss: 2.5904 - accuracy: 0.3401 - val_loss: 5.0195 - val_accuracy: 0.1174\n",
      "Epoch 309/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5844 - accuracy: 0.3520 - val_loss: 5.0025 - val_accuracy: 0.1195\n",
      "Epoch 310/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.5857 - accuracy: 0.3408 - val_loss: 5.0174 - val_accuracy: 0.1132\n",
      "Epoch 311/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5769 - accuracy: 0.3471 - val_loss: 5.0439 - val_accuracy: 0.1258\n",
      "Epoch 312/500\n",
      "1429/1429 [==============================] - 0s 118us/step - loss: 2.5818 - accuracy: 0.3387 - val_loss: 5.0698 - val_accuracy: 0.1132\n",
      "Epoch 313/500\n",
      "1429/1429 [==============================] - 0s 125us/step - loss: 2.5813 - accuracy: 0.3506 - val_loss: 5.0649 - val_accuracy: 0.1153\n",
      "Epoch 314/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5800 - accuracy: 0.3513 - val_loss: 5.0490 - val_accuracy: 0.1216\n",
      "Epoch 315/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.5827 - accuracy: 0.3471 - val_loss: 5.0668 - val_accuracy: 0.1111\n",
      "Epoch 316/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.5732 - accuracy: 0.3541 - val_loss: 5.0698 - val_accuracy: 0.1174\n",
      "Epoch 317/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5799 - accuracy: 0.3387 - val_loss: 5.0612 - val_accuracy: 0.1237\n",
      "Epoch 318/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5830 - accuracy: 0.3569 - val_loss: 5.0606 - val_accuracy: 0.1174\n",
      "Epoch 319/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.5824 - accuracy: 0.3527 - val_loss: 5.0894 - val_accuracy: 0.1111\n",
      "Epoch 320/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.5749 - accuracy: 0.3478 - val_loss: 5.0962 - val_accuracy: 0.1279\n",
      "Epoch 321/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.5763 - accuracy: 0.3464 - val_loss: 5.1018 - val_accuracy: 0.1174\n",
      "Epoch 322/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.5757 - accuracy: 0.3471 - val_loss: 5.0991 - val_accuracy: 0.1258\n",
      "Epoch 323/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.5730 - accuracy: 0.3499 - val_loss: 5.1106 - val_accuracy: 0.1153\n",
      "Epoch 324/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5770 - accuracy: 0.3450 - val_loss: 5.1002 - val_accuracy: 0.1279\n",
      "Epoch 325/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.5754 - accuracy: 0.3478 - val_loss: 5.1288 - val_accuracy: 0.1132\n",
      "Epoch 326/500\n",
      "1429/1429 [==============================] - 0s 128us/step - loss: 2.5740 - accuracy: 0.3457 - val_loss: 5.1276 - val_accuracy: 0.1195\n",
      "Epoch 327/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.5658 - accuracy: 0.3583 - val_loss: 5.1452 - val_accuracy: 0.1174\n",
      "Epoch 328/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.5706 - accuracy: 0.3443 - val_loss: 5.1518 - val_accuracy: 0.1153\n",
      "Epoch 329/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.5717 - accuracy: 0.3422 - val_loss: 5.1514 - val_accuracy: 0.1132\n",
      "Epoch 330/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.5746 - accuracy: 0.3534 - val_loss: 5.1790 - val_accuracy: 0.1195\n",
      "Epoch 331/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5706 - accuracy: 0.3534 - val_loss: 5.1706 - val_accuracy: 0.1174\n",
      "Epoch 332/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.5677 - accuracy: 0.3492 - val_loss: 5.2092 - val_accuracy: 0.1132\n",
      "Epoch 333/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5745 - accuracy: 0.3527 - val_loss: 5.1897 - val_accuracy: 0.1174\n",
      "Epoch 334/500\n",
      "1429/1429 [==============================] - 0s 140us/step - loss: 2.5716 - accuracy: 0.3506 - val_loss: 5.2063 - val_accuracy: 0.1216\n",
      "Epoch 335/500\n",
      "1429/1429 [==============================] - 0s 142us/step - loss: 2.5707 - accuracy: 0.3499 - val_loss: 5.2050 - val_accuracy: 0.1237\n",
      "Epoch 336/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.5706 - accuracy: 0.3443 - val_loss: 5.2416 - val_accuracy: 0.1132\n",
      "Epoch 337/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5744 - accuracy: 0.3478 - val_loss: 5.2305 - val_accuracy: 0.1111\n",
      "Epoch 338/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.5672 - accuracy: 0.3471 - val_loss: 5.2202 - val_accuracy: 0.1195\n",
      "Epoch 339/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 2.5747 - accuracy: 0.3492 - val_loss: 5.2338 - val_accuracy: 0.1153\n",
      "Epoch 340/500\n",
      "1429/1429 [==============================] - 0s 93us/step - loss: 2.5716 - accuracy: 0.3576 - val_loss: 5.2409 - val_accuracy: 0.1237\n",
      "Epoch 341/500\n",
      "1429/1429 [==============================] - 0s 124us/step - loss: 2.5676 - accuracy: 0.3422 - val_loss: 5.2867 - val_accuracy: 0.1195\n",
      "Epoch 342/500\n",
      "1429/1429 [==============================] - 0s 209us/step - loss: 2.5661 - accuracy: 0.3457 - val_loss: 5.2412 - val_accuracy: 0.1237\n",
      "Epoch 343/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.5673 - accuracy: 0.3464 - val_loss: 5.2875 - val_accuracy: 0.1111\n",
      "Epoch 344/500\n",
      "1429/1429 [==============================] - 0s 121us/step - loss: 2.5631 - accuracy: 0.3464 - val_loss: 5.2793 - val_accuracy: 0.1132\n",
      "Epoch 345/500\n",
      "1429/1429 [==============================] - 0s 128us/step - loss: 2.5689 - accuracy: 0.3513 - val_loss: 5.3319 - val_accuracy: 0.1153\n",
      "Epoch 346/500\n",
      "1429/1429 [==============================] - 0s 115us/step - loss: 2.5751 - accuracy: 0.3492 - val_loss: 5.2877 - val_accuracy: 0.1300\n",
      "Epoch 347/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5702 - accuracy: 0.3583 - val_loss: 5.2876 - val_accuracy: 0.1153\n",
      "Epoch 348/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.5623 - accuracy: 0.3569 - val_loss: 5.3153 - val_accuracy: 0.1048\n",
      "Epoch 349/500\n",
      "1429/1429 [==============================] - 0s 124us/step - loss: 2.5676 - accuracy: 0.3541 - val_loss: 5.3257 - val_accuracy: 0.1090\n",
      "Epoch 350/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.5652 - accuracy: 0.3499 - val_loss: 5.3240 - val_accuracy: 0.1090\n",
      "Epoch 351/500\n",
      "1429/1429 [==============================] - 0s 149us/step - loss: 2.5667 - accuracy: 0.3478 - val_loss: 5.3161 - val_accuracy: 0.1216\n",
      "Epoch 352/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5661 - accuracy: 0.3450 - val_loss: 5.3410 - val_accuracy: 0.1216\n",
      "Epoch 353/500\n",
      "1429/1429 [==============================] - 0s 120us/step - loss: 2.5633 - accuracy: 0.3555 - val_loss: 5.3733 - val_accuracy: 0.1174\n",
      "Epoch 354/500\n",
      "1429/1429 [==============================] - 0s 118us/step - loss: 2.5673 - accuracy: 0.3457 - val_loss: 5.3467 - val_accuracy: 0.1195\n",
      "Epoch 355/500\n",
      "1429/1429 [==============================] - 0s 121us/step - loss: 2.5624 - accuracy: 0.3429 - val_loss: 5.3900 - val_accuracy: 0.1111\n",
      "Epoch 356/500\n",
      "1429/1429 [==============================] - 0s 130us/step - loss: 2.5678 - accuracy: 0.3485 - val_loss: 5.3797 - val_accuracy: 0.1237\n",
      "Epoch 357/500\n",
      "1429/1429 [==============================] - 0s 125us/step - loss: 2.5644 - accuracy: 0.3478 - val_loss: 5.3855 - val_accuracy: 0.1237\n",
      "Epoch 358/500\n",
      "1429/1429 [==============================] - 0s 128us/step - loss: 2.5636 - accuracy: 0.3555 - val_loss: 5.3820 - val_accuracy: 0.1174\n",
      "Epoch 359/500\n",
      "1429/1429 [==============================] - 0s 121us/step - loss: 2.5603 - accuracy: 0.3443 - val_loss: 5.3890 - val_accuracy: 0.1132\n",
      "Epoch 360/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.5645 - accuracy: 0.3541 - val_loss: 5.4331 - val_accuracy: 0.1174\n",
      "Epoch 361/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.5615 - accuracy: 0.3485 - val_loss: 5.4156 - val_accuracy: 0.1090\n",
      "Epoch 362/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.5655 - accuracy: 0.3408 - val_loss: 5.4166 - val_accuracy: 0.1132\n",
      "Epoch 363/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5598 - accuracy: 0.3597 - val_loss: 5.4365 - val_accuracy: 0.1195\n",
      "Epoch 364/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5584 - accuracy: 0.3471 - val_loss: 5.4189 - val_accuracy: 0.1216\n",
      "Epoch 365/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5553 - accuracy: 0.3527 - val_loss: 5.4521 - val_accuracy: 0.1132\n",
      "Epoch 366/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5581 - accuracy: 0.3485 - val_loss: 5.4577 - val_accuracy: 0.1195\n",
      "Epoch 367/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5530 - accuracy: 0.3520 - val_loss: 5.4675 - val_accuracy: 0.1132\n",
      "Epoch 368/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5565 - accuracy: 0.3527 - val_loss: 5.4453 - val_accuracy: 0.1132\n",
      "Epoch 369/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5497 - accuracy: 0.3534 - val_loss: 5.4566 - val_accuracy: 0.1237\n",
      "Epoch 370/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5557 - accuracy: 0.3541 - val_loss: 5.4679 - val_accuracy: 0.1174\n",
      "Epoch 371/500\n",
      "1429/1429 [==============================] - 0s 120us/step - loss: 2.5539 - accuracy: 0.3464 - val_loss: 5.4770 - val_accuracy: 0.1216\n",
      "Epoch 372/500\n",
      "1429/1429 [==============================] - 0s 132us/step - loss: 2.5541 - accuracy: 0.3513 - val_loss: 5.4872 - val_accuracy: 0.1279\n",
      "Epoch 373/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 129us/step - loss: 2.5562 - accuracy: 0.3534 - val_loss: 5.4968 - val_accuracy: 0.1132\n",
      "Epoch 374/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5514 - accuracy: 0.3492 - val_loss: 5.5150 - val_accuracy: 0.1216\n",
      "Epoch 375/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5531 - accuracy: 0.3520 - val_loss: 5.5395 - val_accuracy: 0.1090\n",
      "Epoch 376/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5602 - accuracy: 0.3562 - val_loss: 5.5290 - val_accuracy: 0.1132\n",
      "Epoch 377/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.5544 - accuracy: 0.3450 - val_loss: 5.5449 - val_accuracy: 0.1090\n",
      "Epoch 378/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.5530 - accuracy: 0.3569 - val_loss: 5.5601 - val_accuracy: 0.1174\n",
      "Epoch 379/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.5558 - accuracy: 0.3548 - val_loss: 5.5303 - val_accuracy: 0.1174\n",
      "Epoch 380/500\n",
      "1429/1429 [==============================] - 0s 129us/step - loss: 2.5550 - accuracy: 0.3541 - val_loss: 5.5639 - val_accuracy: 0.1111\n",
      "Epoch 381/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.5512 - accuracy: 0.3415 - val_loss: 5.5661 - val_accuracy: 0.1132\n",
      "Epoch 382/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.5494 - accuracy: 0.3583 - val_loss: 5.5943 - val_accuracy: 0.1174\n",
      "Epoch 383/500\n",
      "1429/1429 [==============================] - 0s 126us/step - loss: 2.5495 - accuracy: 0.3513 - val_loss: 5.5697 - val_accuracy: 0.1174\n",
      "Epoch 384/500\n",
      "1429/1429 [==============================] - 0s 127us/step - loss: 2.5576 - accuracy: 0.3478 - val_loss: 5.5755 - val_accuracy: 0.1132\n",
      "Epoch 385/500\n",
      "1429/1429 [==============================] - 0s 120us/step - loss: 2.5486 - accuracy: 0.3506 - val_loss: 5.5802 - val_accuracy: 0.1195\n",
      "Epoch 386/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.5498 - accuracy: 0.3618 - val_loss: 5.5973 - val_accuracy: 0.1174\n",
      "Epoch 387/500\n",
      "1429/1429 [==============================] - 0s 118us/step - loss: 2.5535 - accuracy: 0.3506 - val_loss: 5.6066 - val_accuracy: 0.1111\n",
      "Epoch 388/500\n",
      "1429/1429 [==============================] - 0s 121us/step - loss: 2.5500 - accuracy: 0.3590 - val_loss: 5.6514 - val_accuracy: 0.1090\n",
      "Epoch 389/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.5562 - accuracy: 0.3478 - val_loss: 5.6318 - val_accuracy: 0.1237\n",
      "Epoch 390/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.5504 - accuracy: 0.3562 - val_loss: 5.6401 - val_accuracy: 0.1174\n",
      "Epoch 391/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5443 - accuracy: 0.3590 - val_loss: 5.6543 - val_accuracy: 0.1153\n",
      "Epoch 392/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.5477 - accuracy: 0.3541 - val_loss: 5.6535 - val_accuracy: 0.1153\n",
      "Epoch 393/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5439 - accuracy: 0.3604 - val_loss: 5.6412 - val_accuracy: 0.1132\n",
      "Epoch 394/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.5482 - accuracy: 0.3590 - val_loss: 5.6915 - val_accuracy: 0.1027\n",
      "Epoch 395/500\n",
      "1429/1429 [==============================] - 0s 125us/step - loss: 2.5464 - accuracy: 0.3597 - val_loss: 5.6666 - val_accuracy: 0.1195\n",
      "Epoch 396/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.5508 - accuracy: 0.3499 - val_loss: 5.7049 - val_accuracy: 0.1111\n",
      "Epoch 397/500\n",
      "1429/1429 [==============================] - 0s 120us/step - loss: 2.5461 - accuracy: 0.3541 - val_loss: 5.6870 - val_accuracy: 0.1216\n",
      "Epoch 398/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.5526 - accuracy: 0.3471 - val_loss: 5.6998 - val_accuracy: 0.1090\n",
      "Epoch 399/500\n",
      "1429/1429 [==============================] - 0s 124us/step - loss: 2.5507 - accuracy: 0.3485 - val_loss: 5.6981 - val_accuracy: 0.1132\n",
      "Epoch 400/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.5528 - accuracy: 0.3520 - val_loss: 5.6913 - val_accuracy: 0.1153\n",
      "Epoch 401/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5484 - accuracy: 0.3562 - val_loss: 5.7110 - val_accuracy: 0.1279\n",
      "Epoch 402/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.5474 - accuracy: 0.3471 - val_loss: 5.7275 - val_accuracy: 0.1027\n",
      "Epoch 403/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.5480 - accuracy: 0.3513 - val_loss: 5.7274 - val_accuracy: 0.1216\n",
      "Epoch 404/500\n",
      "1429/1429 [==============================] - 0s 132us/step - loss: 2.5417 - accuracy: 0.3401 - val_loss: 5.7677 - val_accuracy: 0.1195\n",
      "Epoch 405/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.5414 - accuracy: 0.3548 - val_loss: 5.7531 - val_accuracy: 0.1111\n",
      "Epoch 406/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5467 - accuracy: 0.3569 - val_loss: 5.7791 - val_accuracy: 0.1174\n",
      "Epoch 407/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5426 - accuracy: 0.3604 - val_loss: 5.7589 - val_accuracy: 0.1216\n",
      "Epoch 408/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5413 - accuracy: 0.3478 - val_loss: 5.7663 - val_accuracy: 0.1216\n",
      "Epoch 409/500\n",
      "1429/1429 [==============================] - 0s 94us/step - loss: 2.5454 - accuracy: 0.3576 - val_loss: 5.7814 - val_accuracy: 0.1111\n",
      "Epoch 410/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5378 - accuracy: 0.3548 - val_loss: 5.7884 - val_accuracy: 0.1090\n",
      "Epoch 411/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5487 - accuracy: 0.3576 - val_loss: 5.8334 - val_accuracy: 0.1132\n",
      "Epoch 412/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5420 - accuracy: 0.3527 - val_loss: 5.8154 - val_accuracy: 0.1111\n",
      "Epoch 413/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5414 - accuracy: 0.3534 - val_loss: 5.8247 - val_accuracy: 0.1048\n",
      "Epoch 414/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.5377 - accuracy: 0.3646 - val_loss: 5.8218 - val_accuracy: 0.1153\n",
      "Epoch 415/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.5428 - accuracy: 0.3520 - val_loss: 5.8506 - val_accuracy: 0.1090\n",
      "Epoch 416/500\n",
      "1429/1429 [==============================] - 0s 122us/step - loss: 2.5445 - accuracy: 0.3541 - val_loss: 5.8617 - val_accuracy: 0.1111\n",
      "Epoch 417/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.5375 - accuracy: 0.3583 - val_loss: 5.8558 - val_accuracy: 0.1195\n",
      "Epoch 418/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.5404 - accuracy: 0.3576 - val_loss: 5.8581 - val_accuracy: 0.1195\n",
      "Epoch 419/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5405 - accuracy: 0.3653 - val_loss: 5.8386 - val_accuracy: 0.1069\n",
      "Epoch 420/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.5392 - accuracy: 0.3569 - val_loss: 5.8864 - val_accuracy: 0.1153\n",
      "Epoch 421/500\n",
      "1429/1429 [==============================] - 0s 133us/step - loss: 2.5501 - accuracy: 0.3506 - val_loss: 5.8865 - val_accuracy: 0.1153\n",
      "Epoch 422/500\n",
      "1429/1429 [==============================] - 0s 127us/step - loss: 2.5358 - accuracy: 0.3625 - val_loss: 5.8822 - val_accuracy: 0.1111\n",
      "Epoch 423/500\n",
      "1429/1429 [==============================] - 0s 123us/step - loss: 2.5361 - accuracy: 0.3639 - val_loss: 5.8947 - val_accuracy: 0.1132\n",
      "Epoch 424/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5346 - accuracy: 0.3548 - val_loss: 5.9174 - val_accuracy: 0.1069\n",
      "Epoch 425/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.5393 - accuracy: 0.3618 - val_loss: 5.9202 - val_accuracy: 0.1048\n",
      "Epoch 426/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.5381 - accuracy: 0.3534 - val_loss: 5.9391 - val_accuracy: 0.1069\n",
      "Epoch 427/500\n",
      "1429/1429 [==============================] - 0s 133us/step - loss: 2.5329 - accuracy: 0.3534 - val_loss: 5.9569 - val_accuracy: 0.1111\n",
      "Epoch 428/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.5341 - accuracy: 0.3604 - val_loss: 5.9605 - val_accuracy: 0.1069\n",
      "Epoch 429/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5367 - accuracy: 0.3583 - val_loss: 5.9349 - val_accuracy: 0.1111\n",
      "Epoch 430/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.5354 - accuracy: 0.3618 - val_loss: 5.9743 - val_accuracy: 0.1069\n",
      "Epoch 431/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5301 - accuracy: 0.3569 - val_loss: 5.9489 - val_accuracy: 0.1174\n",
      "Epoch 432/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.5318 - accuracy: 0.3611 - val_loss: 5.9638 - val_accuracy: 0.1069\n",
      "Epoch 433/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.5360 - accuracy: 0.3541 - val_loss: 5.9859 - val_accuracy: 0.1069\n",
      "Epoch 434/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5377 - accuracy: 0.3534 - val_loss: 5.9927 - val_accuracy: 0.1111\n",
      "Epoch 435/500\n",
      "1429/1429 [==============================] - 0s 123us/step - loss: 2.5374 - accuracy: 0.3646 - val_loss: 5.9835 - val_accuracy: 0.1090\n",
      "Epoch 436/500\n",
      "1429/1429 [==============================] - 0s 147us/step - loss: 2.5358 - accuracy: 0.3527 - val_loss: 6.0263 - val_accuracy: 0.1195\n",
      "Epoch 437/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.5339 - accuracy: 0.3618 - val_loss: 6.0244 - val_accuracy: 0.1069\n",
      "Epoch 438/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.5333 - accuracy: 0.3569 - val_loss: 6.0116 - val_accuracy: 0.1279\n",
      "Epoch 439/500\n",
      "1429/1429 [==============================] - 0s 125us/step - loss: 2.5346 - accuracy: 0.3569 - val_loss: 6.0443 - val_accuracy: 0.1048\n",
      "Epoch 440/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.5346 - accuracy: 0.3604 - val_loss: 6.0394 - val_accuracy: 0.0985\n",
      "Epoch 441/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.5306 - accuracy: 0.3471 - val_loss: 6.0615 - val_accuracy: 0.1048\n",
      "Epoch 442/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.5316 - accuracy: 0.3541 - val_loss: 6.0629 - val_accuracy: 0.1153\n",
      "Epoch 443/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.5375 - accuracy: 0.3548 - val_loss: 6.0758 - val_accuracy: 0.1090\n",
      "Epoch 444/500\n",
      "1429/1429 [==============================] - 0s 124us/step - loss: 2.5341 - accuracy: 0.3576 - val_loss: 6.0857 - val_accuracy: 0.1090\n",
      "Epoch 445/500\n",
      "1429/1429 [==============================] - 0s 120us/step - loss: 2.5262 - accuracy: 0.3646 - val_loss: 6.0706 - val_accuracy: 0.1174\n",
      "Epoch 446/500\n",
      "1429/1429 [==============================] - 0s 118us/step - loss: 2.5272 - accuracy: 0.3660 - val_loss: 6.0929 - val_accuracy: 0.1048\n",
      "Epoch 447/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.5326 - accuracy: 0.3562 - val_loss: 6.1112 - val_accuracy: 0.1048\n",
      "Epoch 448/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.5279 - accuracy: 0.3527 - val_loss: 6.0980 - val_accuracy: 0.1069\n",
      "Epoch 449/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5254 - accuracy: 0.3562 - val_loss: 6.1186 - val_accuracy: 0.1111\n",
      "Epoch 450/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.5233 - accuracy: 0.3548 - val_loss: 6.1257 - val_accuracy: 0.1174\n",
      "Epoch 451/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.5311 - accuracy: 0.3527 - val_loss: 6.1270 - val_accuracy: 0.1132\n",
      "Epoch 452/500\n",
      "1429/1429 [==============================] - 0s 125us/step - loss: 2.5285 - accuracy: 0.3625 - val_loss: 6.1192 - val_accuracy: 0.1237\n",
      "Epoch 453/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.5245 - accuracy: 0.3555 - val_loss: 6.1428 - val_accuracy: 0.1132\n",
      "Epoch 454/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5245 - accuracy: 0.3632 - val_loss: 6.1466 - val_accuracy: 0.1153\n",
      "Epoch 455/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.5286 - accuracy: 0.3548 - val_loss: 6.1674 - val_accuracy: 0.1048\n",
      "Epoch 456/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5326 - accuracy: 0.3576 - val_loss: 6.1623 - val_accuracy: 0.1006\n",
      "Epoch 457/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.5228 - accuracy: 0.3569 - val_loss: 6.1715 - val_accuracy: 0.1153\n",
      "Epoch 458/500\n",
      "1429/1429 [==============================] - 0s 122us/step - loss: 2.5217 - accuracy: 0.3548 - val_loss: 6.1860 - val_accuracy: 0.1132\n",
      "Epoch 459/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.5232 - accuracy: 0.3555 - val_loss: 6.1803 - val_accuracy: 0.1111\n",
      "Epoch 460/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5247 - accuracy: 0.3597 - val_loss: 6.1821 - val_accuracy: 0.1048\n",
      "Epoch 461/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5232 - accuracy: 0.3597 - val_loss: 6.1963 - val_accuracy: 0.1132\n",
      "Epoch 462/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.5270 - accuracy: 0.3576 - val_loss: 6.1988 - val_accuracy: 0.1006\n",
      "Epoch 463/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.5248 - accuracy: 0.3618 - val_loss: 6.2148 - val_accuracy: 0.1111\n",
      "Epoch 464/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.5284 - accuracy: 0.3632 - val_loss: 6.2041 - val_accuracy: 0.1153\n",
      "Epoch 465/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.5272 - accuracy: 0.3492 - val_loss: 6.2517 - val_accuracy: 0.1090\n",
      "Epoch 466/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.5246 - accuracy: 0.3590 - val_loss: 6.2733 - val_accuracy: 0.1048\n",
      "Epoch 467/500\n",
      "1429/1429 [==============================] - 0s 127us/step - loss: 2.5313 - accuracy: 0.3492 - val_loss: 6.2428 - val_accuracy: 0.1048\n",
      "Epoch 468/500\n",
      "1429/1429 [==============================] - 0s 143us/step - loss: 2.5256 - accuracy: 0.3597 - val_loss: 6.2776 - val_accuracy: 0.1069\n",
      "Epoch 469/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5229 - accuracy: 0.3541 - val_loss: 6.2886 - val_accuracy: 0.1132\n",
      "Epoch 470/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5181 - accuracy: 0.3611 - val_loss: 6.2816 - val_accuracy: 0.1006\n",
      "Epoch 471/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.5170 - accuracy: 0.3618 - val_loss: 6.3039 - val_accuracy: 0.1069\n",
      "Epoch 472/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5186 - accuracy: 0.3639 - val_loss: 6.3034 - val_accuracy: 0.1111\n",
      "Epoch 473/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5239 - accuracy: 0.3555 - val_loss: 6.3025 - val_accuracy: 0.1132\n",
      "Epoch 474/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.5199 - accuracy: 0.3639 - val_loss: 6.3408 - val_accuracy: 0.1048\n",
      "Epoch 475/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.5164 - accuracy: 0.3604 - val_loss: 6.3061 - val_accuracy: 0.1195\n",
      "Epoch 476/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5207 - accuracy: 0.3562 - val_loss: 6.3389 - val_accuracy: 0.1006\n",
      "Epoch 477/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5180 - accuracy: 0.3548 - val_loss: 6.3528 - val_accuracy: 0.1048\n",
      "Epoch 478/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.5188 - accuracy: 0.3576 - val_loss: 6.3414 - val_accuracy: 0.1090\n",
      "Epoch 479/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5230 - accuracy: 0.3604 - val_loss: 6.3344 - val_accuracy: 0.1090\n",
      "Epoch 480/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5219 - accuracy: 0.3576 - val_loss: 6.3497 - val_accuracy: 0.1090\n",
      "Epoch 481/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5203 - accuracy: 0.3597 - val_loss: 6.3600 - val_accuracy: 0.1153\n",
      "Epoch 482/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.5134 - accuracy: 0.3618 - val_loss: 6.3945 - val_accuracy: 0.1069\n",
      "Epoch 483/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5138 - accuracy: 0.3555 - val_loss: 6.3683 - val_accuracy: 0.1174\n",
      "Epoch 484/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5180 - accuracy: 0.3576 - val_loss: 6.4060 - val_accuracy: 0.1153\n",
      "Epoch 485/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.5176 - accuracy: 0.3604 - val_loss: 6.3897 - val_accuracy: 0.1111\n",
      "Epoch 486/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5188 - accuracy: 0.3618 - val_loss: 6.4104 - val_accuracy: 0.1237\n",
      "Epoch 487/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.5171 - accuracy: 0.3618 - val_loss: 6.4489 - val_accuracy: 0.1048\n",
      "Epoch 488/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.5185 - accuracy: 0.3597 - val_loss: 6.4452 - val_accuracy: 0.1090\n",
      "Epoch 489/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.5207 - accuracy: 0.3555 - val_loss: 6.4301 - val_accuracy: 0.1195\n",
      "Epoch 490/500\n",
      "1429/1429 [==============================] - 0s 121us/step - loss: 2.5151 - accuracy: 0.3639 - val_loss: 6.4669 - val_accuracy: 0.1027\n",
      "Epoch 491/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5157 - accuracy: 0.3660 - val_loss: 6.4856 - val_accuracy: 0.1027\n",
      "Epoch 492/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5153 - accuracy: 0.3590 - val_loss: 6.4705 - val_accuracy: 0.0985\n",
      "Epoch 493/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5188 - accuracy: 0.3604 - val_loss: 6.4909 - val_accuracy: 0.1006\n",
      "Epoch 494/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.5170 - accuracy: 0.3597 - val_loss: 6.4890 - val_accuracy: 0.1111\n",
      "Epoch 495/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.5139 - accuracy: 0.3646 - val_loss: 6.4851 - val_accuracy: 0.1132\n",
      "Epoch 496/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5169 - accuracy: 0.3569 - val_loss: 6.5210 - val_accuracy: 0.1090\n",
      "Epoch 497/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.5145 - accuracy: 0.3555 - val_loss: 6.5447 - val_accuracy: 0.1069\n",
      "Epoch 498/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5157 - accuracy: 0.3681 - val_loss: 6.5113 - val_accuracy: 0.1069\n",
      "Epoch 499/500\n",
      "1429/1429 [==============================] - 0s 121us/step - loss: 2.5180 - accuracy: 0.3506 - val_loss: 6.5287 - val_accuracy: 0.1027\n",
      "Epoch 500/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.5130 - accuracy: 0.3618 - val_loss: 6.5091 - val_accuracy: 0.1048\n",
      "Train on 1429 samples, validate on 477 samples\n",
      "Epoch 1/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 3.3397 - accuracy: 0.2932 - val_loss: 4.0102 - val_accuracy: 0.2788\n",
      "Epoch 2/500\n",
      "1429/1429 [==============================] - 0s 134us/step - loss: 3.2180 - accuracy: 0.3002 - val_loss: 3.9124 - val_accuracy: 0.2600\n",
      "Epoch 3/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 3.1360 - accuracy: 0.3051 - val_loss: 3.8580 - val_accuracy: 0.2600\n",
      "Epoch 4/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 3.0815 - accuracy: 0.2960 - val_loss: 3.7974 - val_accuracy: 0.2369\n",
      "Epoch 5/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 3.0272 - accuracy: 0.3016 - val_loss: 3.7366 - val_accuracy: 0.2432\n",
      "Epoch 6/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.9802 - accuracy: 0.3009 - val_loss: 3.7122 - val_accuracy: 0.2264\n",
      "Epoch 7/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.9514 - accuracy: 0.3079 - val_loss: 3.7187 - val_accuracy: 0.2264\n",
      "Epoch 8/500\n",
      "1429/1429 [==============================] - 0s 115us/step - loss: 2.9373 - accuracy: 0.3072 - val_loss: 3.7202 - val_accuracy: 0.2222\n",
      "Epoch 9/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.9206 - accuracy: 0.3170 - val_loss: 3.7228 - val_accuracy: 0.2222\n",
      "Epoch 10/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.9126 - accuracy: 0.3128 - val_loss: 3.7406 - val_accuracy: 0.2180\n",
      "Epoch 11/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.9061 - accuracy: 0.3065 - val_loss: 3.7538 - val_accuracy: 0.2075\n",
      "Epoch 12/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.9031 - accuracy: 0.3100 - val_loss: 3.7651 - val_accuracy: 0.2117\n",
      "Epoch 13/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.8812 - accuracy: 0.3184 - val_loss: 3.7723 - val_accuracy: 0.2243\n",
      "Epoch 14/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 2.8767 - accuracy: 0.3142 - val_loss: 3.7626 - val_accuracy: 0.2138\n",
      "Epoch 15/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.8701 - accuracy: 0.3149 - val_loss: 3.7832 - val_accuracy: 0.2034\n",
      "Epoch 16/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.8691 - accuracy: 0.3149 - val_loss: 3.7932 - val_accuracy: 0.2013\n",
      "Epoch 17/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.8593 - accuracy: 0.3184 - val_loss: 3.7900 - val_accuracy: 0.2055\n",
      "Epoch 18/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.8666 - accuracy: 0.3086 - val_loss: 3.8019 - val_accuracy: 0.1992\n",
      "Epoch 19/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.8529 - accuracy: 0.3226 - val_loss: 3.8084 - val_accuracy: 0.1929\n",
      "Epoch 20/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.8406 - accuracy: 0.3184 - val_loss: 3.8145 - val_accuracy: 0.1950\n",
      "Epoch 21/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.8362 - accuracy: 0.3191 - val_loss: 3.8144 - val_accuracy: 0.2013\n",
      "Epoch 22/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.8310 - accuracy: 0.3142 - val_loss: 3.8012 - val_accuracy: 0.1992\n",
      "Epoch 23/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.8267 - accuracy: 0.3058 - val_loss: 3.8254 - val_accuracy: 0.1908\n",
      "Epoch 24/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.8224 - accuracy: 0.3191 - val_loss: 3.8332 - val_accuracy: 0.2055\n",
      "Epoch 25/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.8205 - accuracy: 0.3114 - val_loss: 3.8225 - val_accuracy: 0.1866\n",
      "Epoch 26/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.8208 - accuracy: 0.3142 - val_loss: 3.8284 - val_accuracy: 0.1929\n",
      "Epoch 27/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.8147 - accuracy: 0.3156 - val_loss: 3.8277 - val_accuracy: 0.1803\n",
      "Epoch 28/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.8036 - accuracy: 0.3163 - val_loss: 3.8372 - val_accuracy: 0.1908\n",
      "Epoch 29/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.8104 - accuracy: 0.3114 - val_loss: 3.8276 - val_accuracy: 0.2096\n",
      "Epoch 30/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.8016 - accuracy: 0.3191 - val_loss: 3.8330 - val_accuracy: 0.1992\n",
      "Epoch 31/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7937 - accuracy: 0.3072 - val_loss: 3.8603 - val_accuracy: 0.1845\n",
      "Epoch 32/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.7935 - accuracy: 0.3114 - val_loss: 3.8416 - val_accuracy: 0.1971\n",
      "Epoch 33/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.7886 - accuracy: 0.3240 - val_loss: 3.8638 - val_accuracy: 0.1950\n",
      "Epoch 34/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7874 - accuracy: 0.3296 - val_loss: 3.8585 - val_accuracy: 0.1887\n",
      "Epoch 35/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7846 - accuracy: 0.3121 - val_loss: 3.8558 - val_accuracy: 0.1908\n",
      "Epoch 36/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.7831 - accuracy: 0.3254 - val_loss: 3.8769 - val_accuracy: 0.1845\n",
      "Epoch 37/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.7763 - accuracy: 0.3233 - val_loss: 3.8684 - val_accuracy: 0.1971\n",
      "Epoch 38/500\n",
      "1429/1429 [==============================] - 0s 134us/step - loss: 2.7796 - accuracy: 0.3254 - val_loss: 3.8831 - val_accuracy: 0.1950\n",
      "Epoch 39/500\n",
      "1429/1429 [==============================] - 0s 95us/step - loss: 2.7734 - accuracy: 0.3212 - val_loss: 3.8795 - val_accuracy: 0.1887\n",
      "Epoch 40/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7661 - accuracy: 0.3261 - val_loss: 3.8737 - val_accuracy: 0.1803\n",
      "Epoch 41/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.7675 - accuracy: 0.3268 - val_loss: 3.8860 - val_accuracy: 0.1845\n",
      "Epoch 42/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7687 - accuracy: 0.3226 - val_loss: 3.8904 - val_accuracy: 0.1887\n",
      "Epoch 43/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7655 - accuracy: 0.3163 - val_loss: 3.8920 - val_accuracy: 0.1950\n",
      "Epoch 44/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.7584 - accuracy: 0.3205 - val_loss: 3.9026 - val_accuracy: 0.1887\n",
      "Epoch 45/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7609 - accuracy: 0.3233 - val_loss: 3.8918 - val_accuracy: 0.1740\n",
      "Epoch 46/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.7569 - accuracy: 0.3212 - val_loss: 3.8993 - val_accuracy: 0.1845\n",
      "Epoch 47/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7580 - accuracy: 0.3219 - val_loss: 3.9028 - val_accuracy: 0.1782\n",
      "Epoch 48/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7501 - accuracy: 0.3338 - val_loss: 3.9239 - val_accuracy: 0.1866\n",
      "Epoch 49/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.7543 - accuracy: 0.3317 - val_loss: 3.9185 - val_accuracy: 0.1866\n",
      "Epoch 50/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7440 - accuracy: 0.3317 - val_loss: 3.9267 - val_accuracy: 0.1908\n",
      "Epoch 51/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.7521 - accuracy: 0.3198 - val_loss: 3.9173 - val_accuracy: 0.1782\n",
      "Epoch 52/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7364 - accuracy: 0.3240 - val_loss: 3.9269 - val_accuracy: 0.1635\n",
      "Epoch 53/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.7396 - accuracy: 0.3275 - val_loss: 3.9173 - val_accuracy: 0.1866\n",
      "Epoch 54/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.7403 - accuracy: 0.3275 - val_loss: 3.9300 - val_accuracy: 0.1782\n",
      "Epoch 55/500\n",
      "1429/1429 [==============================] - 0s 90us/step - loss: 2.7380 - accuracy: 0.3303 - val_loss: 3.9317 - val_accuracy: 0.1761\n",
      "Epoch 56/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7412 - accuracy: 0.3219 - val_loss: 3.9299 - val_accuracy: 0.1803\n",
      "Epoch 57/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7373 - accuracy: 0.3296 - val_loss: 3.9360 - val_accuracy: 0.1782\n",
      "Epoch 58/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7276 - accuracy: 0.3324 - val_loss: 3.9402 - val_accuracy: 0.1719\n",
      "Epoch 59/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.7293 - accuracy: 0.3254 - val_loss: 3.9308 - val_accuracy: 0.1908\n",
      "Epoch 60/500\n",
      "1429/1429 [==============================] - 0s 93us/step - loss: 2.7253 - accuracy: 0.3282 - val_loss: 3.9352 - val_accuracy: 0.1656\n",
      "Epoch 61/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7238 - accuracy: 0.3331 - val_loss: 3.9453 - val_accuracy: 0.1782\n",
      "Epoch 62/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.7306 - accuracy: 0.3240 - val_loss: 3.9427 - val_accuracy: 0.1635\n",
      "Epoch 63/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.7223 - accuracy: 0.3254 - val_loss: 3.9621 - val_accuracy: 0.1782\n",
      "Epoch 64/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.7219 - accuracy: 0.3289 - val_loss: 3.9521 - val_accuracy: 0.1782\n",
      "Epoch 65/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.7200 - accuracy: 0.3324 - val_loss: 3.9445 - val_accuracy: 0.1698\n",
      "Epoch 66/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7245 - accuracy: 0.3205 - val_loss: 3.9616 - val_accuracy: 0.1719\n",
      "Epoch 67/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.7130 - accuracy: 0.3310 - val_loss: 3.9540 - val_accuracy: 0.1740\n",
      "Epoch 68/500\n",
      "1429/1429 [==============================] - 0s 93us/step - loss: 2.7132 - accuracy: 0.3324 - val_loss: 3.9640 - val_accuracy: 0.1845\n",
      "Epoch 69/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.7117 - accuracy: 0.3394 - val_loss: 3.9875 - val_accuracy: 0.1719\n",
      "Epoch 70/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 2.7116 - accuracy: 0.3268 - val_loss: 3.9831 - val_accuracy: 0.1614\n",
      "Epoch 71/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.7111 - accuracy: 0.3310 - val_loss: 3.9721 - val_accuracy: 0.1677\n",
      "Epoch 72/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.7094 - accuracy: 0.3366 - val_loss: 3.9923 - val_accuracy: 0.1719\n",
      "Epoch 73/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.7055 - accuracy: 0.3387 - val_loss: 3.9697 - val_accuracy: 0.1635\n",
      "Epoch 74/500\n",
      "1429/1429 [==============================] - 0s 161us/step - loss: 2.7067 - accuracy: 0.3310 - val_loss: 3.9637 - val_accuracy: 0.1677\n",
      "Epoch 75/500\n",
      "1429/1429 [==============================] - 0s 133us/step - loss: 2.7084 - accuracy: 0.3282 - val_loss: 3.9867 - val_accuracy: 0.1635\n",
      "Epoch 76/500\n",
      "1429/1429 [==============================] - 0s 125us/step - loss: 2.7142 - accuracy: 0.3296 - val_loss: 4.0035 - val_accuracy: 0.1614\n",
      "Epoch 77/500\n",
      "1429/1429 [==============================] - 0s 121us/step - loss: 2.7054 - accuracy: 0.3324 - val_loss: 3.9980 - val_accuracy: 0.1824\n",
      "Epoch 78/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.6982 - accuracy: 0.3331 - val_loss: 3.9985 - val_accuracy: 0.1656\n",
      "Epoch 79/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.6981 - accuracy: 0.3296 - val_loss: 4.0034 - val_accuracy: 0.1656\n",
      "Epoch 80/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.7032 - accuracy: 0.3268 - val_loss: 3.9987 - val_accuracy: 0.1530\n",
      "Epoch 81/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.6967 - accuracy: 0.3359 - val_loss: 3.9967 - val_accuracy: 0.1614\n",
      "Epoch 82/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.6978 - accuracy: 0.3366 - val_loss: 4.0069 - val_accuracy: 0.1761\n",
      "Epoch 83/500\n",
      "1429/1429 [==============================] - 0s 146us/step - loss: 2.6945 - accuracy: 0.3366 - val_loss: 4.0018 - val_accuracy: 0.1635\n",
      "Epoch 84/500\n",
      "1429/1429 [==============================] - 0s 130us/step - loss: 2.6901 - accuracy: 0.3324 - val_loss: 4.0003 - val_accuracy: 0.1635\n",
      "Epoch 85/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.6939 - accuracy: 0.3415 - val_loss: 4.0059 - val_accuracy: 0.1740\n",
      "Epoch 86/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.6877 - accuracy: 0.3359 - val_loss: 4.0584 - val_accuracy: 0.1509\n",
      "Epoch 87/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.6883 - accuracy: 0.3408 - val_loss: 4.0299 - val_accuracy: 0.1551\n",
      "Epoch 88/500\n",
      "1429/1429 [==============================] - 0s 118us/step - loss: 2.6853 - accuracy: 0.3387 - val_loss: 4.0274 - val_accuracy: 0.1530\n",
      "Epoch 89/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.6869 - accuracy: 0.3359 - val_loss: 4.0136 - val_accuracy: 0.1593\n",
      "Epoch 90/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.6870 - accuracy: 0.3373 - val_loss: 4.0411 - val_accuracy: 0.1509\n",
      "Epoch 91/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.6857 - accuracy: 0.3359 - val_loss: 4.0215 - val_accuracy: 0.1530\n",
      "Epoch 92/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6813 - accuracy: 0.3345 - val_loss: 4.0488 - val_accuracy: 0.1530\n",
      "Epoch 93/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.6815 - accuracy: 0.3380 - val_loss: 4.0297 - val_accuracy: 0.1551\n",
      "Epoch 94/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.6764 - accuracy: 0.3387 - val_loss: 4.0371 - val_accuracy: 0.1635\n",
      "Epoch 95/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.6791 - accuracy: 0.3345 - val_loss: 4.0335 - val_accuracy: 0.1426\n",
      "Epoch 96/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.6794 - accuracy: 0.3387 - val_loss: 4.0471 - val_accuracy: 0.1488\n",
      "Epoch 97/500\n",
      "1429/1429 [==============================] - 0s 147us/step - loss: 2.6790 - accuracy: 0.3387 - val_loss: 4.0502 - val_accuracy: 0.1593\n",
      "Epoch 98/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.6770 - accuracy: 0.3331 - val_loss: 4.0631 - val_accuracy: 0.1635\n",
      "Epoch 99/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.6716 - accuracy: 0.3373 - val_loss: 4.0400 - val_accuracy: 0.1635\n",
      "Epoch 100/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.6797 - accuracy: 0.3317 - val_loss: 4.0451 - val_accuracy: 0.1593\n",
      "Epoch 101/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6668 - accuracy: 0.3394 - val_loss: 4.0499 - val_accuracy: 0.1509\n",
      "Epoch 102/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.6696 - accuracy: 0.3373 - val_loss: 4.0541 - val_accuracy: 0.1530\n",
      "Epoch 103/500\n",
      "1429/1429 [==============================] - 0s 128us/step - loss: 2.6685 - accuracy: 0.3436 - val_loss: 4.0626 - val_accuracy: 0.1572\n",
      "Epoch 104/500\n",
      "1429/1429 [==============================] - 0s 115us/step - loss: 2.6725 - accuracy: 0.3401 - val_loss: 4.0602 - val_accuracy: 0.1635\n",
      "Epoch 105/500\n",
      "1429/1429 [==============================] - 0s 140us/step - loss: 2.6753 - accuracy: 0.3429 - val_loss: 4.0666 - val_accuracy: 0.1530\n",
      "Epoch 106/500\n",
      "1429/1429 [==============================] - 0s 148us/step - loss: 2.6629 - accuracy: 0.3338 - val_loss: 4.0640 - val_accuracy: 0.1426\n",
      "Epoch 107/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.6638 - accuracy: 0.3359 - val_loss: 4.0735 - val_accuracy: 0.1363\n",
      "Epoch 108/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.6657 - accuracy: 0.3359 - val_loss: 4.0788 - val_accuracy: 0.1468\n",
      "Epoch 109/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.6647 - accuracy: 0.3289 - val_loss: 4.0789 - val_accuracy: 0.1426\n",
      "Epoch 110/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.6694 - accuracy: 0.3373 - val_loss: 4.0825 - val_accuracy: 0.1447\n",
      "Epoch 111/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.6648 - accuracy: 0.3338 - val_loss: 4.0857 - val_accuracy: 0.1530\n",
      "Epoch 112/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.6669 - accuracy: 0.3422 - val_loss: 4.0874 - val_accuracy: 0.1468\n",
      "Epoch 113/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.6617 - accuracy: 0.3422 - val_loss: 4.0795 - val_accuracy: 0.1468\n",
      "Epoch 114/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6587 - accuracy: 0.3401 - val_loss: 4.1025 - val_accuracy: 0.1572\n",
      "Epoch 115/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.6661 - accuracy: 0.3471 - val_loss: 4.1075 - val_accuracy: 0.1468\n",
      "Epoch 116/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.6656 - accuracy: 0.3254 - val_loss: 4.1120 - val_accuracy: 0.1363\n",
      "Epoch 117/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.6606 - accuracy: 0.3366 - val_loss: 4.0995 - val_accuracy: 0.1468\n",
      "Epoch 118/500\n",
      "1429/1429 [==============================] - 0s 121us/step - loss: 2.6583 - accuracy: 0.3359 - val_loss: 4.1028 - val_accuracy: 0.1342\n",
      "Epoch 119/500\n",
      "1429/1429 [==============================] - 0s 118us/step - loss: 2.6572 - accuracy: 0.3352 - val_loss: 4.1298 - val_accuracy: 0.1426\n",
      "Epoch 120/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.6545 - accuracy: 0.3331 - val_loss: 4.1093 - val_accuracy: 0.1488\n",
      "Epoch 121/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.6512 - accuracy: 0.3429 - val_loss: 4.1281 - val_accuracy: 0.1363\n",
      "Epoch 122/500\n",
      "1429/1429 [==============================] - 0s 115us/step - loss: 2.6535 - accuracy: 0.3436 - val_loss: 4.1057 - val_accuracy: 0.1447\n",
      "Epoch 123/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.6509 - accuracy: 0.3408 - val_loss: 4.1273 - val_accuracy: 0.1509\n",
      "Epoch 124/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.6509 - accuracy: 0.3338 - val_loss: 4.1225 - val_accuracy: 0.1363\n",
      "Epoch 125/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6513 - accuracy: 0.3443 - val_loss: 4.1252 - val_accuracy: 0.1363\n",
      "Epoch 126/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.6508 - accuracy: 0.3324 - val_loss: 4.1284 - val_accuracy: 0.1468\n",
      "Epoch 127/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.6530 - accuracy: 0.3366 - val_loss: 4.1369 - val_accuracy: 0.1614\n",
      "Epoch 128/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.6452 - accuracy: 0.3366 - val_loss: 4.1444 - val_accuracy: 0.1530\n",
      "Epoch 129/500\n",
      "1429/1429 [==============================] - 0s 115us/step - loss: 2.6439 - accuracy: 0.3387 - val_loss: 4.1366 - val_accuracy: 0.1384\n",
      "Epoch 130/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.6394 - accuracy: 0.3436 - val_loss: 4.1345 - val_accuracy: 0.1405\n",
      "Epoch 131/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.6409 - accuracy: 0.3345 - val_loss: 4.1424 - val_accuracy: 0.1509\n",
      "Epoch 132/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.6383 - accuracy: 0.3429 - val_loss: 4.1461 - val_accuracy: 0.1426\n",
      "Epoch 133/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.6368 - accuracy: 0.3443 - val_loss: 4.1657 - val_accuracy: 0.1447\n",
      "Epoch 134/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.6435 - accuracy: 0.3457 - val_loss: 4.1642 - val_accuracy: 0.1447\n",
      "Epoch 135/500\n",
      "1429/1429 [==============================] - 0s 118us/step - loss: 2.6489 - accuracy: 0.3366 - val_loss: 4.1580 - val_accuracy: 0.1384\n",
      "Epoch 136/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.6395 - accuracy: 0.3464 - val_loss: 4.1617 - val_accuracy: 0.1468\n",
      "Epoch 137/500\n",
      "1429/1429 [==============================] - 0s 127us/step - loss: 2.6409 - accuracy: 0.3380 - val_loss: 4.1655 - val_accuracy: 0.1384\n",
      "Epoch 138/500\n",
      "1429/1429 [==============================] - 0s 161us/step - loss: 2.6334 - accuracy: 0.3436 - val_loss: 4.1597 - val_accuracy: 0.1426\n",
      "Epoch 139/500\n",
      "1429/1429 [==============================] - 0s 122us/step - loss: 2.6404 - accuracy: 0.3296 - val_loss: 4.1625 - val_accuracy: 0.1426\n",
      "Epoch 140/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.6310 - accuracy: 0.3464 - val_loss: 4.1762 - val_accuracy: 0.1405\n",
      "Epoch 141/500\n",
      "1429/1429 [==============================] - 0s 115us/step - loss: 2.6388 - accuracy: 0.3422 - val_loss: 4.1726 - val_accuracy: 0.1488\n",
      "Epoch 142/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.6360 - accuracy: 0.3457 - val_loss: 4.1751 - val_accuracy: 0.1363\n",
      "Epoch 143/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6358 - accuracy: 0.3443 - val_loss: 4.1995 - val_accuracy: 0.1321\n",
      "Epoch 144/500\n",
      "1429/1429 [==============================] - 0s 124us/step - loss: 2.6322 - accuracy: 0.3359 - val_loss: 4.1961 - val_accuracy: 0.1363\n",
      "Epoch 145/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.6352 - accuracy: 0.3394 - val_loss: 4.1980 - val_accuracy: 0.1300\n",
      "Epoch 146/500\n",
      "1429/1429 [==============================] - 0s 124us/step - loss: 2.6295 - accuracy: 0.3415 - val_loss: 4.1887 - val_accuracy: 0.1405\n",
      "Epoch 147/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6243 - accuracy: 0.3450 - val_loss: 4.1996 - val_accuracy: 0.1342\n",
      "Epoch 148/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.6255 - accuracy: 0.3478 - val_loss: 4.2023 - val_accuracy: 0.1321\n",
      "Epoch 149/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.6297 - accuracy: 0.3387 - val_loss: 4.2174 - val_accuracy: 0.1572\n",
      "Epoch 150/500\n",
      "1429/1429 [==============================] - 0s 122us/step - loss: 2.6206 - accuracy: 0.3408 - val_loss: 4.1989 - val_accuracy: 0.1405\n",
      "Epoch 151/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.6264 - accuracy: 0.3436 - val_loss: 4.2091 - val_accuracy: 0.1426\n",
      "Epoch 152/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.6224 - accuracy: 0.3485 - val_loss: 4.2185 - val_accuracy: 0.1279\n",
      "Epoch 153/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.6169 - accuracy: 0.3415 - val_loss: 4.2149 - val_accuracy: 0.1216\n",
      "Epoch 154/500\n",
      "1429/1429 [==============================] - 0s 120us/step - loss: 2.6282 - accuracy: 0.3366 - val_loss: 4.2100 - val_accuracy: 0.1363\n",
      "Epoch 155/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.6252 - accuracy: 0.3387 - val_loss: 4.2294 - val_accuracy: 0.1363\n",
      "Epoch 156/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.6176 - accuracy: 0.3436 - val_loss: 4.2478 - val_accuracy: 0.1237\n",
      "Epoch 157/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.6324 - accuracy: 0.3387 - val_loss: 4.2325 - val_accuracy: 0.1468\n",
      "Epoch 158/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.6239 - accuracy: 0.3408 - val_loss: 4.2309 - val_accuracy: 0.1363\n",
      "Epoch 159/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6184 - accuracy: 0.3443 - val_loss: 4.2419 - val_accuracy: 0.1258\n",
      "Epoch 160/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.6211 - accuracy: 0.3373 - val_loss: 4.2431 - val_accuracy: 0.1384\n",
      "Epoch 161/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.6157 - accuracy: 0.3478 - val_loss: 4.2469 - val_accuracy: 0.1363\n",
      "Epoch 162/500\n",
      "1429/1429 [==============================] - 0s 122us/step - loss: 2.6161 - accuracy: 0.3436 - val_loss: 4.2187 - val_accuracy: 0.1258\n",
      "Epoch 163/500\n",
      "1429/1429 [==============================] - 0s 122us/step - loss: 2.6178 - accuracy: 0.3373 - val_loss: 4.2456 - val_accuracy: 0.1195\n",
      "Epoch 164/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.6206 - accuracy: 0.3450 - val_loss: 4.2450 - val_accuracy: 0.1258\n",
      "Epoch 165/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6117 - accuracy: 0.3443 - val_loss: 4.2523 - val_accuracy: 0.1363\n",
      "Epoch 166/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.6072 - accuracy: 0.3422 - val_loss: 4.2720 - val_accuracy: 0.1258\n",
      "Epoch 167/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6134 - accuracy: 0.3436 - val_loss: 4.2735 - val_accuracy: 0.1258\n",
      "Epoch 168/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.6127 - accuracy: 0.3513 - val_loss: 4.2960 - val_accuracy: 0.1195\n",
      "Epoch 169/500\n",
      "1429/1429 [==============================] - 0s 126us/step - loss: 2.6150 - accuracy: 0.3387 - val_loss: 4.2741 - val_accuracy: 0.1342\n",
      "Epoch 170/500\n",
      "1429/1429 [==============================] - 0s 126us/step - loss: 2.6115 - accuracy: 0.3373 - val_loss: 4.2664 - val_accuracy: 0.1174\n",
      "Epoch 171/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.6101 - accuracy: 0.3485 - val_loss: 4.2650 - val_accuracy: 0.1216\n",
      "Epoch 172/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.6140 - accuracy: 0.3471 - val_loss: 4.2648 - val_accuracy: 0.1258\n",
      "Epoch 173/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6097 - accuracy: 0.3464 - val_loss: 4.2798 - val_accuracy: 0.1153\n",
      "Epoch 174/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.6126 - accuracy: 0.3387 - val_loss: 4.2842 - val_accuracy: 0.1132\n",
      "Epoch 175/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.6105 - accuracy: 0.3499 - val_loss: 4.2861 - val_accuracy: 0.1258\n",
      "Epoch 176/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.6064 - accuracy: 0.3394 - val_loss: 4.2878 - val_accuracy: 0.1363\n",
      "Epoch 177/500\n",
      "1429/1429 [==============================] - 0s 90us/step - loss: 2.6032 - accuracy: 0.3408 - val_loss: 4.2875 - val_accuracy: 0.1300\n",
      "Epoch 178/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.6016 - accuracy: 0.3548 - val_loss: 4.3164 - val_accuracy: 0.1363\n",
      "Epoch 179/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.6081 - accuracy: 0.3415 - val_loss: 4.2881 - val_accuracy: 0.1153\n",
      "Epoch 180/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.6011 - accuracy: 0.3408 - val_loss: 4.2991 - val_accuracy: 0.1300\n",
      "Epoch 181/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.6028 - accuracy: 0.3380 - val_loss: 4.3113 - val_accuracy: 0.1300\n",
      "Epoch 182/500\n",
      "1429/1429 [==============================] - 0s 93us/step - loss: 2.6011 - accuracy: 0.3450 - val_loss: 4.3038 - val_accuracy: 0.1363\n",
      "Epoch 183/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.6132 - accuracy: 0.3429 - val_loss: 4.2940 - val_accuracy: 0.1237\n",
      "Epoch 184/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.5974 - accuracy: 0.3569 - val_loss: 4.3211 - val_accuracy: 0.1279\n",
      "Epoch 185/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.6028 - accuracy: 0.3436 - val_loss: 4.3130 - val_accuracy: 0.1300\n",
      "Epoch 186/500\n",
      "1429/1429 [==============================] - 0s 121us/step - loss: 2.5977 - accuracy: 0.3520 - val_loss: 4.3188 - val_accuracy: 0.1174\n",
      "Epoch 187/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.6009 - accuracy: 0.3457 - val_loss: 4.3263 - val_accuracy: 0.1237\n",
      "Epoch 188/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5936 - accuracy: 0.3450 - val_loss: 4.3308 - val_accuracy: 0.1132\n",
      "Epoch 189/500\n",
      "1429/1429 [==============================] - 0s 126us/step - loss: 2.5969 - accuracy: 0.3478 - val_loss: 4.3170 - val_accuracy: 0.1153\n",
      "Epoch 190/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5951 - accuracy: 0.3429 - val_loss: 4.3238 - val_accuracy: 0.1300\n",
      "Epoch 191/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5924 - accuracy: 0.3499 - val_loss: 4.3438 - val_accuracy: 0.1321\n",
      "Epoch 192/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5914 - accuracy: 0.3443 - val_loss: 4.3471 - val_accuracy: 0.1237\n",
      "Epoch 193/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5943 - accuracy: 0.3429 - val_loss: 4.3428 - val_accuracy: 0.1195\n",
      "Epoch 194/500\n",
      "1429/1429 [==============================] - 0s 125us/step - loss: 2.5997 - accuracy: 0.3401 - val_loss: 4.3429 - val_accuracy: 0.1258\n",
      "Epoch 195/500\n",
      "1429/1429 [==============================] - 0s 137us/step - loss: 2.5924 - accuracy: 0.3492 - val_loss: 4.3366 - val_accuracy: 0.1111\n",
      "Epoch 196/500\n",
      "1429/1429 [==============================] - 0s 123us/step - loss: 2.5925 - accuracy: 0.3499 - val_loss: 4.3817 - val_accuracy: 0.1153\n",
      "Epoch 197/500\n",
      "1429/1429 [==============================] - 0s 121us/step - loss: 2.5955 - accuracy: 0.3506 - val_loss: 4.3760 - val_accuracy: 0.1132\n",
      "Epoch 198/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.5942 - accuracy: 0.3513 - val_loss: 4.3794 - val_accuracy: 0.1258\n",
      "Epoch 199/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.5923 - accuracy: 0.3450 - val_loss: 4.3801 - val_accuracy: 0.1111\n",
      "Epoch 200/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.6018 - accuracy: 0.3429 - val_loss: 4.3687 - val_accuracy: 0.1132\n",
      "Epoch 201/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.5928 - accuracy: 0.3471 - val_loss: 4.3917 - val_accuracy: 0.1090\n",
      "Epoch 202/500\n",
      "1429/1429 [==============================] - 0s 153us/step - loss: 2.5877 - accuracy: 0.3443 - val_loss: 4.3638 - val_accuracy: 0.1279\n",
      "Epoch 203/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.5894 - accuracy: 0.3443 - val_loss: 4.3851 - val_accuracy: 0.1174\n",
      "Epoch 204/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.5858 - accuracy: 0.3499 - val_loss: 4.3947 - val_accuracy: 0.1237\n",
      "Epoch 205/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.5898 - accuracy: 0.3499 - val_loss: 4.3780 - val_accuracy: 0.1384\n",
      "Epoch 206/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.5936 - accuracy: 0.3450 - val_loss: 4.3639 - val_accuracy: 0.1153\n",
      "Epoch 207/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5889 - accuracy: 0.3485 - val_loss: 4.3933 - val_accuracy: 0.1258\n",
      "Epoch 208/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.5798 - accuracy: 0.3443 - val_loss: 4.3944 - val_accuracy: 0.1279\n",
      "Epoch 209/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5860 - accuracy: 0.3513 - val_loss: 4.3997 - val_accuracy: 0.1216\n",
      "Epoch 210/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5801 - accuracy: 0.3513 - val_loss: 4.3950 - val_accuracy: 0.1132\n",
      "Epoch 211/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.5809 - accuracy: 0.3534 - val_loss: 4.4031 - val_accuracy: 0.1153\n",
      "Epoch 212/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.5820 - accuracy: 0.3478 - val_loss: 4.4102 - val_accuracy: 0.1195\n",
      "Epoch 213/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5885 - accuracy: 0.3485 - val_loss: 4.4142 - val_accuracy: 0.1174\n",
      "Epoch 214/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.5792 - accuracy: 0.3485 - val_loss: 4.3972 - val_accuracy: 0.1174\n",
      "Epoch 215/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5820 - accuracy: 0.3380 - val_loss: 4.4146 - val_accuracy: 0.1111\n",
      "Epoch 216/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.5839 - accuracy: 0.3555 - val_loss: 4.4258 - val_accuracy: 0.1111\n",
      "Epoch 217/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5816 - accuracy: 0.3436 - val_loss: 4.4242 - val_accuracy: 0.1279\n",
      "Epoch 218/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5754 - accuracy: 0.3541 - val_loss: 4.4290 - val_accuracy: 0.1153\n",
      "Epoch 219/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.5788 - accuracy: 0.3492 - val_loss: 4.4188 - val_accuracy: 0.1195\n",
      "Epoch 220/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5757 - accuracy: 0.3569 - val_loss: 4.4460 - val_accuracy: 0.1090\n",
      "Epoch 221/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.5770 - accuracy: 0.3464 - val_loss: 4.4390 - val_accuracy: 0.1111\n",
      "Epoch 222/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5694 - accuracy: 0.3527 - val_loss: 4.4231 - val_accuracy: 0.1111\n",
      "Epoch 223/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5827 - accuracy: 0.3485 - val_loss: 4.4503 - val_accuracy: 0.1237\n",
      "Epoch 224/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5723 - accuracy: 0.3464 - val_loss: 4.4466 - val_accuracy: 0.1174\n",
      "Epoch 225/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.5765 - accuracy: 0.3464 - val_loss: 4.4524 - val_accuracy: 0.1153\n",
      "Epoch 226/500\n",
      "1429/1429 [==============================] - 0s 115us/step - loss: 2.5809 - accuracy: 0.3527 - val_loss: 4.4420 - val_accuracy: 0.1174\n",
      "Epoch 227/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.5672 - accuracy: 0.3520 - val_loss: 4.4817 - val_accuracy: 0.1216\n",
      "Epoch 228/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.5732 - accuracy: 0.3492 - val_loss: 4.4579 - val_accuracy: 0.1258\n",
      "Epoch 229/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.5764 - accuracy: 0.3478 - val_loss: 4.4542 - val_accuracy: 0.1174\n",
      "Epoch 230/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5784 - accuracy: 0.3415 - val_loss: 4.4716 - val_accuracy: 0.1153\n",
      "Epoch 231/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5735 - accuracy: 0.3436 - val_loss: 4.4724 - val_accuracy: 0.1111\n",
      "Epoch 232/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5719 - accuracy: 0.3415 - val_loss: 4.4779 - val_accuracy: 0.1153\n",
      "Epoch 233/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.5651 - accuracy: 0.3541 - val_loss: 4.4928 - val_accuracy: 0.1090\n",
      "Epoch 234/500\n",
      "1429/1429 [==============================] - 0s 134us/step - loss: 2.5695 - accuracy: 0.3520 - val_loss: 4.4773 - val_accuracy: 0.1090\n",
      "Epoch 235/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.5627 - accuracy: 0.3506 - val_loss: 4.4757 - val_accuracy: 0.1111\n",
      "Epoch 236/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.5605 - accuracy: 0.3527 - val_loss: 4.4668 - val_accuracy: 0.1132\n",
      "Epoch 237/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.5663 - accuracy: 0.3436 - val_loss: 4.5002 - val_accuracy: 0.1195\n",
      "Epoch 238/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.5691 - accuracy: 0.3513 - val_loss: 4.4985 - val_accuracy: 0.1174\n",
      "Epoch 239/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5666 - accuracy: 0.3450 - val_loss: 4.4878 - val_accuracy: 0.1132\n",
      "Epoch 240/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.5683 - accuracy: 0.3562 - val_loss: 4.5038 - val_accuracy: 0.1258\n",
      "Epoch 241/500\n",
      "1429/1429 [==============================] - 0s 126us/step - loss: 2.5707 - accuracy: 0.3597 - val_loss: 4.5065 - val_accuracy: 0.1153\n",
      "Epoch 242/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5608 - accuracy: 0.3534 - val_loss: 4.4979 - val_accuracy: 0.1153\n",
      "Epoch 243/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5639 - accuracy: 0.3492 - val_loss: 4.5044 - val_accuracy: 0.1174\n",
      "Epoch 244/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5704 - accuracy: 0.3520 - val_loss: 4.5043 - val_accuracy: 0.1237\n",
      "Epoch 245/500\n",
      "1429/1429 [==============================] - 0s 121us/step - loss: 2.5647 - accuracy: 0.3527 - val_loss: 4.5084 - val_accuracy: 0.1195\n",
      "Epoch 246/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.5632 - accuracy: 0.3541 - val_loss: 4.5040 - val_accuracy: 0.1153\n",
      "Epoch 247/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.5579 - accuracy: 0.3478 - val_loss: 4.5216 - val_accuracy: 0.1237\n",
      "Epoch 248/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.5581 - accuracy: 0.3583 - val_loss: 4.5288 - val_accuracy: 0.1153\n",
      "Epoch 249/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.5624 - accuracy: 0.3499 - val_loss: 4.5277 - val_accuracy: 0.1132\n",
      "Epoch 250/500\n",
      "1429/1429 [==============================] - 0s 121us/step - loss: 2.5599 - accuracy: 0.3513 - val_loss: 4.5225 - val_accuracy: 0.1321\n",
      "Epoch 251/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.5563 - accuracy: 0.3513 - val_loss: 4.5248 - val_accuracy: 0.1153\n",
      "Epoch 252/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.5564 - accuracy: 0.3492 - val_loss: 4.5386 - val_accuracy: 0.1174\n",
      "Epoch 253/500\n",
      "1429/1429 [==============================] - 0s 120us/step - loss: 2.5584 - accuracy: 0.3555 - val_loss: 4.5264 - val_accuracy: 0.1174\n",
      "Epoch 254/500\n",
      "1429/1429 [==============================] - 0s 121us/step - loss: 2.5472 - accuracy: 0.3471 - val_loss: 4.5471 - val_accuracy: 0.1195\n",
      "Epoch 255/500\n",
      "1429/1429 [==============================] - 0s 118us/step - loss: 2.5614 - accuracy: 0.3499 - val_loss: 4.5445 - val_accuracy: 0.1195\n",
      "Epoch 256/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5514 - accuracy: 0.3562 - val_loss: 4.5444 - val_accuracy: 0.1090\n",
      "Epoch 257/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.5554 - accuracy: 0.3555 - val_loss: 4.5423 - val_accuracy: 0.1174\n",
      "Epoch 258/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 118us/step - loss: 2.5568 - accuracy: 0.3513 - val_loss: 4.5562 - val_accuracy: 0.1069\n",
      "Epoch 259/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.5551 - accuracy: 0.3464 - val_loss: 4.5650 - val_accuracy: 0.1174\n",
      "Epoch 260/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.5516 - accuracy: 0.3548 - val_loss: 4.5478 - val_accuracy: 0.1174\n",
      "Epoch 261/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.5632 - accuracy: 0.3604 - val_loss: 4.5674 - val_accuracy: 0.1153\n",
      "Epoch 262/500\n",
      "1429/1429 [==============================] - 0s 125us/step - loss: 2.5559 - accuracy: 0.3520 - val_loss: 4.5717 - val_accuracy: 0.1195\n",
      "Epoch 263/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.5518 - accuracy: 0.3527 - val_loss: 4.5915 - val_accuracy: 0.1132\n",
      "Epoch 264/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5509 - accuracy: 0.3583 - val_loss: 4.5690 - val_accuracy: 0.1090\n",
      "Epoch 265/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5486 - accuracy: 0.3555 - val_loss: 4.5822 - val_accuracy: 0.1111\n",
      "Epoch 266/500\n",
      "1429/1429 [==============================] - 0s 148us/step - loss: 2.5530 - accuracy: 0.3562 - val_loss: 4.5820 - val_accuracy: 0.1174\n",
      "Epoch 267/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.5487 - accuracy: 0.3576 - val_loss: 4.5731 - val_accuracy: 0.1111\n",
      "Epoch 268/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.5504 - accuracy: 0.3555 - val_loss: 4.5920 - val_accuracy: 0.1090\n",
      "Epoch 269/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5517 - accuracy: 0.3534 - val_loss: 4.5809 - val_accuracy: 0.1195\n",
      "Epoch 270/500\n",
      "1429/1429 [==============================] - 0s 115us/step - loss: 2.5456 - accuracy: 0.3604 - val_loss: 4.5761 - val_accuracy: 0.1174\n",
      "Epoch 271/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.5467 - accuracy: 0.3583 - val_loss: 4.5962 - val_accuracy: 0.1216\n",
      "Epoch 272/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.5444 - accuracy: 0.3548 - val_loss: 4.6023 - val_accuracy: 0.1069\n",
      "Epoch 273/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5459 - accuracy: 0.3590 - val_loss: 4.6094 - val_accuracy: 0.1048\n",
      "Epoch 274/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5426 - accuracy: 0.3583 - val_loss: 4.6190 - val_accuracy: 0.1090\n",
      "Epoch 275/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5436 - accuracy: 0.3555 - val_loss: 4.6261 - val_accuracy: 0.0985\n",
      "Epoch 276/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5392 - accuracy: 0.3541 - val_loss: 4.6047 - val_accuracy: 0.1090\n",
      "Epoch 277/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.5441 - accuracy: 0.3597 - val_loss: 4.6097 - val_accuracy: 0.1195\n",
      "Epoch 278/500\n",
      "1429/1429 [==============================] - 0s 134us/step - loss: 2.5503 - accuracy: 0.3590 - val_loss: 4.6040 - val_accuracy: 0.1111\n",
      "Epoch 279/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.5518 - accuracy: 0.3597 - val_loss: 4.6249 - val_accuracy: 0.1195\n",
      "Epoch 280/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.5387 - accuracy: 0.3576 - val_loss: 4.6393 - val_accuracy: 0.1111\n",
      "Epoch 281/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5425 - accuracy: 0.3618 - val_loss: 4.6593 - val_accuracy: 0.1132\n",
      "Epoch 282/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5415 - accuracy: 0.3611 - val_loss: 4.6340 - val_accuracy: 0.1027\n",
      "Epoch 283/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5385 - accuracy: 0.3611 - val_loss: 4.6421 - val_accuracy: 0.1090\n",
      "Epoch 284/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.5390 - accuracy: 0.3625 - val_loss: 4.6298 - val_accuracy: 0.1111\n",
      "Epoch 285/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.5471 - accuracy: 0.3548 - val_loss: 4.6482 - val_accuracy: 0.1174\n",
      "Epoch 286/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.5419 - accuracy: 0.3548 - val_loss: 4.6496 - val_accuracy: 0.1090\n",
      "Epoch 287/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.5403 - accuracy: 0.3562 - val_loss: 4.6498 - val_accuracy: 0.1111\n",
      "Epoch 288/500\n",
      "1429/1429 [==============================] - 0s 124us/step - loss: 2.5407 - accuracy: 0.3618 - val_loss: 4.6566 - val_accuracy: 0.1216\n",
      "Epoch 289/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.5433 - accuracy: 0.3520 - val_loss: 4.6725 - val_accuracy: 0.1048\n",
      "Epoch 290/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5356 - accuracy: 0.3520 - val_loss: 4.6625 - val_accuracy: 0.1048\n",
      "Epoch 291/500\n",
      "1429/1429 [==============================] - 0s 118us/step - loss: 2.5435 - accuracy: 0.3527 - val_loss: 4.6683 - val_accuracy: 0.1111\n",
      "Epoch 292/500\n",
      "1429/1429 [==============================] - 0s 120us/step - loss: 2.5330 - accuracy: 0.3576 - val_loss: 4.6591 - val_accuracy: 0.1153\n",
      "Epoch 293/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.5346 - accuracy: 0.3604 - val_loss: 4.6815 - val_accuracy: 0.1048\n",
      "Epoch 294/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.5390 - accuracy: 0.3597 - val_loss: 4.6715 - val_accuracy: 0.1195\n",
      "Epoch 295/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.5402 - accuracy: 0.3548 - val_loss: 4.6793 - val_accuracy: 0.1069\n",
      "Epoch 296/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.5352 - accuracy: 0.3548 - val_loss: 4.6777 - val_accuracy: 0.1090\n",
      "Epoch 297/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.5324 - accuracy: 0.3569 - val_loss: 4.6762 - val_accuracy: 0.1132\n",
      "Epoch 298/500\n",
      "1429/1429 [==============================] - 0s 151us/step - loss: 2.5332 - accuracy: 0.3597 - val_loss: 4.7248 - val_accuracy: 0.1090\n",
      "Epoch 299/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5357 - accuracy: 0.3716 - val_loss: 4.6805 - val_accuracy: 0.1153\n",
      "Epoch 300/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5281 - accuracy: 0.3534 - val_loss: 4.7157 - val_accuracy: 0.1153\n",
      "Epoch 301/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5390 - accuracy: 0.3604 - val_loss: 4.7092 - val_accuracy: 0.1216\n",
      "Epoch 302/500\n",
      "1429/1429 [==============================] - 0s 151us/step - loss: 2.5323 - accuracy: 0.3604 - val_loss: 4.7020 - val_accuracy: 0.1027\n",
      "Epoch 303/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.5349 - accuracy: 0.3576 - val_loss: 4.7133 - val_accuracy: 0.1132\n",
      "Epoch 304/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5290 - accuracy: 0.3611 - val_loss: 4.7195 - val_accuracy: 0.0985\n",
      "Epoch 305/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5295 - accuracy: 0.3569 - val_loss: 4.7273 - val_accuracy: 0.1090\n",
      "Epoch 306/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5280 - accuracy: 0.3597 - val_loss: 4.7325 - val_accuracy: 0.1027\n",
      "Epoch 307/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.5295 - accuracy: 0.3527 - val_loss: 4.7321 - val_accuracy: 0.1090\n",
      "Epoch 308/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5249 - accuracy: 0.3618 - val_loss: 4.7287 - val_accuracy: 0.1174\n",
      "Epoch 309/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.5266 - accuracy: 0.3646 - val_loss: 4.7364 - val_accuracy: 0.1174\n",
      "Epoch 310/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5266 - accuracy: 0.3548 - val_loss: 4.7318 - val_accuracy: 0.1069\n",
      "Epoch 311/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.5301 - accuracy: 0.3576 - val_loss: 4.7439 - val_accuracy: 0.1069\n",
      "Epoch 312/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5330 - accuracy: 0.3604 - val_loss: 4.7527 - val_accuracy: 0.1048\n",
      "Epoch 313/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.5266 - accuracy: 0.3590 - val_loss: 4.7363 - val_accuracy: 0.1195\n",
      "Epoch 314/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5285 - accuracy: 0.3562 - val_loss: 4.7554 - val_accuracy: 0.1174\n",
      "Epoch 315/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5215 - accuracy: 0.3681 - val_loss: 4.7629 - val_accuracy: 0.1027\n",
      "Epoch 316/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5195 - accuracy: 0.3569 - val_loss: 4.7644 - val_accuracy: 0.1069\n",
      "Epoch 317/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.5288 - accuracy: 0.3583 - val_loss: 4.7503 - val_accuracy: 0.1111\n",
      "Epoch 318/500\n",
      "1429/1429 [==============================] - 0s 126us/step - loss: 2.5263 - accuracy: 0.3569 - val_loss: 4.7593 - val_accuracy: 0.1006\n",
      "Epoch 319/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5242 - accuracy: 0.3653 - val_loss: 4.7508 - val_accuracy: 0.1048\n",
      "Epoch 320/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5233 - accuracy: 0.3541 - val_loss: 4.7569 - val_accuracy: 0.1090\n",
      "Epoch 321/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5306 - accuracy: 0.3625 - val_loss: 4.7893 - val_accuracy: 0.0985\n",
      "Epoch 322/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.5300 - accuracy: 0.3618 - val_loss: 4.7758 - val_accuracy: 0.0985\n",
      "Epoch 323/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.5248 - accuracy: 0.3527 - val_loss: 4.7782 - val_accuracy: 0.0985\n",
      "Epoch 324/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.5260 - accuracy: 0.3625 - val_loss: 4.8040 - val_accuracy: 0.1132\n",
      "Epoch 325/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.5207 - accuracy: 0.3639 - val_loss: 4.7861 - val_accuracy: 0.1027\n",
      "Epoch 326/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5243 - accuracy: 0.3527 - val_loss: 4.8080 - val_accuracy: 0.1069\n",
      "Epoch 327/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5231 - accuracy: 0.3555 - val_loss: 4.7926 - val_accuracy: 0.1111\n",
      "Epoch 328/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.5174 - accuracy: 0.3604 - val_loss: 4.8116 - val_accuracy: 0.1090\n",
      "Epoch 329/500\n",
      "1429/1429 [==============================] - 0s 133us/step - loss: 2.5190 - accuracy: 0.3555 - val_loss: 4.7997 - val_accuracy: 0.1090\n",
      "Epoch 330/500\n",
      "1429/1429 [==============================] - 0s 142us/step - loss: 2.5197 - accuracy: 0.3583 - val_loss: 4.8055 - val_accuracy: 0.1132\n",
      "Epoch 331/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.5202 - accuracy: 0.3632 - val_loss: 4.8116 - val_accuracy: 0.1132\n",
      "Epoch 332/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5206 - accuracy: 0.3555 - val_loss: 4.8173 - val_accuracy: 0.1132\n",
      "Epoch 333/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.5152 - accuracy: 0.3639 - val_loss: 4.8125 - val_accuracy: 0.0985\n",
      "Epoch 334/500\n",
      "1429/1429 [==============================] - 0s 115us/step - loss: 2.5222 - accuracy: 0.3590 - val_loss: 4.8044 - val_accuracy: 0.1195\n",
      "Epoch 335/500\n",
      "1429/1429 [==============================] - 0s 118us/step - loss: 2.5164 - accuracy: 0.3653 - val_loss: 4.8277 - val_accuracy: 0.1069\n",
      "Epoch 336/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5208 - accuracy: 0.3604 - val_loss: 4.8271 - val_accuracy: 0.1048\n",
      "Epoch 337/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.5187 - accuracy: 0.3625 - val_loss: 4.8257 - val_accuracy: 0.1027\n",
      "Epoch 338/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5134 - accuracy: 0.3702 - val_loss: 4.8374 - val_accuracy: 0.0985\n",
      "Epoch 339/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.5186 - accuracy: 0.3576 - val_loss: 4.8537 - val_accuracy: 0.1069\n",
      "Epoch 340/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5159 - accuracy: 0.3562 - val_loss: 4.8345 - val_accuracy: 0.1027\n",
      "Epoch 341/500\n",
      "1429/1429 [==============================] - 0s 131us/step - loss: 2.5129 - accuracy: 0.3611 - val_loss: 4.8321 - val_accuracy: 0.1153\n",
      "Epoch 342/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5117 - accuracy: 0.3583 - val_loss: 4.8624 - val_accuracy: 0.0985\n",
      "Epoch 343/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.5094 - accuracy: 0.3639 - val_loss: 4.8654 - val_accuracy: 0.1006\n",
      "Epoch 344/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.5188 - accuracy: 0.3506 - val_loss: 4.8496 - val_accuracy: 0.1132\n",
      "Epoch 345/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.5130 - accuracy: 0.3625 - val_loss: 4.8633 - val_accuracy: 0.1027\n",
      "Epoch 346/500\n",
      "1429/1429 [==============================] - 0s 125us/step - loss: 2.5121 - accuracy: 0.3632 - val_loss: 4.8707 - val_accuracy: 0.1006\n",
      "Epoch 347/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.5134 - accuracy: 0.3667 - val_loss: 4.8814 - val_accuracy: 0.0985\n",
      "Epoch 348/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.5102 - accuracy: 0.3660 - val_loss: 4.8742 - val_accuracy: 0.1174\n",
      "Epoch 349/500\n",
      "1429/1429 [==============================] - 0s 131us/step - loss: 2.5108 - accuracy: 0.3555 - val_loss: 4.8874 - val_accuracy: 0.1006\n",
      "Epoch 350/500\n",
      "1429/1429 [==============================] - 0s 116us/step - loss: 2.5144 - accuracy: 0.3576 - val_loss: 4.8969 - val_accuracy: 0.1153\n",
      "Epoch 351/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.5077 - accuracy: 0.3597 - val_loss: 4.8846 - val_accuracy: 0.1069\n",
      "Epoch 352/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5142 - accuracy: 0.3611 - val_loss: 4.9142 - val_accuracy: 0.1111\n",
      "Epoch 353/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5112 - accuracy: 0.3527 - val_loss: 4.9172 - val_accuracy: 0.1132\n",
      "Epoch 354/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.5150 - accuracy: 0.3590 - val_loss: 4.9051 - val_accuracy: 0.0985\n",
      "Epoch 355/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5221 - accuracy: 0.3541 - val_loss: 4.9072 - val_accuracy: 0.1132\n",
      "Epoch 356/500\n",
      "1429/1429 [==============================] - 0s 131us/step - loss: 2.5129 - accuracy: 0.3583 - val_loss: 4.9151 - val_accuracy: 0.1027\n",
      "Epoch 357/500\n",
      "1429/1429 [==============================] - 0s 118us/step - loss: 2.5139 - accuracy: 0.3611 - val_loss: 4.9109 - val_accuracy: 0.1048\n",
      "Epoch 358/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5078 - accuracy: 0.3709 - val_loss: 4.9098 - val_accuracy: 0.1111\n",
      "Epoch 359/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.5032 - accuracy: 0.3632 - val_loss: 4.9336 - val_accuracy: 0.1153\n",
      "Epoch 360/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5086 - accuracy: 0.3639 - val_loss: 4.9393 - val_accuracy: 0.1069\n",
      "Epoch 361/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.5043 - accuracy: 0.3611 - val_loss: 4.9347 - val_accuracy: 0.1027\n",
      "Epoch 362/500\n",
      "1429/1429 [==============================] - 0s 138us/step - loss: 2.5074 - accuracy: 0.3625 - val_loss: 4.9492 - val_accuracy: 0.0985\n",
      "Epoch 363/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5038 - accuracy: 0.3674 - val_loss: 4.9210 - val_accuracy: 0.1027\n",
      "Epoch 364/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5012 - accuracy: 0.3695 - val_loss: 4.9498 - val_accuracy: 0.1111\n",
      "Epoch 365/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.5010 - accuracy: 0.3758 - val_loss: 4.9410 - val_accuracy: 0.1069\n",
      "Epoch 366/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.5039 - accuracy: 0.3660 - val_loss: 4.9524 - val_accuracy: 0.1006\n",
      "Epoch 367/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.5061 - accuracy: 0.3625 - val_loss: 4.9560 - val_accuracy: 0.1048\n",
      "Epoch 368/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.5072 - accuracy: 0.3695 - val_loss: 4.9475 - val_accuracy: 0.0985\n",
      "Epoch 369/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5159 - accuracy: 0.3597 - val_loss: 4.9677 - val_accuracy: 0.0964\n",
      "Epoch 370/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5103 - accuracy: 0.3653 - val_loss: 4.9757 - val_accuracy: 0.1153\n",
      "Epoch 371/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5072 - accuracy: 0.3555 - val_loss: 4.9584 - val_accuracy: 0.1027\n",
      "Epoch 372/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.5030 - accuracy: 0.3639 - val_loss: 4.9776 - val_accuracy: 0.1090\n",
      "Epoch 373/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.5087 - accuracy: 0.3583 - val_loss: 4.9802 - val_accuracy: 0.0985\n",
      "Epoch 374/500\n",
      "1429/1429 [==============================] - 0s 106us/step - loss: 2.5034 - accuracy: 0.3653 - val_loss: 4.9794 - val_accuracy: 0.1090\n",
      "Epoch 375/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5006 - accuracy: 0.3618 - val_loss: 4.9770 - val_accuracy: 0.1048\n",
      "Epoch 376/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.5021 - accuracy: 0.3625 - val_loss: 4.9953 - val_accuracy: 0.1069\n",
      "Epoch 377/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5029 - accuracy: 0.3667 - val_loss: 5.0046 - val_accuracy: 0.1111\n",
      "Epoch 378/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.4974 - accuracy: 0.3667 - val_loss: 5.0163 - val_accuracy: 0.1027\n",
      "Epoch 379/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.5077 - accuracy: 0.3674 - val_loss: 5.0014 - val_accuracy: 0.1027\n",
      "Epoch 380/500\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 2.5062 - accuracy: 0.3688 - val_loss: 4.9928 - val_accuracy: 0.1027\n",
      "Epoch 381/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.5063 - accuracy: 0.3569 - val_loss: 4.9939 - val_accuracy: 0.1111\n",
      "Epoch 382/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.5033 - accuracy: 0.3646 - val_loss: 5.0203 - val_accuracy: 0.1090\n",
      "Epoch 383/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.5047 - accuracy: 0.3660 - val_loss: 5.0112 - val_accuracy: 0.0964\n",
      "Epoch 384/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.5037 - accuracy: 0.3618 - val_loss: 5.0044 - val_accuracy: 0.1090\n",
      "Epoch 385/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.4969 - accuracy: 0.3807 - val_loss: 5.0400 - val_accuracy: 0.1006\n",
      "Epoch 386/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.5051 - accuracy: 0.3625 - val_loss: 5.0292 - val_accuracy: 0.1090\n",
      "Epoch 387/500\n",
      "1429/1429 [==============================] - 0s 129us/step - loss: 2.4979 - accuracy: 0.3660 - val_loss: 5.0222 - val_accuracy: 0.0964\n",
      "Epoch 388/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.5005 - accuracy: 0.3639 - val_loss: 5.0403 - val_accuracy: 0.0943\n",
      "Epoch 389/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.4978 - accuracy: 0.3492 - val_loss: 5.0444 - val_accuracy: 0.0985\n",
      "Epoch 390/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.4993 - accuracy: 0.3758 - val_loss: 5.0388 - val_accuracy: 0.1006\n",
      "Epoch 391/500\n",
      "1429/1429 [==============================] - 0s 132us/step - loss: 2.4903 - accuracy: 0.3702 - val_loss: 5.0493 - val_accuracy: 0.1069\n",
      "Epoch 392/500\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 2.4947 - accuracy: 0.3695 - val_loss: 5.0626 - val_accuracy: 0.0985\n",
      "Epoch 393/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.4984 - accuracy: 0.3604 - val_loss: 5.1031 - val_accuracy: 0.1027\n",
      "Epoch 394/500\n",
      "1429/1429 [==============================] - 0s 140us/step - loss: 2.4983 - accuracy: 0.3723 - val_loss: 5.0713 - val_accuracy: 0.1006\n",
      "Epoch 395/500\n",
      "1429/1429 [==============================] - 0s 147us/step - loss: 2.4999 - accuracy: 0.3590 - val_loss: 5.0585 - val_accuracy: 0.1132\n",
      "Epoch 396/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.4971 - accuracy: 0.3723 - val_loss: 5.0579 - val_accuracy: 0.1090\n",
      "Epoch 397/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.4965 - accuracy: 0.3646 - val_loss: 5.0737 - val_accuracy: 0.1111\n",
      "Epoch 398/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.4964 - accuracy: 0.3716 - val_loss: 5.0802 - val_accuracy: 0.1069\n",
      "Epoch 399/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.4975 - accuracy: 0.3716 - val_loss: 5.0977 - val_accuracy: 0.1006\n",
      "Epoch 400/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.4923 - accuracy: 0.3681 - val_loss: 5.0888 - val_accuracy: 0.0964\n",
      "Epoch 401/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.4930 - accuracy: 0.3632 - val_loss: 5.0784 - val_accuracy: 0.1027\n",
      "Epoch 402/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.4933 - accuracy: 0.3611 - val_loss: 5.0963 - val_accuracy: 0.0964\n",
      "Epoch 403/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.4921 - accuracy: 0.3597 - val_loss: 5.0869 - val_accuracy: 0.0985\n",
      "Epoch 404/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.4959 - accuracy: 0.3667 - val_loss: 5.0969 - val_accuracy: 0.1027\n",
      "Epoch 405/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.4931 - accuracy: 0.3639 - val_loss: 5.1184 - val_accuracy: 0.1006\n",
      "Epoch 406/500\n",
      "1429/1429 [==============================] - 0s 98us/step - loss: 2.4925 - accuracy: 0.3590 - val_loss: 5.1193 - val_accuracy: 0.0964\n",
      "Epoch 407/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.4897 - accuracy: 0.3709 - val_loss: 5.1285 - val_accuracy: 0.1090\n",
      "Epoch 408/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.4929 - accuracy: 0.3597 - val_loss: 5.1329 - val_accuracy: 0.0943\n",
      "Epoch 409/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.4944 - accuracy: 0.3583 - val_loss: 5.1348 - val_accuracy: 0.0964\n",
      "Epoch 410/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 2.4946 - accuracy: 0.3646 - val_loss: 5.1232 - val_accuracy: 0.1027\n",
      "Epoch 411/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.5001 - accuracy: 0.3611 - val_loss: 5.1331 - val_accuracy: 0.0964\n",
      "Epoch 412/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.4887 - accuracy: 0.3730 - val_loss: 5.1296 - val_accuracy: 0.0985\n",
      "Epoch 413/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.4915 - accuracy: 0.3730 - val_loss: 5.1368 - val_accuracy: 0.0964\n",
      "Epoch 414/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.4881 - accuracy: 0.3681 - val_loss: 5.1364 - val_accuracy: 0.0964\n",
      "Epoch 415/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.4887 - accuracy: 0.3674 - val_loss: 5.1405 - val_accuracy: 0.1006\n",
      "Epoch 416/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.4842 - accuracy: 0.3688 - val_loss: 5.1550 - val_accuracy: 0.1006\n",
      "Epoch 417/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.4835 - accuracy: 0.3639 - val_loss: 5.1542 - val_accuracy: 0.0964\n",
      "Epoch 418/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.4866 - accuracy: 0.3646 - val_loss: 5.1354 - val_accuracy: 0.0964\n",
      "Epoch 419/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.4891 - accuracy: 0.3695 - val_loss: 5.1577 - val_accuracy: 0.0964\n",
      "Epoch 420/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.4829 - accuracy: 0.3646 - val_loss: 5.1620 - val_accuracy: 0.0964\n",
      "Epoch 421/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.4893 - accuracy: 0.3723 - val_loss: 5.1633 - val_accuracy: 0.1027\n",
      "Epoch 422/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.4852 - accuracy: 0.3765 - val_loss: 5.1683 - val_accuracy: 0.1069\n",
      "Epoch 423/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.4885 - accuracy: 0.3562 - val_loss: 5.2098 - val_accuracy: 0.1006\n",
      "Epoch 424/500\n",
      "1429/1429 [==============================] - 0s 119us/step - loss: 2.4877 - accuracy: 0.3723 - val_loss: 5.1630 - val_accuracy: 0.1048\n",
      "Epoch 425/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.4886 - accuracy: 0.3695 - val_loss: 5.1827 - val_accuracy: 0.0985\n",
      "Epoch 426/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.4852 - accuracy: 0.3702 - val_loss: 5.1909 - val_accuracy: 0.0985\n",
      "Epoch 427/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.4836 - accuracy: 0.3604 - val_loss: 5.1773 - val_accuracy: 0.0922\n",
      "Epoch 428/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.4842 - accuracy: 0.3667 - val_loss: 5.2033 - val_accuracy: 0.1006\n",
      "Epoch 429/500\n",
      "1429/1429 [==============================] - 0s 135us/step - loss: 2.4813 - accuracy: 0.3709 - val_loss: 5.1876 - val_accuracy: 0.1006\n",
      "Epoch 430/500\n",
      "1429/1429 [==============================] - 0s 123us/step - loss: 2.4811 - accuracy: 0.3765 - val_loss: 5.2019 - val_accuracy: 0.0985\n",
      "Epoch 431/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.4843 - accuracy: 0.3688 - val_loss: 5.2112 - val_accuracy: 0.1006\n",
      "Epoch 432/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.4822 - accuracy: 0.3681 - val_loss: 5.2129 - val_accuracy: 0.1048\n",
      "Epoch 433/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.4814 - accuracy: 0.3702 - val_loss: 5.2001 - val_accuracy: 0.0985\n",
      "Epoch 434/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.4802 - accuracy: 0.3737 - val_loss: 5.2122 - val_accuracy: 0.0943\n",
      "Epoch 435/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.4847 - accuracy: 0.3730 - val_loss: 5.2112 - val_accuracy: 0.1048\n",
      "Epoch 436/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.4802 - accuracy: 0.3709 - val_loss: 5.2140 - val_accuracy: 0.0985\n",
      "Epoch 437/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.4743 - accuracy: 0.3688 - val_loss: 5.2327 - val_accuracy: 0.0985\n",
      "Epoch 438/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.4756 - accuracy: 0.3667 - val_loss: 5.2240 - val_accuracy: 0.0943\n",
      "Epoch 439/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.4807 - accuracy: 0.3716 - val_loss: 5.2343 - val_accuracy: 0.1069\n",
      "Epoch 440/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.4836 - accuracy: 0.3709 - val_loss: 5.2303 - val_accuracy: 0.1048\n",
      "Epoch 441/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.4796 - accuracy: 0.3758 - val_loss: 5.2381 - val_accuracy: 0.1069\n",
      "Epoch 442/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.4815 - accuracy: 0.3695 - val_loss: 5.2396 - val_accuracy: 0.1006\n",
      "Epoch 443/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.4811 - accuracy: 0.3737 - val_loss: 5.2641 - val_accuracy: 0.0881\n",
      "Epoch 444/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.4784 - accuracy: 0.3737 - val_loss: 5.2595 - val_accuracy: 0.0943\n",
      "Epoch 445/500\n",
      "1429/1429 [==============================] - 0s 114us/step - loss: 2.4741 - accuracy: 0.3737 - val_loss: 5.2617 - val_accuracy: 0.0985\n",
      "Epoch 446/500\n",
      "1429/1429 [==============================] - 0s 113us/step - loss: 2.4758 - accuracy: 0.3779 - val_loss: 5.2703 - val_accuracy: 0.0964\n",
      "Epoch 447/500\n",
      "1429/1429 [==============================] - 0s 109us/step - loss: 2.4883 - accuracy: 0.3576 - val_loss: 5.2598 - val_accuracy: 0.1069\n",
      "Epoch 448/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.4771 - accuracy: 0.3758 - val_loss: 5.2735 - val_accuracy: 0.0985\n",
      "Epoch 449/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.4756 - accuracy: 0.3695 - val_loss: 5.2990 - val_accuracy: 0.0943\n",
      "Epoch 450/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.4750 - accuracy: 0.3730 - val_loss: 5.2804 - val_accuracy: 0.0964\n",
      "Epoch 451/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.4736 - accuracy: 0.3674 - val_loss: 5.2751 - val_accuracy: 0.1090\n",
      "Epoch 452/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.4781 - accuracy: 0.3737 - val_loss: 5.3070 - val_accuracy: 0.0985\n",
      "Epoch 453/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.4755 - accuracy: 0.3667 - val_loss: 5.3052 - val_accuracy: 0.0943\n",
      "Epoch 454/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.4692 - accuracy: 0.3772 - val_loss: 5.3059 - val_accuracy: 0.1069\n",
      "Epoch 455/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.4813 - accuracy: 0.3723 - val_loss: 5.3071 - val_accuracy: 0.1006\n",
      "Epoch 456/500\n",
      "1429/1429 [==============================] - 0s 89us/step - loss: 2.4789 - accuracy: 0.3723 - val_loss: 5.3086 - val_accuracy: 0.1006\n",
      "Epoch 457/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.4715 - accuracy: 0.3716 - val_loss: 5.3147 - val_accuracy: 0.1006\n",
      "Epoch 458/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.4754 - accuracy: 0.3688 - val_loss: 5.3163 - val_accuracy: 0.1048\n",
      "Epoch 459/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.4771 - accuracy: 0.3723 - val_loss: 5.3285 - val_accuracy: 0.0922\n",
      "Epoch 460/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.4748 - accuracy: 0.3723 - val_loss: 5.3172 - val_accuracy: 0.1027\n",
      "Epoch 461/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.4722 - accuracy: 0.3807 - val_loss: 5.3379 - val_accuracy: 0.0985\n",
      "Epoch 462/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.4729 - accuracy: 0.3793 - val_loss: 5.3476 - val_accuracy: 0.1069\n",
      "Epoch 463/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.4778 - accuracy: 0.3639 - val_loss: 5.3313 - val_accuracy: 0.1027\n",
      "Epoch 464/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.4700 - accuracy: 0.3744 - val_loss: 5.3445 - val_accuracy: 0.0964\n",
      "Epoch 465/500\n",
      "1429/1429 [==============================] - 0s 140us/step - loss: 2.4741 - accuracy: 0.3688 - val_loss: 5.3555 - val_accuracy: 0.0964\n",
      "Epoch 466/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.4712 - accuracy: 0.3709 - val_loss: 5.3356 - val_accuracy: 0.1006\n",
      "Epoch 467/500\n",
      "1429/1429 [==============================] - 0s 104us/step - loss: 2.4743 - accuracy: 0.3604 - val_loss: 5.3554 - val_accuracy: 0.0964\n",
      "Epoch 468/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.4759 - accuracy: 0.3646 - val_loss: 5.3684 - val_accuracy: 0.1069\n",
      "Epoch 469/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.4725 - accuracy: 0.3716 - val_loss: 5.3638 - val_accuracy: 0.1027\n",
      "Epoch 470/500\n",
      "1429/1429 [==============================] - 0s 132us/step - loss: 2.4822 - accuracy: 0.3702 - val_loss: 5.3595 - val_accuracy: 0.1006\n",
      "Epoch 471/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.4730 - accuracy: 0.3779 - val_loss: 5.3692 - val_accuracy: 0.1006\n",
      "Epoch 472/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.4705 - accuracy: 0.3737 - val_loss: 5.3717 - val_accuracy: 0.0943\n",
      "Epoch 473/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.4713 - accuracy: 0.3695 - val_loss: 5.3686 - val_accuracy: 0.0964\n",
      "Epoch 474/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.4697 - accuracy: 0.3730 - val_loss: 5.3799 - val_accuracy: 0.0922\n",
      "Epoch 475/500\n",
      "1429/1429 [==============================] - 0s 133us/step - loss: 2.4717 - accuracy: 0.3730 - val_loss: 5.3682 - val_accuracy: 0.1111\n",
      "Epoch 476/500\n",
      "1429/1429 [==============================] - 0s 121us/step - loss: 2.4696 - accuracy: 0.3779 - val_loss: 5.3938 - val_accuracy: 0.0943\n",
      "Epoch 477/500\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 2.4704 - accuracy: 0.3758 - val_loss: 5.4083 - val_accuracy: 0.1090\n",
      "Epoch 478/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 [==============================] - 0s 121us/step - loss: 2.4670 - accuracy: 0.3765 - val_loss: 5.4019 - val_accuracy: 0.1006\n",
      "Epoch 479/500\n",
      "1429/1429 [==============================] - 0s 112us/step - loss: 2.4657 - accuracy: 0.3737 - val_loss: 5.3934 - val_accuracy: 0.0922\n",
      "Epoch 480/500\n",
      "1429/1429 [==============================] - 0s 110us/step - loss: 2.4686 - accuracy: 0.3709 - val_loss: 5.4154 - val_accuracy: 0.1069\n",
      "Epoch 481/500\n",
      "1429/1429 [==============================] - 0s 111us/step - loss: 2.4678 - accuracy: 0.3779 - val_loss: 5.4102 - val_accuracy: 0.1006\n",
      "Epoch 482/500\n",
      "1429/1429 [==============================] - 0s 118us/step - loss: 2.4701 - accuracy: 0.3772 - val_loss: 5.4228 - val_accuracy: 0.0964\n",
      "Epoch 483/500\n",
      "1429/1429 [==============================] - 0s 133us/step - loss: 2.4703 - accuracy: 0.3723 - val_loss: 5.4189 - val_accuracy: 0.0985\n",
      "Epoch 484/500\n",
      "1429/1429 [==============================] - 0s 123us/step - loss: 2.4652 - accuracy: 0.3716 - val_loss: 5.4463 - val_accuracy: 0.1027\n",
      "Epoch 485/500\n",
      "1429/1429 [==============================] - 0s 92us/step - loss: 2.4715 - accuracy: 0.3758 - val_loss: 5.4213 - val_accuracy: 0.1090\n",
      "Epoch 486/500\n",
      "1429/1429 [==============================] - 0s 96us/step - loss: 2.4610 - accuracy: 0.3758 - val_loss: 5.4347 - val_accuracy: 0.0943\n",
      "Epoch 487/500\n",
      "1429/1429 [==============================] - 0s 100us/step - loss: 2.4591 - accuracy: 0.3807 - val_loss: 5.4534 - val_accuracy: 0.1006\n",
      "Epoch 488/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.4661 - accuracy: 0.3695 - val_loss: 5.4451 - val_accuracy: 0.0964\n",
      "Epoch 489/500\n",
      "1429/1429 [==============================] - 0s 91us/step - loss: 2.4671 - accuracy: 0.3674 - val_loss: 5.4561 - val_accuracy: 0.1090\n",
      "Epoch 490/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.4689 - accuracy: 0.3674 - val_loss: 5.4658 - val_accuracy: 0.1006\n",
      "Epoch 491/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.4622 - accuracy: 0.3737 - val_loss: 5.4604 - val_accuracy: 0.1027\n",
      "Epoch 492/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.4608 - accuracy: 0.3772 - val_loss: 5.4849 - val_accuracy: 0.0943\n",
      "Epoch 493/500\n",
      "1429/1429 [==============================] - 0s 97us/step - loss: 2.4670 - accuracy: 0.3660 - val_loss: 5.4673 - val_accuracy: 0.0985\n",
      "Epoch 494/500\n",
      "1429/1429 [==============================] - 0s 103us/step - loss: 2.4655 - accuracy: 0.3737 - val_loss: 5.4691 - val_accuracy: 0.0943\n",
      "Epoch 495/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.4669 - accuracy: 0.3751 - val_loss: 5.4881 - val_accuracy: 0.1027\n",
      "Epoch 496/500\n",
      "1429/1429 [==============================] - 0s 101us/step - loss: 2.4702 - accuracy: 0.3625 - val_loss: 5.4715 - val_accuracy: 0.0985\n",
      "Epoch 497/500\n",
      "1429/1429 [==============================] - 0s 102us/step - loss: 2.4650 - accuracy: 0.3618 - val_loss: 5.5107 - val_accuracy: 0.0839\n",
      "Epoch 498/500\n",
      "1429/1429 [==============================] - 0s 142us/step - loss: 2.4719 - accuracy: 0.3660 - val_loss: 5.4826 - val_accuracy: 0.0985\n",
      "Epoch 499/500\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 2.4619 - accuracy: 0.3758 - val_loss: 5.4945 - val_accuracy: 0.1006\n",
      "Epoch 500/500\n",
      "1429/1429 [==============================] - 0s 99us/step - loss: 2.4643 - accuracy: 0.3681 - val_loss: 5.5118 - val_accuracy: 0.0964\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "ss = ShuffleSplit(n_splits=5, test_size=0.25, random_state=0)\n",
    "for train_index, test_index in ss.split(X_transform):\n",
    "    X_train, y_train, X_test, y_test=X_transform[train_index],y_[train_index],X_transform[test_index],y_[test_index] \n",
    "    history=model.fit(X_train,y_train,callbacks=callbacks_list,epochs=500,batch_size=32,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_keras=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_keras_inverse=np.argmax(Pred_keras,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1db9117deb8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>99</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>97</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>87</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>477 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual Values  Predicted Values\n",
       "0               53                84\n",
       "1               75                82\n",
       "2                1                68\n",
       "3               97                88\n",
       "4               40                77\n",
       "..             ...               ...\n",
       "472             99                90\n",
       "473             83                80\n",
       "474             97                96\n",
       "475             87                66\n",
       "476             17                15\n",
       "\n",
       "[477 rows x 2 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Actual Values':np.argmax(y_test,axis=1),'Predicted Values':Pred_keras_inverse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 18.134171907756812\n",
      "MSE: 672.335429769392\n",
      "RMSE: 25.929431728624365\n",
      "Accuracy: 9.224318658280922\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,mean_squared_error\n",
    "import numpy as np\n",
    "print('MAE:', mean_absolute_error(np.argmax(y_test,axis=1), Pred_keras_inverse))\n",
    "print('MSE:', mean_squared_error(np.argmax(y_test,axis=1), Pred_keras_inverse))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(np.argmax(y_test,axis=1), Pred_keras_inverse)))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy:',100*accuracy_score(np.argmax(y_test,axis=1),Pred_keras_inverse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,BaggingClassifier,ExtraTreesClassifier,RandomForestRegressor,GradientBoostingRegressor\n",
    "#rfc,gbc,bc,etc=RandomForestClassifier(n_estimators=10),GradientBoostingClassifier(),BaggingClassifier(),ExtraTreesClassifier(),RandomForestRegressor()\n",
    "from sklearn.svm import SVR\n",
    "svr=SVR()\n",
    "rfr=RandomForestRegressor()\n",
    "gbr=GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rfc.fit(X_train,y_train)\n",
    "#gbc.fit(X_train,y_train)\n",
    "#bc.fit(X_train,y_train)\n",
    "#etc.fit(X_train,y_train)\n",
    "#rfr.fit(X_train,y_train)\n",
    "svr.fit(X_train,y_train)\n",
    "\n",
    "#gbr.fit(X_train,y_train)\n",
    "#pred_rfc=rfc.predict(X_test)\n",
    "#pred_gbc=gbc.predict(X_test)\n",
    "#pred_bc=bc.predict(X_test)\n",
    "#pred_etc=etc.predict(X_test)\n",
    "#pred_rfr=rfr.predict(X_test)\n",
    "#pred_gbr=gbr.predict(X_test)\n",
    "pred_svr=svr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 24.475524475524477\n",
      "MSE: 949.0524475524476\n",
      "RMSE: 30.80669484953632\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,mean_squared_error\n",
    "import numpy as np\n",
    "print('MAE:', mean_absolute_error(y_test, np.floor(pred_svr)))\n",
    "print('MSE:', mean_squared_error(y_test, np.floor(pred_svr)))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, np.floor(pred_svr))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 14.926624737945493\n",
      "MSE: 373.70649895178195\n",
      "RMSE: 19.331489827527054\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,mean_squared_error\n",
    "import numpy as np\n",
    "print('MAE:', mean_absolute_error(y_test, np.floor(pred_gbr)))\n",
    "print('MSE:', mean_squared_error(y_test, np.floor(pred_gbr)))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, np.floor(pred_gbr))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 13.60587002096436\n",
      "MSE: 337.0901467505241\n",
      "RMSE: 18.36001488971412\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,mean_squared_error\n",
    "import numpy as np\n",
    "print('MAE:', mean_absolute_error(y_test, np.floor(pred_rfr)))\n",
    "print('MSE:', mean_squared_error(y_test, np.floor(pred_rfr)))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, np.floor(pred_rfr))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kanishk\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[75, 64.0],\n",
       "       [26, 17.0],\n",
       "       [81, 74.0],\n",
       "       [57, 52.0],\n",
       "       [44, 55.0],\n",
       "       [86, 71.0],\n",
       "       [85, 53.0],\n",
       "       [29, 40.0],\n",
       "       [70, 51.0],\n",
       "       [1, 6.0],\n",
       "       [22, 27.0],\n",
       "       [59, 31.0],\n",
       "       [89, 84.0],\n",
       "       [80, 57.0],\n",
       "       [81, 83.0],\n",
       "       [55, 25.0],\n",
       "       [100, 98.0],\n",
       "       [93, 44.0],\n",
       "       [90, 75.0],\n",
       "       [97, 89.0],\n",
       "       [100, 93.0],\n",
       "       [77, 5.0],\n",
       "       [23, 46.0],\n",
       "       [36, 51.0],\n",
       "       [13, 33.0],\n",
       "       [94, 75.0],\n",
       "       [57, 52.0],\n",
       "       [79, 79.0],\n",
       "       [89, 75.0],\n",
       "       [22, 40.0],\n",
       "       [49, 90.0],\n",
       "       [92, 87.0],\n",
       "       [65, 48.0],\n",
       "       [52, 56.0],\n",
       "       [62, 51.0],\n",
       "       [6, 9.0],\n",
       "       [77, 80.0],\n",
       "       [99, 97.0],\n",
       "       [91, 85.0],\n",
       "       [93, 79.0],\n",
       "       [55, 48.0],\n",
       "       [4, 12.0],\n",
       "       [61, 73.0],\n",
       "       [11, 39.0],\n",
       "       [91, 95.0],\n",
       "       [79, 73.0],\n",
       "       [92, 60.0],\n",
       "       [18, 44.0],\n",
       "       [86, 80.0],\n",
       "       [100, 97.0],\n",
       "       [46, 32.0],\n",
       "       [100, 98.0],\n",
       "       [87, 73.0],\n",
       "       [97, 89.0],\n",
       "       [13, 41.0],\n",
       "       [84, 64.0],\n",
       "       [89, 74.0],\n",
       "       [55, 59.0],\n",
       "       [33, 46.0],\n",
       "       [87, 99.0],\n",
       "       [58, 68.0],\n",
       "       [45, 55.0],\n",
       "       [32, 38.0],\n",
       "       [63, 75.0],\n",
       "       [76, 70.0],\n",
       "       [1, 47.0],\n",
       "       [2, 11.0],\n",
       "       [1, 9.0],\n",
       "       [17, 40.0],\n",
       "       [16, 38.0],\n",
       "       [44, 29.0],\n",
       "       [80, 80.0],\n",
       "       [31, 29.0],\n",
       "       [100, 98.0],\n",
       "       [50, 57.0],\n",
       "       [37, 29.0],\n",
       "       [2, 7.0],\n",
       "       [75, 77.0],\n",
       "       [94, 61.0],\n",
       "       [54, 60.0],\n",
       "       [24, 40.0],\n",
       "       [91, 72.0],\n",
       "       [99, 91.0],\n",
       "       [49, 45.0],\n",
       "       [95, 88.0],\n",
       "       [82, 74.0],\n",
       "       [33, 64.0],\n",
       "       [69, 74.0],\n",
       "       [81, 75.0],\n",
       "       [82, 61.0],\n",
       "       [99, 95.0],\n",
       "       [54, 44.0],\n",
       "       [91, 84.0],\n",
       "       [70, 48.0],\n",
       "       [94, 74.0],\n",
       "       [78, 45.0],\n",
       "       [83, 82.0],\n",
       "       [65, 55.0],\n",
       "       [100, 89.0],\n",
       "       [88, 73.0],\n",
       "       [82, 88.0],\n",
       "       [85, 85.0],\n",
       "       [100, 100.0],\n",
       "       [70, 89.0],\n",
       "       [86, 41.0],\n",
       "       [86, 55.0],\n",
       "       [52, 52.0],\n",
       "       [15, 48.0],\n",
       "       [92, 72.0],\n",
       "       [41, 49.0],\n",
       "       [37, 46.0],\n",
       "       [23, 20.0],\n",
       "       [1, 13.0],\n",
       "       [74, 68.0],\n",
       "       [97, 89.0],\n",
       "       [53, 46.0],\n",
       "       [80, 68.0],\n",
       "       [47, 53.0],\n",
       "       [76, 54.0],\n",
       "       [36, 42.0],\n",
       "       [97, 88.0],\n",
       "       [62, 51.0],\n",
       "       [75, 62.0],\n",
       "       [76, 66.0],\n",
       "       [6, 30.0],\n",
       "       [82, 55.0],\n",
       "       [78, 82.0],\n",
       "       [65, 49.0],\n",
       "       [84, 67.0],\n",
       "       [1, 8.0],\n",
       "       [37, 46.0],\n",
       "       [71, 82.0],\n",
       "       [60, 55.0],\n",
       "       [88, 77.0],\n",
       "       [14, 44.0],\n",
       "       [77, 71.0],\n",
       "       [86, 91.0],\n",
       "       [14, 29.0],\n",
       "       [100, 89.0],\n",
       "       [84, 59.0],\n",
       "       [85, 58.0],\n",
       "       [63, 60.0],\n",
       "       [64, 64.0],\n",
       "       [53, 75.0],\n",
       "       [33, 55.0],\n",
       "       [3, 8.0],\n",
       "       [71, 58.0],\n",
       "       [39, 57.0],\n",
       "       [3, 18.0],\n",
       "       [99, 96.0],\n",
       "       [58, 82.0],\n",
       "       [20, 28.0],\n",
       "       [96, 88.0],\n",
       "       [94, 81.0],\n",
       "       [36, 57.0],\n",
       "       [98, 90.0],\n",
       "       [84, 82.0],\n",
       "       [99, 85.0],\n",
       "       [100, 99.0],\n",
       "       [70, 73.0],\n",
       "       [93, 86.0],\n",
       "       [22, 61.0],\n",
       "       [90, 70.0],\n",
       "       [94, 77.0],\n",
       "       [77, 37.0],\n",
       "       [38, 45.0],\n",
       "       [62, 47.0],\n",
       "       [27, 50.0],\n",
       "       [89, 70.0],\n",
       "       [98, 91.0],\n",
       "       [47, 35.0],\n",
       "       [97, 84.0],\n",
       "       [68, 63.0],\n",
       "       [15, 3.0],\n",
       "       [79, 74.0],\n",
       "       [63, 57.0],\n",
       "       [94, 78.0],\n",
       "       [70, 44.0],\n",
       "       [47, 58.0],\n",
       "       [87, 83.0],\n",
       "       [1, 12.0],\n",
       "       [95, 84.0],\n",
       "       [32, 37.0],\n",
       "       [61, 65.0],\n",
       "       [66, 60.0],\n",
       "       [95, 90.0],\n",
       "       [96, 95.0],\n",
       "       [92, 90.0],\n",
       "       [58, 40.0],\n",
       "       [93, 80.0],\n",
       "       [91, 96.0],\n",
       "       [81, 67.0],\n",
       "       [95, 95.0],\n",
       "       [64, 45.0],\n",
       "       [41, 41.0],\n",
       "       [51, 59.0],\n",
       "       [94, 83.0],\n",
       "       [53, 43.0],\n",
       "       [54, 62.0],\n",
       "       [89, 88.0],\n",
       "       [82, 82.0],\n",
       "       [60, 61.0],\n",
       "       [29, 56.0],\n",
       "       [100, 97.0],\n",
       "       [38, 17.0],\n",
       "       [72, 46.0],\n",
       "       [1, 33.0],\n",
       "       [33, 65.0],\n",
       "       [62, 42.0],\n",
       "       [57, 63.0],\n",
       "       [41, 56.0],\n",
       "       [2, 24.0],\n",
       "       [76, 57.0],\n",
       "       [43, 29.0],\n",
       "       [5, 54.0],\n",
       "       [92, 79.0],\n",
       "       [94, 86.0],\n",
       "       [53, 75.0],\n",
       "       [100, 97.0],\n",
       "       [13, 57.0],\n",
       "       [81, 81.0],\n",
       "       [69, 60.0],\n",
       "       [96, 89.0],\n",
       "       [100, 99.0],\n",
       "       [99, 93.0],\n",
       "       [98, 83.0],\n",
       "       [5, 24.0],\n",
       "       [34, 45.0],\n",
       "       [15, 34.0],\n",
       "       [84, 70.0],\n",
       "       [76, 84.0],\n",
       "       [63, 47.0],\n",
       "       [71, 54.0],\n",
       "       [7, 57.0],\n",
       "       [59, 41.0],\n",
       "       [84, 49.0],\n",
       "       [70, 62.0],\n",
       "       [90, 40.0],\n",
       "       [75, 80.0],\n",
       "       [52, 56.0],\n",
       "       [1, 25.0],\n",
       "       [35, 58.0],\n",
       "       [97, 97.0],\n",
       "       [8, 35.0],\n",
       "       [59, 49.0],\n",
       "       [11, 39.0],\n",
       "       [33, 43.0],\n",
       "       [44, 35.0],\n",
       "       [60, 72.0],\n",
       "       [80, 78.0],\n",
       "       [97, 90.0],\n",
       "       [46, 67.0],\n",
       "       [75, 84.0],\n",
       "       [43, 30.0],\n",
       "       [92, 58.0],\n",
       "       [35, 54.0],\n",
       "       [99, 53.0],\n",
       "       [38, 45.0],\n",
       "       [1, 5.0],\n",
       "       [22, 28.0],\n",
       "       [66, 62.0],\n",
       "       [92, 97.0],\n",
       "       [88, 41.0],\n",
       "       [78, 51.0],\n",
       "       [100, 98.0],\n",
       "       [98, 88.0],\n",
       "       [1, 3.0],\n",
       "       [63, 64.0],\n",
       "       [41, 47.0],\n",
       "       [52, 50.0],\n",
       "       [78, 54.0],\n",
       "       [99, 84.0],\n",
       "       [93, 90.0],\n",
       "       [49, 50.0],\n",
       "       [84, 82.0],\n",
       "       [80, 85.0],\n",
       "       [89, 86.0],\n",
       "       [56, 26.0],\n",
       "       [96, 81.0],\n",
       "       [100, 97.0],\n",
       "       [100, 98.0],\n",
       "       [2, 30.0],\n",
       "       [92, 80.0],\n",
       "       [62, 57.0],\n",
       "       [99, 94.0],\n",
       "       [69, 32.0],\n",
       "       [87, 89.0],\n",
       "       [55, 67.0],\n",
       "       [80, 62.0],\n",
       "       [84, 77.0],\n",
       "       [67, 42.0],\n",
       "       [97, 95.0],\n",
       "       [1, 19.0],\n",
       "       [100, 99.0],\n",
       "       [51, 49.0],\n",
       "       [36, 45.0],\n",
       "       [94, 94.0],\n",
       "       [42, 73.0],\n",
       "       [56, 76.0],\n",
       "       [4, 9.0],\n",
       "       [23, 40.0],\n",
       "       [16, 35.0],\n",
       "       [71, 71.0],\n",
       "       [100, 94.0],\n",
       "       [100, 98.0],\n",
       "       [84, 75.0],\n",
       "       [44, 51.0],\n",
       "       [78, 84.0],\n",
       "       [96, 12.0],\n",
       "       [77, 61.0],\n",
       "       [97, 94.0],\n",
       "       [24, 46.0],\n",
       "       [93, 83.0],\n",
       "       [98, 97.0],\n",
       "       [94, 78.0],\n",
       "       [52, 54.0],\n",
       "       [92, 90.0],\n",
       "       [67, 71.0],\n",
       "       [98, 94.0],\n",
       "       [44, 66.0],\n",
       "       [8, 60.0],\n",
       "       [12, 53.0],\n",
       "       [100, 78.0],\n",
       "       [67, 83.0],\n",
       "       [17, 46.0],\n",
       "       [36, 48.0],\n",
       "       [90, 85.0],\n",
       "       [23, 42.0],\n",
       "       [69, 62.0],\n",
       "       [85, 61.0],\n",
       "       [93, 83.0],\n",
       "       [73, 60.0],\n",
       "       [1, 8.0],\n",
       "       [79, 72.0],\n",
       "       [91, 84.0],\n",
       "       [74, 64.0],\n",
       "       [51, 27.0],\n",
       "       [100, 95.0],\n",
       "       [49, 41.0],\n",
       "       [40, 64.0],\n",
       "       [26, 21.0],\n",
       "       [84, 83.0],\n",
       "       [64, 53.0],\n",
       "       [98, 81.0],\n",
       "       [17, 17.0],\n",
       "       [82, 67.0],\n",
       "       [96, 87.0],\n",
       "       [49, 48.0],\n",
       "       [1, 36.0],\n",
       "       [68, 88.0],\n",
       "       [100, 99.0],\n",
       "       [83, 64.0],\n",
       "       [73, 40.0],\n",
       "       [97, 11.0],\n",
       "       [81, 53.0],\n",
       "       [79, 78.0],\n",
       "       [66, 61.0],\n",
       "       [6, 34.0],\n",
       "       [58, 29.0],\n",
       "       [31, 45.0],\n",
       "       [81, 72.0],\n",
       "       [26, 46.0],\n",
       "       [60, 46.0],\n",
       "       [73, 75.0],\n",
       "       [46, 42.0],\n",
       "       [36, 32.0],\n",
       "       [67, 51.0],\n",
       "       [93, 83.0],\n",
       "       [83, 84.0],\n",
       "       [26, 52.0],\n",
       "       [12, 8.0],\n",
       "       [100, 58.0],\n",
       "       [99, 92.0],\n",
       "       [77, 65.0],\n",
       "       [70, 67.0],\n",
       "       [51, 47.0],\n",
       "       [100, 97.0],\n",
       "       [66, 61.0],\n",
       "       [91, 86.0],\n",
       "       [15, 30.0],\n",
       "       [68, 88.0],\n",
       "       [98, 90.0],\n",
       "       [16, 55.0],\n",
       "       [68, 71.0],\n",
       "       [62, 31.0],\n",
       "       [57, 58.0],\n",
       "       [71, 60.0],\n",
       "       [22, 53.0],\n",
       "       [79, 68.0],\n",
       "       [94, 84.0],\n",
       "       [72, 70.0],\n",
       "       [36, 52.0],\n",
       "       [90, 90.0],\n",
       "       [61, 31.0],\n",
       "       [81, 80.0],\n",
       "       [94, 89.0],\n",
       "       [85, 49.0],\n",
       "       [1, 27.0],\n",
       "       [38, 52.0],\n",
       "       [99, 94.0],\n",
       "       [87, 78.0],\n",
       "       [25, 17.0],\n",
       "       [97, 95.0],\n",
       "       [96, 86.0],\n",
       "       [92, 83.0],\n",
       "       [29, 54.0],\n",
       "       [78, 56.0],\n",
       "       [66, 43.0],\n",
       "       [93, 83.0],\n",
       "       [83, 75.0],\n",
       "       [1, 3.0],\n",
       "       [88, 48.0],\n",
       "       [19, 30.0],\n",
       "       [95, 92.0],\n",
       "       [82, 59.0],\n",
       "       [25, 44.0],\n",
       "       [64, 47.0],\n",
       "       [49, 52.0],\n",
       "       [53, 61.0],\n",
       "       [71, 48.0],\n",
       "       [16, 36.0],\n",
       "       [80, 74.0],\n",
       "       [87, 67.0],\n",
       "       [92, 90.0],\n",
       "       [50, 66.0],\n",
       "       [3, 13.0],\n",
       "       [40, 41.0],\n",
       "       [29, 46.0],\n",
       "       [89, 91.0],\n",
       "       [19, 31.0],\n",
       "       [78, 77.0],\n",
       "       [68, 71.0],\n",
       "       [4, 35.0],\n",
       "       [51, 39.0],\n",
       "       [42, 47.0],\n",
       "       [66, 54.0],\n",
       "       [77, 52.0],\n",
       "       [93, 76.0],\n",
       "       [39, 25.0],\n",
       "       [42, 39.0],\n",
       "       [87, 77.0],\n",
       "       [100, 96.0],\n",
       "       [44, 80.0],\n",
       "       [7, 29.0],\n",
       "       [86, 88.0],\n",
       "       [39, 48.0],\n",
       "       [59, 46.0],\n",
       "       [16, 62.0],\n",
       "       [60, 71.0],\n",
       "       [1, 6.0],\n",
       "       [65, 71.0],\n",
       "       [99, 97.0],\n",
       "       [21, 26.0],\n",
       "       [82, 66.0],\n",
       "       [99, 49.0],\n",
       "       [97, 91.0],\n",
       "       [26, 41.0],\n",
       "       [67, 70.0],\n",
       "       [15, 46.0],\n",
       "       [87, 93.0],\n",
       "       [24, 60.0],\n",
       "       [21, 25.0],\n",
       "       [60, 54.0],\n",
       "       [92, 93.0],\n",
       "       [79, 75.0],\n",
       "       [100, 90.0],\n",
       "       [93, 57.0],\n",
       "       [66, 39.0],\n",
       "       [13, 27.0],\n",
       "       [88, 81.0],\n",
       "       [73, 28.0],\n",
       "       [71, 70.0],\n",
       "       [49, 69.0],\n",
       "       [95, 91.0],\n",
       "       [49, 45.0],\n",
       "       [77, 67.0],\n",
       "       [18, 23.0]], dtype=object)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Actual Values':y_test,'Predictions':np.floor(pred_rfr)})\n",
    "df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 16.834381551362682\n",
      "MSE: 620.6331236897274\n",
      "RMSE: 24.91250938162849\n",
      "Accuracy: 5.870020964360587\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,mean_squared_error\n",
    "import numpy as np\n",
    "print('MAE:', mean_absolute_error(y_test, pred_rfc))\n",
    "print('MSE:', mean_squared_error(y_test, pred_rfc))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, pred_rfc)))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy:',100*accuracy_score(y_test,pred_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 84,   8,  12,  87,  44, 100,  63,  41,  92,  13,  51,  99,   2,\n",
       "        95,  77, 100,   9,  88,  47,  53,  85,  88,  63,  13,  86,  87,\n",
       "        80,  41,  29,  17,   1,  60,  72,  79,  48,  79,  99,  47,   2,\n",
       "        19,  79,  89,   1,   6,  99,  21,  43,  60, 100,  87,  89,  93,\n",
       "        63,  63,  30,  93,  44,  71, 100,  92,  80,  46, 100,  93,  91,\n",
       "        63,  16,  99,  47, 100,  61,  68,  16,  80,  66,  98,  94,  38,\n",
       "        91,  99,  70,  92,  22,  66, 100,  40,  20, 100,   1,  59,  93,\n",
       "        51,  29,  35,  87,  37,  97, 100,  63,   1,   8,  15,  77,  91,\n",
       "        83,  67,  94,  74,  95,  58,  97,  99,  45,  41,  93,  86,  15,\n",
       "        79,  64,  64,  47,  76,  84,  71,  98,  41,  89,  54,  62,  93,\n",
       "        93,  45,  94,  59, 100,  96,  58,  35,  78,   3,  41,  15,  30,\n",
       "         1,  99,  83,  87,   1, 100,  43,  49,  97,  29,  76,   7,  68,\n",
       "        42,  49,  25,  87,  77,  88,  26,  93,  71, 100,  89,  18,  74,\n",
       "        42,  79,  94,  80,  85,  79,  81,  40,  69,  44,  89, 100,  49,\n",
       "        94,  81,  62,  65,   1,  43,  36, 100,  92,  83,  63,  43, 100,\n",
       "        18,  75,  87,  93,  39,  98,  60,  35,  32,   1,  87,  16,   1,\n",
       "        78,  20,  53,  29,  20,   6,  77,  91,  50,   6,  98,  88,   1,\n",
       "        85,  94,  85,  91,  51,  48,  54,  98,  34,  26,  62,  69,   2,\n",
       "        76,  71,   1,  44,  87,  52,  98,  80,  89,   4,  44,  61, 100,\n",
       "        79,  22,  46,  93,  26,  36,   8,  61,   6,  62,  78,  88, 100,\n",
       "        44,  94,  84,  46,  44,  25,  87,  90,  34,  97,  91, 100,  25,\n",
       "        92,  74,  14,  26,  40,  87,   3,  94,  28,  98,  88,  72,  89,\n",
       "        21,  64,  36,  53,  43,  86,  61,  78,  65,  74,  76,  34,  84,\n",
       "        26,  64,  87,  67,  59,  64,  97,  52,  21,  94,  59,  39,   6,\n",
       "        79,  49,  60,  66,  29,  15,   2,  86,   6, 100,  22,  12,  50,\n",
       "        90,  98,  43,  79,  97,  79,  89,  70,  52,  69, 100,   1,  98,\n",
       "        41,  74,   1,  50,  30,  88,  89,  66,  52,  79, 100,  78,  97,\n",
       "        30,  49,   1,  40,  44,  59,  22,  77,  88,  50,  80,  91,  65,\n",
       "        51,  55,  30,  78,  71,  74,  91,  44,  99, 100,   1,  45,  71,\n",
       "        73,   6, 100,  40, 100,  42,  85,  96,  79,  88,  68,  29,  33,\n",
       "        83,  59,  83,  69,  89,  40,  67,  47,  63,  33, 100,  20,  87,\n",
       "        92,  44,   9,  47,  44,  92,   1,  58,  66,  54,   3,  49,  70,\n",
       "        70,  56,  99,  44,  75,  86,  93,  91,   8,  14,  18,   6,  58,\n",
       "        98,  76,  50,   1,  91,  34,  35,  79,  60, 100,  47,  49,  38,\n",
       "        58,  87,  74,  47, 100,  23,  78,  54,  63,  42,  81,  83,  15,\n",
       "        77,  28,   1,  77,   1,  10,  81,  90,   2,  88,   1,  76,  47,\n",
       "        92,   1,  28,  69,  61,  79,  90,  63,  28])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Actual Values':y_test,'Predictions':pred_rfc})\n",
    "pred_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kanishk\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 53,  84],\n",
       "       [ 75,   8],\n",
       "       [  1,  12],\n",
       "       [ 97,  87],\n",
       "       [ 40,  44],\n",
       "       [100, 100],\n",
       "       [ 89,  63],\n",
       "       [ 23,  41],\n",
       "       [ 97,  92],\n",
       "       [ 48,  13],\n",
       "       [ 26,  51],\n",
       "       [100,  99],\n",
       "       [ 31,   2],\n",
       "       [ 96,  95],\n",
       "       [ 84,  77],\n",
       "       [100, 100],\n",
       "       [ 10,   9],\n",
       "       [ 66,  88],\n",
       "       [ 53,  47],\n",
       "       [ 43,  53],\n",
       "       [ 96,  85],\n",
       "       [ 91,  88],\n",
       "       [ 58,  63],\n",
       "       [ 47,  13],\n",
       "       [ 71,  86],\n",
       "       [ 81,  87],\n",
       "       [ 97,  80],\n",
       "       [ 45,  41],\n",
       "       [ 29,  29],\n",
       "       [ 85,  17],\n",
       "       [ 27,   1],\n",
       "       [ 85,  60],\n",
       "       [ 50,  72],\n",
       "       [ 88,  79],\n",
       "       [ 12,  48],\n",
       "       [ 93,  79],\n",
       "       [ 98,  99],\n",
       "       [ 41,  47],\n",
       "       [ 16,   2],\n",
       "       [ 31,  19],\n",
       "       [ 89,  79],\n",
       "       [ 95,  89],\n",
       "       [  3,   1],\n",
       "       [  7,   6],\n",
       "       [ 99,  99],\n",
       "       [ 42,  21],\n",
       "       [ 39,  43],\n",
       "       [ 34,  60],\n",
       "       [ 96, 100],\n",
       "       [ 89,  87],\n",
       "       [ 78,  89],\n",
       "       [ 80,  93],\n",
       "       [ 49,  63],\n",
       "       [ 53,  63],\n",
       "       [ 66,  30],\n",
       "       [ 95,  93],\n",
       "       [ 60,  44],\n",
       "       [100,  71],\n",
       "       [100, 100],\n",
       "       [ 98,  92],\n",
       "       [ 90,  80],\n",
       "       [ 55,  46],\n",
       "       [100, 100],\n",
       "       [ 69,  93],\n",
       "       [ 82,  91],\n",
       "       [ 75,  63],\n",
       "       [ 66,  16],\n",
       "       [ 99,  99],\n",
       "       [ 67,  47],\n",
       "       [100, 100],\n",
       "       [ 82,  61],\n",
       "       [ 54,  68],\n",
       "       [ 25,  16],\n",
       "       [ 92,  80],\n",
       "       [ 70,  66],\n",
       "       [100,  98],\n",
       "       [ 79,  94],\n",
       "       [ 37,  38],\n",
       "       [ 90,  91],\n",
       "       [100,  99],\n",
       "       [ 82,  70],\n",
       "       [ 57,  92],\n",
       "       [ 70,  22],\n",
       "       [ 57,  66],\n",
       "       [ 90, 100],\n",
       "       [ 43,  40],\n",
       "       [ 72,  20],\n",
       "       [  7, 100],\n",
       "       [ 84,   1],\n",
       "       [ 93,  59],\n",
       "       [ 74,  93],\n",
       "       [ 55,  51],\n",
       "       [ 22,  29],\n",
       "       [ 32,  35],\n",
       "       [ 92,  87],\n",
       "       [ 29,  37],\n",
       "       [ 85,  97],\n",
       "       [100, 100],\n",
       "       [ 88,  63],\n",
       "       [  4,   1],\n",
       "       [ 44,   8],\n",
       "       [ 58,  15],\n",
       "       [ 95,  77],\n",
       "       [ 82,  91],\n",
       "       [ 77,  83],\n",
       "       [ 88,  67],\n",
       "       [ 91,  94],\n",
       "       [ 53,  74],\n",
       "       [ 73,  95],\n",
       "       [ 54,  58],\n",
       "       [ 91,  97],\n",
       "       [100,  99],\n",
       "       [ 28,  45],\n",
       "       [ 48,  41],\n",
       "       [ 93,  93],\n",
       "       [ 87,  86],\n",
       "       [ 54,  15],\n",
       "       [ 79,  79],\n",
       "       [ 93,  64],\n",
       "       [ 79,  64],\n",
       "       [ 85,  47],\n",
       "       [ 88,  76],\n",
       "       [ 94,  84],\n",
       "       [ 73,  71],\n",
       "       [ 89,  98],\n",
       "       [  5,  41],\n",
       "       [ 40,  89],\n",
       "       [ 55,  54],\n",
       "       [ 62,  62],\n",
       "       [ 95,  93],\n",
       "       [100,  93],\n",
       "       [ 65,  45],\n",
       "       [ 93,  94],\n",
       "       [ 57,  59],\n",
       "       [100, 100],\n",
       "       [ 86,  96],\n",
       "       [ 46,  58],\n",
       "       [ 21,  35],\n",
       "       [ 46,  78],\n",
       "       [  1,   3],\n",
       "       [ 60,  41],\n",
       "       [ 22,  15],\n",
       "       [ 69,  30],\n",
       "       [ 51,   1],\n",
       "       [100,  99],\n",
       "       [ 91,  83],\n",
       "       [ 67,  87],\n",
       "       [ 78,   1],\n",
       "       [ 96, 100],\n",
       "       [ 23,  43],\n",
       "       [ 16,  49],\n",
       "       [ 98,  97],\n",
       "       [ 57,  29],\n",
       "       [ 54,  76],\n",
       "       [ 11,   7],\n",
       "       [ 93,  68],\n",
       "       [ 28,  42],\n",
       "       [ 51,  49],\n",
       "       [ 88,  25],\n",
       "       [ 99,  87],\n",
       "       [ 84,  77],\n",
       "       [ 71,  88],\n",
       "       [ 35,  26],\n",
       "       [100,  93],\n",
       "       [ 56,  71],\n",
       "       [100, 100],\n",
       "       [  7,  89],\n",
       "       [ 21,  18],\n",
       "       [ 84,  74],\n",
       "       [ 32,  42],\n",
       "       [ 90,  79],\n",
       "       [ 96,  94],\n",
       "       [ 95,  80],\n",
       "       [ 63,  85],\n",
       "       [ 69,  79],\n",
       "       [  1,  81],\n",
       "       [ 55,  40],\n",
       "       [ 79,  69],\n",
       "       [ 36,  44],\n",
       "       [ 97,  89],\n",
       "       [100, 100],\n",
       "       [ 81,  49],\n",
       "       [ 94,  94],\n",
       "       [ 94,  81],\n",
       "       [ 64,  62],\n",
       "       [ 42,  65],\n",
       "       [  1,   1],\n",
       "       [ 69,  43],\n",
       "       [ 53,  36],\n",
       "       [100, 100],\n",
       "       [ 98,  92],\n",
       "       [ 92,  83],\n",
       "       [ 71,  63],\n",
       "       [ 26,  43],\n",
       "       [ 99, 100],\n",
       "       [ 30,  18],\n",
       "       [ 71,  75],\n",
       "       [ 89,  87],\n",
       "       [ 82,  93],\n",
       "       [ 83,  39],\n",
       "       [ 98,  98],\n",
       "       [ 80,  60],\n",
       "       [ 42,  35],\n",
       "       [ 29,  32],\n",
       "       [ 53,   1],\n",
       "       [ 97,  87],\n",
       "       [ 31,  16],\n",
       "       [ 71,   1],\n",
       "       [ 68,  78],\n",
       "       [ 70,  20],\n",
       "       [ 81,  53],\n",
       "       [ 29,  29],\n",
       "       [ 20,  20],\n",
       "       [ 26,   6],\n",
       "       [ 63,  77],\n",
       "       [ 49,  91],\n",
       "       [ 52,  50],\n",
       "       [ 66,   6],\n",
       "       [ 99,  98],\n",
       "       [ 64,  88],\n",
       "       [ 53,   1],\n",
       "       [ 82,  85],\n",
       "       [ 95,  94],\n",
       "       [ 94,  85],\n",
       "       [ 36,  91],\n",
       "       [ 68,  51],\n",
       "       [ 24,  48],\n",
       "       [ 91,  54],\n",
       "       [ 87,  98],\n",
       "       [ 82,  34],\n",
       "       [ 17,  26],\n",
       "       [ 45,  62],\n",
       "       [ 44,  69],\n",
       "       [ 38,   2],\n",
       "       [ 77,  76],\n",
       "       [ 79,  71],\n",
       "       [  4,   1],\n",
       "       [ 42,  44],\n",
       "       [ 97,  87],\n",
       "       [ 45,  52],\n",
       "       [ 95,  98],\n",
       "       [ 77,  80],\n",
       "       [ 84,  89],\n",
       "       [ 64,   4],\n",
       "       [ 22,  44],\n",
       "       [ 70,  61],\n",
       "       [100, 100],\n",
       "       [ 93,  79],\n",
       "       [ 39,  22],\n",
       "       [ 36,  46],\n",
       "       [ 92,  93],\n",
       "       [  1,  26],\n",
       "       [ 41,  36],\n",
       "       [ 83,   8],\n",
       "       [ 65,  61],\n",
       "       [  4,   6],\n",
       "       [ 59,  62],\n",
       "       [ 55,  78],\n",
       "       [ 86,  88],\n",
       "       [100, 100],\n",
       "       [  6,  44],\n",
       "       [ 95,  94],\n",
       "       [ 37,  84],\n",
       "       [ 71,  46],\n",
       "       [ 72,  44],\n",
       "       [ 32,  25],\n",
       "       [ 88,  87],\n",
       "       [ 90,  90],\n",
       "       [ 35,  34],\n",
       "       [ 97,  97],\n",
       "       [ 79,  91],\n",
       "       [ 83, 100],\n",
       "       [ 58,  25],\n",
       "       [ 78,  92],\n",
       "       [ 61,  74],\n",
       "       [  6,  14],\n",
       "       [ 15,  26],\n",
       "       [ 51,  40],\n",
       "       [ 83,  87],\n",
       "       [ 26,   3],\n",
       "       [ 86,  94],\n",
       "       [ 29,  28],\n",
       "       [ 87,  98],\n",
       "       [ 90,  88],\n",
       "       [ 36,  72],\n",
       "       [ 91,  89],\n",
       "       [ 31,  21],\n",
       "       [ 88,  64],\n",
       "       [ 51,  36],\n",
       "       [ 21,  53],\n",
       "       [ 34,  43],\n",
       "       [ 78,  86],\n",
       "       [ 53,  61],\n",
       "       [ 79,  78],\n",
       "       [ 61,  65],\n",
       "       [ 58,  74],\n",
       "       [ 60,  76],\n",
       "       [ 32,  34],\n",
       "       [ 85,  84],\n",
       "       [ 44,  26],\n",
       "       [ 84,  64],\n",
       "       [ 98,  87],\n",
       "       [ 64,  67],\n",
       "       [ 50,  59],\n",
       "       [ 35,  64],\n",
       "       [ 96,  97],\n",
       "       [ 48,  52],\n",
       "       [  9,  21],\n",
       "       [ 98,  94],\n",
       "       [ 74,  59],\n",
       "       [ 42,  39],\n",
       "       [ 52,   6],\n",
       "       [ 82,  79],\n",
       "       [ 69,  49],\n",
       "       [ 64,  60],\n",
       "       [ 54,  66],\n",
       "       [ 36,  29],\n",
       "       [ 18,  15],\n",
       "       [  3,   2],\n",
       "       [ 42,  86],\n",
       "       [  4,   6],\n",
       "       [100, 100],\n",
       "       [ 51,  22],\n",
       "       [ 41,  12],\n",
       "       [ 92,  50],\n",
       "       [ 90,  90],\n",
       "       [ 99,  98],\n",
       "       [ 17,  43],\n",
       "       [ 80,  79],\n",
       "       [ 99,  97],\n",
       "       [ 35,  79],\n",
       "       [ 88,  89],\n",
       "       [ 22,  70],\n",
       "       [ 34,  52],\n",
       "       [ 69,  69],\n",
       "       [100, 100],\n",
       "       [  4,   1],\n",
       "       [ 97,  98],\n",
       "       [ 36,  41],\n",
       "       [ 79,  74],\n",
       "       [  3,   1],\n",
       "       [ 70,  50],\n",
       "       [ 45,  30],\n",
       "       [ 97,  88],\n",
       "       [ 80,  89],\n",
       "       [ 84,  66],\n",
       "       [ 24,  52],\n",
       "       [ 63,  79],\n",
       "       [ 75, 100],\n",
       "       [  5,  78],\n",
       "       [ 91,  97],\n",
       "       [ 40,  30],\n",
       "       [ 59,  49],\n",
       "       [ 54,   1],\n",
       "       [ 93,  40],\n",
       "       [ 79,  44],\n",
       "       [ 30,  59],\n",
       "       [ 22,  22],\n",
       "       [ 60,  77],\n",
       "       [ 84,  88],\n",
       "       [ 51,  50],\n",
       "       [ 81,  80],\n",
       "       [ 79,  91],\n",
       "       [ 71,  65],\n",
       "       [ 67,  51],\n",
       "       [ 85,  55],\n",
       "       [ 58,  30],\n",
       "       [ 95,  78],\n",
       "       [ 56,  71],\n",
       "       [ 92,  74],\n",
       "       [100,  91],\n",
       "       [ 36,  44],\n",
       "       [100,  99],\n",
       "       [100, 100],\n",
       "       [ 16,   1],\n",
       "       [ 77,  45],\n",
       "       [ 72,  71],\n",
       "       [ 95,  73],\n",
       "       [ 74,   6],\n",
       "       [ 99, 100],\n",
       "       [ 63,  40],\n",
       "       [ 99, 100],\n",
       "       [ 47,  42],\n",
       "       [ 73,  85],\n",
       "       [ 97,  96],\n",
       "       [ 98,  79],\n",
       "       [ 84,  88],\n",
       "       [ 78,  68],\n",
       "       [ 38,  29],\n",
       "       [ 70,  33],\n",
       "       [ 85,  83],\n",
       "       [ 83,  59],\n",
       "       [ 87,  83],\n",
       "       [ 94,  69],\n",
       "       [ 86,  89],\n",
       "       [ 83,  40],\n",
       "       [ 56,  67],\n",
       "       [ 15,  47],\n",
       "       [ 81,  63],\n",
       "       [ 46,  33],\n",
       "       [100, 100],\n",
       "       [ 19,  20],\n",
       "       [ 88,  87],\n",
       "       [ 97,  92],\n",
       "       [ 73,  44],\n",
       "       [ 14,   9],\n",
       "       [ 41,  47],\n",
       "       [ 34,  44],\n",
       "       [ 96,  92],\n",
       "       [ 48,   1],\n",
       "       [ 20,  58],\n",
       "       [ 52,  66],\n",
       "       [ 25,  54],\n",
       "       [ 21,   3],\n",
       "       [ 70,  49],\n",
       "       [ 68,  70],\n",
       "       [ 19,  70],\n",
       "       [ 67,  56],\n",
       "       [100,  99],\n",
       "       [ 84,  44],\n",
       "       [ 55,  75],\n",
       "       [ 97,  86],\n",
       "       [ 92,  93],\n",
       "       [ 96,  91],\n",
       "       [ 93,   8],\n",
       "       [ 70,  14],\n",
       "       [ 68,  18],\n",
       "       [ 40,   6],\n",
       "       [ 30,  58],\n",
       "       [ 68,  98],\n",
       "       [ 45,  76],\n",
       "       [ 26,  50],\n",
       "       [  1,   1],\n",
       "       [ 61,  91],\n",
       "       [ 59,  34],\n",
       "       [ 64,  35],\n",
       "       [ 65,  79],\n",
       "       [ 46,  60],\n",
       "       [100, 100],\n",
       "       [ 49,  47],\n",
       "       [ 76,  49],\n",
       "       [ 29,  38],\n",
       "       [ 87,  58],\n",
       "       [ 99,  87],\n",
       "       [ 79,  74],\n",
       "       [ 70,  47],\n",
       "       [ 58, 100],\n",
       "       [ 21,  23],\n",
       "       [ 39,  78],\n",
       "       [ 64,  54],\n",
       "       [ 58,  63],\n",
       "       [ 76,  42],\n",
       "       [ 90,  81],\n",
       "       [ 90,  83],\n",
       "       [  4,  15],\n",
       "       [ 82,  77],\n",
       "       [ 62,  28],\n",
       "       [ 18,   1],\n",
       "       [ 88,  77],\n",
       "       [ 81,   1],\n",
       "       [  8,  10],\n",
       "       [ 91,  81],\n",
       "       [ 63,  90],\n",
       "       [ 74,   2],\n",
       "       [ 22,  88],\n",
       "       [  1,   1],\n",
       "       [ 72,  76],\n",
       "       [ 65,  47],\n",
       "       [ 95,  92],\n",
       "       [ 75,   1],\n",
       "       [ 58,  28],\n",
       "       [ 13,  69],\n",
       "       [ 99,  61],\n",
       "       [ 83,  79],\n",
       "       [ 97,  90],\n",
       "       [ 87,  63],\n",
       "       [ 17,  28]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 20.840670859538783\n",
      "MSE: 877.4025157232704\n",
      "RMSE: 29.620981005416926\n",
      "Accuracy: 6.918238993710692\n"
     ]
    }
   ],
   "source": [
    "print('MAE:', mean_absolute_error(y_test, pred_gbc))\n",
    "print('MSE:', mean_squared_error(y_test, pred_gbc))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, pred_gbc)))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy:',100*accuracy_score(y_test,pred_gbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 16.528301886792452\n",
      "MSE: 601.3752620545073\n",
      "RMSE: 24.52295377915367\n",
      "Accuracy: 8.59538784067086\n"
     ]
    }
   ],
   "source": [
    "print('MAE:', mean_absolute_error(y_test, pred_bc))\n",
    "print('MSE:', mean_squared_error(y_test, pred_bc))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, pred_bc)))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy:',100*accuracy_score(y_test,pred_bc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 14.234800838574424\n",
      "MSE: 459.44654088050316\n",
      "RMSE: 21.434704123931898\n",
      "Accuracy: 8.385744234800839\n"
     ]
    }
   ],
   "source": [
    "print('MAE:', mean_absolute_error(y_test, pred_etc))\n",
    "print('MSE:', mean_squared_error(y_test, pred_etc))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, pred_etc)))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy:',100*accuracy_score(y_test,pred_etc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kanishk\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 53,  84],\n",
       "       [ 75,  76],\n",
       "       [  1,  25],\n",
       "       [ 97,  87],\n",
       "       [ 40,  44],\n",
       "       [100, 100],\n",
       "       [ 89,  95],\n",
       "       [ 23,  22],\n",
       "       [ 97,  92],\n",
       "       [ 48,  53],\n",
       "       [ 26,  32],\n",
       "       [100,  99],\n",
       "       [ 31,  47],\n",
       "       [ 96,  95],\n",
       "       [ 84,  90],\n",
       "       [100,  98],\n",
       "       [ 10,   9],\n",
       "       [ 66,  93],\n",
       "       [ 53,  47],\n",
       "       [ 43,  53],\n",
       "       [ 96,  85],\n",
       "       [ 91,  91],\n",
       "       [ 58,  91],\n",
       "       [ 47,  49],\n",
       "       [ 71,  86],\n",
       "       [ 81,  87],\n",
       "       [ 97,  80],\n",
       "       [ 45,  41],\n",
       "       [ 29,   2],\n",
       "       [ 85,  63],\n",
       "       [ 27,  49],\n",
       "       [ 85,  60],\n",
       "       [ 50,  82],\n",
       "       [ 88,  94],\n",
       "       [ 12,  47],\n",
       "       [ 93,  79],\n",
       "       [ 98,  99],\n",
       "       [ 41,  47],\n",
       "       [ 16,   9],\n",
       "       [ 31,  19],\n",
       "       [ 89,  77],\n",
       "       [ 95,  89],\n",
       "       [  3,   1],\n",
       "       [  7,   6],\n",
       "       [ 99,  98],\n",
       "       [ 42,  43],\n",
       "       [ 39,  43],\n",
       "       [ 34,  76],\n",
       "       [ 96, 100],\n",
       "       [ 89,  87],\n",
       "       [ 78,  87],\n",
       "       [ 80,  93],\n",
       "       [ 49,  63],\n",
       "       [ 53,  65],\n",
       "       [ 66,  30],\n",
       "       [ 95,  93],\n",
       "       [ 60,  44],\n",
       "       [100,  99],\n",
       "       [100, 100],\n",
       "       [ 98,  78],\n",
       "       [ 90,  80],\n",
       "       [ 55,  46],\n",
       "       [100, 100],\n",
       "       [ 69,  93],\n",
       "       [ 82,  91],\n",
       "       [ 75,  63],\n",
       "       [ 66,  16],\n",
       "       [ 99, 100],\n",
       "       [ 67,  71],\n",
       "       [100, 100],\n",
       "       [ 82,  95],\n",
       "       [ 54,  68],\n",
       "       [ 25,  13],\n",
       "       [ 92,  78],\n",
       "       [ 70,  67],\n",
       "       [100, 100],\n",
       "       [ 79,  79],\n",
       "       [ 37,  66],\n",
       "       [ 90,  91],\n",
       "       [100,  99],\n",
       "       [ 82,  83],\n",
       "       [ 57,  94],\n",
       "       [ 70,  76],\n",
       "       [ 57,  64],\n",
       "       [ 90, 100],\n",
       "       [ 43,  40],\n",
       "       [ 72,  52],\n",
       "       [  7, 100],\n",
       "       [ 84,  63],\n",
       "       [ 93,  59],\n",
       "       [ 74,  66],\n",
       "       [ 55,  51],\n",
       "       [ 22,  29],\n",
       "       [ 32,  79],\n",
       "       [ 92,  87],\n",
       "       [ 29,  73],\n",
       "       [ 85,  97],\n",
       "       [100, 100],\n",
       "       [ 88,  95],\n",
       "       [  4,   1],\n",
       "       [ 44,   8],\n",
       "       [ 58,  38],\n",
       "       [ 95,  95],\n",
       "       [ 82,  91],\n",
       "       [ 77,  93],\n",
       "       [ 88,  94],\n",
       "       [ 91,  94],\n",
       "       [ 53,  74],\n",
       "       [ 73,   8],\n",
       "       [ 54,  58],\n",
       "       [ 91,  97],\n",
       "       [100,  99],\n",
       "       [ 28,  45],\n",
       "       [ 48,  17],\n",
       "       [ 93,  83],\n",
       "       [ 87,  86],\n",
       "       [ 54,  46],\n",
       "       [ 79,  62],\n",
       "       [ 93,  91],\n",
       "       [ 79,  75],\n",
       "       [ 85,  84],\n",
       "       [ 88,  84],\n",
       "       [ 94,  84],\n",
       "       [ 73,  71],\n",
       "       [ 89,  92],\n",
       "       [  5,   1],\n",
       "       [ 40,  73],\n",
       "       [ 55,  65],\n",
       "       [ 62,  62],\n",
       "       [ 95,  93],\n",
       "       [100, 100],\n",
       "       [ 65,  73],\n",
       "       [ 93,  94],\n",
       "       [ 57,  59],\n",
       "       [100, 100],\n",
       "       [ 86,  96],\n",
       "       [ 46,  49],\n",
       "       [ 21,  35],\n",
       "       [ 46,  47],\n",
       "       [  1,   4],\n",
       "       [ 60,  69],\n",
       "       [ 22,   9],\n",
       "       [ 69,  30],\n",
       "       [ 51,  55],\n",
       "       [100, 100],\n",
       "       [ 91,  93],\n",
       "       [ 67,  93],\n",
       "       [ 78,  49],\n",
       "       [ 96,  96],\n",
       "       [ 23,  41],\n",
       "       [ 16,  47],\n",
       "       [ 98,  99],\n",
       "       [ 57,  29],\n",
       "       [ 54,  76],\n",
       "       [ 11,  43],\n",
       "       [ 93,  88],\n",
       "       [ 28,  42],\n",
       "       [ 51,  69],\n",
       "       [ 88,  70],\n",
       "       [ 99,  87],\n",
       "       [ 84,  77],\n",
       "       [ 71,  88],\n",
       "       [ 35,  49],\n",
       "       [100,  99],\n",
       "       [ 56,  51],\n",
       "       [100, 100],\n",
       "       [  7,  79],\n",
       "       [ 21,  18],\n",
       "       [ 84,  84],\n",
       "       [ 32,  42],\n",
       "       [ 90,  89],\n",
       "       [ 96,  78],\n",
       "       [ 95,  94],\n",
       "       [ 63,  79],\n",
       "       [ 69,  94],\n",
       "       [  1,  81],\n",
       "       [ 55,  36],\n",
       "       [ 79,  34],\n",
       "       [ 36,  44],\n",
       "       [ 97,  95],\n",
       "       [100, 100],\n",
       "       [ 81,  89],\n",
       "       [ 94,  94],\n",
       "       [ 94,  97],\n",
       "       [ 64,  62],\n",
       "       [ 42,  24],\n",
       "       [  1,   1],\n",
       "       [ 69,  54],\n",
       "       [ 53,  36],\n",
       "       [100, 100],\n",
       "       [ 98,  92],\n",
       "       [ 92,  67],\n",
       "       [ 71,  63],\n",
       "       [ 26,  43],\n",
       "       [ 99, 100],\n",
       "       [ 30,  18],\n",
       "       [ 71,  75],\n",
       "       [ 89,  98],\n",
       "       [ 82,  77],\n",
       "       [ 83,  46],\n",
       "       [ 98,  98],\n",
       "       [ 80,  60],\n",
       "       [ 42,  35],\n",
       "       [ 29,  32],\n",
       "       [ 53,   1],\n",
       "       [ 97,  87],\n",
       "       [ 31,  17],\n",
       "       [ 71,  38],\n",
       "       [ 68,  78],\n",
       "       [ 70,  89],\n",
       "       [ 81,  66],\n",
       "       [ 29,  29],\n",
       "       [ 20,  20],\n",
       "       [ 26,   3],\n",
       "       [ 63,   1],\n",
       "       [ 49,  91],\n",
       "       [ 52,  54],\n",
       "       [ 66,  58],\n",
       "       [ 99,  96],\n",
       "       [ 64,  79],\n",
       "       [ 53,   6],\n",
       "       [ 82,  85],\n",
       "       [ 95,  80],\n",
       "       [ 94,  49],\n",
       "       [ 36,  91],\n",
       "       [ 68,  51],\n",
       "       [ 24,  48],\n",
       "       [ 91,  19],\n",
       "       [ 87,  86],\n",
       "       [ 82,  77],\n",
       "       [ 17,  16],\n",
       "       [ 45,  73],\n",
       "       [ 44,  37],\n",
       "       [ 38,  66],\n",
       "       [ 77,  82],\n",
       "       [ 79,  76],\n",
       "       [  4,   1],\n",
       "       [ 42,  44],\n",
       "       [ 97,  87],\n",
       "       [ 45,  85],\n",
       "       [ 95,  97],\n",
       "       [ 77,  80],\n",
       "       [ 84,  89],\n",
       "       [ 64,   7],\n",
       "       [ 22,  44],\n",
       "       [ 70,  76],\n",
       "       [100,  99],\n",
       "       [ 93,  79],\n",
       "       [ 39,  22],\n",
       "       [ 36,  46],\n",
       "       [ 92,  92],\n",
       "       [  1,   4],\n",
       "       [ 41,  36],\n",
       "       [ 83,  73],\n",
       "       [ 65,  61],\n",
       "       [  4,   6],\n",
       "       [ 59,  62],\n",
       "       [ 55,  84],\n",
       "       [ 86,  79],\n",
       "       [100, 100],\n",
       "       [  6,  44],\n",
       "       [ 95,  94],\n",
       "       [ 37,  84],\n",
       "       [ 71,  70],\n",
       "       [ 72,  81],\n",
       "       [ 32,  52],\n",
       "       [ 88,  87],\n",
       "       [ 90,  90],\n",
       "       [ 35,  77],\n",
       "       [ 97,  97],\n",
       "       [ 79,  91],\n",
       "       [ 83,  63],\n",
       "       [ 58,   9],\n",
       "       [ 78,  92],\n",
       "       [ 61,  74],\n",
       "       [  6,  14],\n",
       "       [ 15,   8],\n",
       "       [ 51,  52],\n",
       "       [ 83,  87],\n",
       "       [ 26,   1],\n",
       "       [ 86,  94],\n",
       "       [ 29,  59],\n",
       "       [ 87,  98],\n",
       "       [ 90,  88],\n",
       "       [ 36,  53],\n",
       "       [ 91,  89],\n",
       "       [ 31,  35],\n",
       "       [ 88,  78],\n",
       "       [ 51,  34],\n",
       "       [ 21,   6],\n",
       "       [ 34,  43],\n",
       "       [ 78,  61],\n",
       "       [ 53,  69],\n",
       "       [ 79,  78],\n",
       "       [ 61,  65],\n",
       "       [ 58,  59],\n",
       "       [ 60,  50],\n",
       "       [ 32,  35],\n",
       "       [ 85,  84],\n",
       "       [ 44,  78],\n",
       "       [ 84,  64],\n",
       "       [ 98,  87],\n",
       "       [ 64,  55],\n",
       "       [ 50,  85],\n",
       "       [ 35,  64],\n",
       "       [ 96,  97],\n",
       "       [ 48,  60],\n",
       "       [  9,  52],\n",
       "       [ 98,  94],\n",
       "       [ 74,  67],\n",
       "       [ 42,  39],\n",
       "       [ 52,  14],\n",
       "       [ 82,  92],\n",
       "       [ 69,  49],\n",
       "       [ 64,  60],\n",
       "       [ 54,  66],\n",
       "       [ 36,  29],\n",
       "       [ 18,  15],\n",
       "       [  3,   2],\n",
       "       [ 42,  86],\n",
       "       [  4,   6],\n",
       "       [100, 100],\n",
       "       [ 51,  52],\n",
       "       [ 41,  33],\n",
       "       [ 92,  98],\n",
       "       [ 90,  93],\n",
       "       [ 99,  99],\n",
       "       [ 17,  83],\n",
       "       [ 80,  79],\n",
       "       [ 99, 100],\n",
       "       [ 35,  79],\n",
       "       [ 88,  89],\n",
       "       [ 22,  70],\n",
       "       [ 34,  69],\n",
       "       [ 69,  69],\n",
       "       [100,  94],\n",
       "       [  4,   1],\n",
       "       [ 97,  90],\n",
       "       [ 36,  58],\n",
       "       [ 79,  80],\n",
       "       [  3,   1],\n",
       "       [ 70,  50],\n",
       "       [ 45,  30],\n",
       "       [ 97,  88],\n",
       "       [ 80,  89],\n",
       "       [ 84,  52],\n",
       "       [ 24,  93],\n",
       "       [ 63,  79],\n",
       "       [ 75, 100],\n",
       "       [  5,  78],\n",
       "       [ 91,  97],\n",
       "       [ 40,  30],\n",
       "       [ 59,  47],\n",
       "       [ 54,   1],\n",
       "       [ 93,  64],\n",
       "       [ 79,  83],\n",
       "       [ 30,  64],\n",
       "       [ 22,   6],\n",
       "       [ 60,  83],\n",
       "       [ 84,  88],\n",
       "       [ 51,  44],\n",
       "       [ 81,  80],\n",
       "       [ 79,  91],\n",
       "       [ 71,  75],\n",
       "       [ 67,  82],\n",
       "       [ 85,  89],\n",
       "       [ 58,  47],\n",
       "       [ 95,  84],\n",
       "       [ 56,  51],\n",
       "       [ 92,  95],\n",
       "       [100,  98],\n",
       "       [ 36,  44],\n",
       "       [100,  98],\n",
       "       [100, 100],\n",
       "       [ 16,  28],\n",
       "       [ 77,  47],\n",
       "       [ 72,  71],\n",
       "       [ 95,  80],\n",
       "       [ 74,  76],\n",
       "       [ 99, 100],\n",
       "       [ 63,  33],\n",
       "       [ 99, 100],\n",
       "       [ 47,  69],\n",
       "       [ 73,  85],\n",
       "       [ 97,  96],\n",
       "       [ 98,  98],\n",
       "       [ 84,  71],\n",
       "       [ 78,  88],\n",
       "       [ 38,  29],\n",
       "       [ 70,  33],\n",
       "       [ 85,  70],\n",
       "       [ 83,  59],\n",
       "       [ 87,  70],\n",
       "       [ 94,  82],\n",
       "       [ 86,  89],\n",
       "       [ 83,  94],\n",
       "       [ 56,  75],\n",
       "       [ 15,  81],\n",
       "       [ 81,  70],\n",
       "       [ 46,  33],\n",
       "       [100, 100],\n",
       "       [ 19,  20],\n",
       "       [ 88,  78],\n",
       "       [ 97,  96],\n",
       "       [ 73,  77],\n",
       "       [ 14,   9],\n",
       "       [ 41,  47],\n",
       "       [ 34,  44],\n",
       "       [ 96,  92],\n",
       "       [ 48,   1],\n",
       "       [ 20,   6],\n",
       "       [ 52,  25],\n",
       "       [ 25,  44],\n",
       "       [ 21,  25],\n",
       "       [ 70,  75],\n",
       "       [ 68,  45],\n",
       "       [ 19,  70],\n",
       "       [ 67,  56],\n",
       "       [100,  98],\n",
       "       [ 84,  86],\n",
       "       [ 55,  93],\n",
       "       [ 97,  97],\n",
       "       [ 92,  93],\n",
       "       [ 96,  99],\n",
       "       [ 93,  44],\n",
       "       [ 70,  61],\n",
       "       [ 68,  23],\n",
       "       [ 40,   8],\n",
       "       [ 30,  58],\n",
       "       [ 68,  91],\n",
       "       [ 45,  76],\n",
       "       [ 26,  44],\n",
       "       [  1,   1],\n",
       "       [ 61,  91],\n",
       "       [ 59,  60],\n",
       "       [ 64,  64],\n",
       "       [ 65,  79],\n",
       "       [ 46,  47],\n",
       "       [100, 100],\n",
       "       [ 49,  47],\n",
       "       [ 76,  49],\n",
       "       [ 29,  66],\n",
       "       [ 87,  87],\n",
       "       [ 99,  99],\n",
       "       [ 79,  30],\n",
       "       [ 70,  47],\n",
       "       [ 58, 100],\n",
       "       [ 21,   1],\n",
       "       [ 39,  78],\n",
       "       [ 64,  79],\n",
       "       [ 58,  63],\n",
       "       [ 76,  86],\n",
       "       [ 90,  94],\n",
       "       [ 90,  88],\n",
       "       [  4,  15],\n",
       "       [ 82,  84],\n",
       "       [ 62,  41],\n",
       "       [ 18,   1],\n",
       "       [ 88,  77],\n",
       "       [ 81,  68],\n",
       "       [  8,  16],\n",
       "       [ 91,  79],\n",
       "       [ 63,  44],\n",
       "       [ 74,  52],\n",
       "       [ 22,  83],\n",
       "       [  1,   1],\n",
       "       [ 72,  87],\n",
       "       [ 65,  47],\n",
       "       [ 95,  92],\n",
       "       [ 75,   1],\n",
       "       [ 58,   1],\n",
       "       [ 13,  69],\n",
       "       [ 99,  93],\n",
       "       [ 83,  35],\n",
       "       [ 97,  95],\n",
       "       [ 87,  75],\n",
       "       [ 17,  28]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Actual Values':y_test,'Predictions':pred_etc})\n",
    "df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_transform, y, test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kanishk\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[43.0, 45.0],\n",
       "       [88.0, 90.0],\n",
       "       [77.0, 91.0],\n",
       "       [81.0, 85.0],\n",
       "       [63.0, 55.0],\n",
       "       [87.0, 87.0],\n",
       "       [75.0, 62.0],\n",
       "       [65.0, 8.0],\n",
       "       [85.0, 87.0],\n",
       "       [21.0, 1.0],\n",
       "       [70.0, 59.0],\n",
       "       [70.0, 59.0],\n",
       "       [63.0, 90.0],\n",
       "       [95.0, 98.0],\n",
       "       [97.0, 90.0],\n",
       "       [99.0, 100.0],\n",
       "       [82.0, 68.0],\n",
       "       [92.0, 83.0],\n",
       "       [39.0, 42.0],\n",
       "       [73.0, 74.0],\n",
       "       [94.0, 88.0],\n",
       "       [7.0, 2.0],\n",
       "       [65.0, 40.0],\n",
       "       [95.0, 91.0],\n",
       "       [36.0, 18.0],\n",
       "       [98.0, 100.0],\n",
       "       [90.0, 87.0],\n",
       "       [27.0, 57.0],\n",
       "       [68.0, 59.0],\n",
       "       [14.0, 59.0],\n",
       "       [10.0, 1.0],\n",
       "       [63.0, 69.0],\n",
       "       [88.0, 97.0],\n",
       "       [35.0, 67.0],\n",
       "       [79.0, 83.0],\n",
       "       [76.0, 79.0],\n",
       "       [87.0, 80.0],\n",
       "       [1.0, 1.0],\n",
       "       [33.0, 39.0],\n",
       "       [77.0, 71.0],\n",
       "       [62.0, 47.0],\n",
       "       [68.0, 73.0],\n",
       "       [97.0, 100.0],\n",
       "       [41.0, 29.0],\n",
       "       [1.0, 47.0],\n",
       "       [53.0, 1.0],\n",
       "       [13.0, 35.0],\n",
       "       [74.0, 40.0],\n",
       "       [77.0, 44.0],\n",
       "       [54.0, 76.0],\n",
       "       [68.0, 91.0],\n",
       "       [53.0, 16.0],\n",
       "       [100.0, 96.0],\n",
       "       [49.0, 76.0],\n",
       "       [14.0, 1.0],\n",
       "       [100.0, 100.0],\n",
       "       [94.0, 87.0],\n",
       "       [95.0, 55.0],\n",
       "       [50.0, 64.0],\n",
       "       [88.0, 94.0],\n",
       "       [22.0, 37.0],\n",
       "       [34.0, 21.0],\n",
       "       [94.0, 96.0],\n",
       "       [9.0, 3.0],\n",
       "       [52.0, 34.0],\n",
       "       [60.0, 63.0],\n",
       "       [94.0, 96.0],\n",
       "       [88.0, 87.0],\n",
       "       [81.0, 22.0],\n",
       "       [84.0, 24.0],\n",
       "       [74.0, 58.0],\n",
       "       [76.0, 77.0],\n",
       "       [75.0, 78.0],\n",
       "       [76.0, 63.0],\n",
       "       [88.0, 89.0],\n",
       "       [83.0, 73.0],\n",
       "       [86.0, 87.0],\n",
       "       [52.0, 53.0],\n",
       "       [59.0, 61.0],\n",
       "       [8.0, 35.0],\n",
       "       [77.0, 81.0],\n",
       "       [5.0, 6.0],\n",
       "       [100.0, 100.0],\n",
       "       [7.0, 16.0],\n",
       "       [43.0, 46.0],\n",
       "       [82.0, 65.0],\n",
       "       [56.0, 60.0],\n",
       "       [34.0, 38.0],\n",
       "       [7.0, 1.0],\n",
       "       [15.0, 13.0],\n",
       "       [89.0, 91.0],\n",
       "       [80.0, 34.0],\n",
       "       [69.0, 44.0],\n",
       "       [35.0, 18.0],\n",
       "       [1.0, 1.0],\n",
       "       [91.0, 81.0],\n",
       "       [37.0, 37.0],\n",
       "       [77.0, 100.0],\n",
       "       [58.0, 1.0],\n",
       "       [53.0, 56.0],\n",
       "       [29.0, 37.0],\n",
       "       [66.0, 14.0],\n",
       "       [61.0, 56.0],\n",
       "       [1.0, 1.0],\n",
       "       [72.0, 11.0],\n",
       "       [58.0, 45.0],\n",
       "       [30.0, 29.0],\n",
       "       [78.0, 82.0],\n",
       "       [85.0, 65.0],\n",
       "       [84.0, 57.0],\n",
       "       [50.0, 47.0],\n",
       "       [1.0, 3.0],\n",
       "       [44.0, 36.0],\n",
       "       [97.0, 89.0],\n",
       "       [86.0, 91.0],\n",
       "       [63.0, 51.0],\n",
       "       [33.0, 25.0],\n",
       "       [8.0, 21.0],\n",
       "       [100.0, 100.0],\n",
       "       [53.0, 63.0],\n",
       "       [83.0, 90.0],\n",
       "       [15.0, 21.0],\n",
       "       [87.0, 92.0],\n",
       "       [100.0, 100.0],\n",
       "       [23.0, 2.0],\n",
       "       [72.0, 28.0],\n",
       "       [79.0, 81.0],\n",
       "       [82.0, 66.0],\n",
       "       [26.0, 29.0],\n",
       "       [81.0, 70.0],\n",
       "       [2.0, 1.0],\n",
       "       [53.0, 56.0],\n",
       "       [93.0, 87.0],\n",
       "       [100.0, 76.0],\n",
       "       [9.0, 1.0],\n",
       "       [6.0, 38.0],\n",
       "       [5.0, 8.0],\n",
       "       [58.0, 47.0],\n",
       "       [91.0, 100.0],\n",
       "       [46.0, 68.0],\n",
       "       [80.0, 51.0],\n",
       "       [78.0, 87.0],\n",
       "       [66.0, 1.0],\n",
       "       [77.0, 62.0],\n",
       "       [68.0, 86.0],\n",
       "       [8.0, 30.0],\n",
       "       [86.0, 51.0],\n",
       "       [17.0, 1.0],\n",
       "       [84.0, 51.0],\n",
       "       [61.0, 30.0],\n",
       "       [80.0, 66.0],\n",
       "       [92.0, 79.0],\n",
       "       [58.0, 40.0],\n",
       "       [69.0, 73.0],\n",
       "       [92.0, 70.0],\n",
       "       [73.0, 30.0],\n",
       "       [4.0, 43.0],\n",
       "       [13.0, 69.0],\n",
       "       [93.0, 24.0],\n",
       "       [100.0, 98.0],\n",
       "       [82.0, 83.0],\n",
       "       [70.0, 59.0],\n",
       "       [100.0, 98.0],\n",
       "       [90.0, 84.0],\n",
       "       [6.0, 1.0],\n",
       "       [70.0, 73.0],\n",
       "       [58.0, 54.0],\n",
       "       [69.0, 38.0],\n",
       "       [59.0, 1.0],\n",
       "       [51.0, 51.0],\n",
       "       [95.0, 99.0],\n",
       "       [70.0, 51.0],\n",
       "       [29.0, 46.0],\n",
       "       [91.0, 88.0],\n",
       "       [100.0, 93.0],\n",
       "       [94.0, 70.0],\n",
       "       [68.0, 91.0],\n",
       "       [44.0, 27.0],\n",
       "       [77.0, 76.0],\n",
       "       [64.0, 62.0],\n",
       "       [92.0, 51.0],\n",
       "       [65.0, 58.0],\n",
       "       [2.0, 1.0],\n",
       "       [64.0, 76.0],\n",
       "       [74.0, 71.0],\n",
       "       [59.0, 51.0],\n",
       "       [79.0, 84.0],\n",
       "       [58.0, 46.0],\n",
       "       [32.0, 21.0],\n",
       "       [99.0, 37.0],\n",
       "       [88.0, 82.0],\n",
       "       [89.0, 87.0],\n",
       "       [55.0, 63.0],\n",
       "       [77.0, 80.0],\n",
       "       [56.0, 1.0],\n",
       "       [97.0, 4.0],\n",
       "       [35.0, 1.0],\n",
       "       [80.0, 35.0],\n",
       "       [8.0, 25.0],\n",
       "       [70.0, 82.0],\n",
       "       [71.0, 73.0],\n",
       "       [94.0, 91.0],\n",
       "       [81.0, 57.0],\n",
       "       [79.0, 79.0],\n",
       "       [78.0, 100.0],\n",
       "       [33.0, 19.0],\n",
       "       [22.0, 15.0],\n",
       "       [74.0, 66.0],\n",
       "       [10.0, 13.0],\n",
       "       [87.0, 99.0],\n",
       "       [78.0, 91.0],\n",
       "       [33.0, 61.0],\n",
       "       [84.0, 62.0],\n",
       "       [45.0, 46.0],\n",
       "       [84.0, 6.0],\n",
       "       [90.0, 89.0],\n",
       "       [61.0, 91.0],\n",
       "       [69.0, 62.0],\n",
       "       [52.0, 56.0],\n",
       "       [12.0, 6.0],\n",
       "       [81.0, 74.0],\n",
       "       [84.0, 84.0],\n",
       "       [58.0, 49.0],\n",
       "       [40.0, 42.0],\n",
       "       [37.0, 36.0],\n",
       "       [22.0, 44.0],\n",
       "       [80.0, 80.0],\n",
       "       [61.0, 26.0],\n",
       "       [60.0, 83.0],\n",
       "       [20.0, 25.0],\n",
       "       [87.0, 54.0],\n",
       "       [52.0, 32.0],\n",
       "       [32.0, 67.0],\n",
       "       [100.0, 100.0],\n",
       "       [1.0, 1.0],\n",
       "       [90.0, 76.0],\n",
       "       [38.0, 24.0],\n",
       "       [79.0, 62.0],\n",
       "       [58.0, 87.0],\n",
       "       [58.0, 36.0],\n",
       "       [97.0, 96.0],\n",
       "       [32.0, 74.0],\n",
       "       [65.0, 62.0],\n",
       "       [36.0, 42.0],\n",
       "       [92.0, 100.0],\n",
       "       [92.0, 76.0],\n",
       "       [95.0, 90.0],\n",
       "       [21.0, 30.0],\n",
       "       [93.0, 91.0],\n",
       "       [72.0, 22.0],\n",
       "       [92.0, 96.0],\n",
       "       [65.0, 59.0],\n",
       "       [72.0, 53.0],\n",
       "       [91.0, 100.0],\n",
       "       [7.0, 20.0],\n",
       "       [78.0, 39.0],\n",
       "       [99.0, 57.0],\n",
       "       [75.0, 56.0],\n",
       "       [56.0, 24.0],\n",
       "       [100.0, 90.0],\n",
       "       [55.0, 21.0],\n",
       "       [90.0, 28.0],\n",
       "       [64.0, 54.0],\n",
       "       [23.0, 49.0],\n",
       "       [30.0, 46.0],\n",
       "       [95.0, 42.0],\n",
       "       [86.0, 87.0],\n",
       "       [97.0, 100.0],\n",
       "       [35.0, 29.0],\n",
       "       [79.0, 68.0],\n",
       "       [85.0, 57.0],\n",
       "       [87.0, 90.0],\n",
       "       [51.0, 18.0],\n",
       "       [92.0, 76.0],\n",
       "       [86.0, 87.0],\n",
       "       [79.0, 78.0],\n",
       "       [88.0, 57.0],\n",
       "       [22.0, 6.0],\n",
       "       [38.0, 1.0],\n",
       "       [18.0, 16.0]], dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bc.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((652, 8), (652,), (280, 8), (280,))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=r'C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='mse', verbose=1, save_best_only=True, mode='auto')\n",
    "#early = EarlyStopping(monitor=\"acc\", mode=\"auto\", patience= 10)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "def build_regressor():\n",
    "    regressor = Sequential()\n",
    "    regressor.add(Dense(units=32, input_dim=8,kernel_initializer='normal',activation='relu'))\n",
    "    regressor.add(Dense(units=1,kernel_initializer='normal'))\n",
    "    regressor.compile(optimizer='adam', loss='mean_squared_error',  metrics=['mse','accuracy'])\n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "regressor = KerasRegressor(build_fn=build_regressor,callbacks=callbacks_list, batch_size=40,epochs=10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "regressor.model.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1429/1429 [==============================] - 1s 414us/step - loss: 4765.7425 - mse: 4765.7427 - accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: mse improved from inf to 4765.74268, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 2/10\n",
      "1429/1429 [==============================] - 0s 210us/step - loss: 4752.7946 - mse: 4752.7949 - accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00002: mse improved from 4765.74268 to 4752.79492, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 3/10\n",
      "1429/1429 [==============================] - 0s 166us/step - loss: 4728.8690 - mse: 4728.8687 - accuracy: 6.9979e-04\n",
      "\n",
      "Epoch 00003: mse improved from 4752.79492 to 4728.86865, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 4/10\n",
      "1429/1429 [==============================] - 0s 107us/step - loss: 4689.1859 - mse: 4689.1855 - accuracy: 0.0245\n",
      "\n",
      "Epoch 00004: mse improved from 4728.86865 to 4689.18555, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 5/10\n",
      "1429/1429 [==============================] - 0s 76us/step - loss: 4631.5736 - mse: 4631.5732 - accuracy: 0.0294\n",
      "\n",
      "Epoch 00005: mse improved from 4689.18555 to 4631.57324, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 6/10\n",
      "1429/1429 [==============================] - 0s 66us/step - loss: 4557.2532 - mse: 4557.2524 - accuracy: 0.0133\n",
      "\n",
      "Epoch 00006: mse improved from 4631.57324 to 4557.25244, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 7/10\n",
      "1429/1429 [==============================] - 0s 71us/step - loss: 4467.5009 - mse: 4467.5005 - accuracy: 0.0077\n",
      "\n",
      "Epoch 00007: mse improved from 4557.25244 to 4467.50049, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 8/10\n",
      "1429/1429 [==============================] - 0s 71us/step - loss: 4362.7875 - mse: 4362.7876 - accuracy: 0.0077\n",
      "\n",
      "Epoch 00008: mse improved from 4467.50049 to 4362.78760, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 9/10\n",
      "1429/1429 [==============================] - 0s 69us/step - loss: 4244.5237 - mse: 4244.5239 - accuracy: 0.0063\n",
      "\n",
      "Epoch 00009: mse improved from 4362.78760 to 4244.52393, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 10/10\n",
      "1429/1429 [==============================] - 0s 72us/step - loss: 4114.4344 - mse: 4114.4346 - accuracy: 0.0070\n",
      "\n",
      "Epoch 00010: mse improved from 4244.52393 to 4114.43457, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 1/10\n",
      "1429/1429 [==============================] - 0s 191us/step - loss: 4751.0815 - mse: 4751.0811 - accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: mse improved from inf to 4751.08105, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 2/10\n",
      "1429/1429 [==============================] - 0s 81us/step - loss: 4739.5470 - mse: 4739.5474 - accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00002: mse improved from 4751.08105 to 4739.54736, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 3/10\n",
      "1429/1429 [==============================] - 0s 81us/step - loss: 4717.6015 - mse: 4717.6021 - accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00003: mse improved from 4739.54736 to 4717.60205, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 4/10\n",
      "1429/1429 [==============================] - 0s 81us/step - loss: 4682.9240 - mse: 4682.9238 - accuracy: 0.0294\n",
      "\n",
      "Epoch 00004: mse improved from 4717.60205 to 4682.92383, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 5/10\n",
      "1429/1429 [==============================] - 0s 85us/step - loss: 4635.0677 - mse: 4635.0679 - accuracy: 0.0385\n",
      "\n",
      "Epoch 00005: mse improved from 4682.92383 to 4635.06787, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 6/10\n",
      "1429/1429 [==============================] - 0s 108us/step - loss: 4573.7050 - mse: 4573.7046 - accuracy: 0.0259\n",
      "\n",
      "Epoch 00006: mse improved from 4635.06787 to 4573.70459, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 7/10\n",
      "1429/1429 [==============================] - 0s 134us/step - loss: 4499.8922 - mse: 4499.8921 - accuracy: 0.0077\n",
      "\n",
      "Epoch 00007: mse improved from 4573.70459 to 4499.89209, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 8/10\n",
      "1429/1429 [==============================] - 0s 105us/step - loss: 4413.4922 - mse: 4413.4922 - accuracy: 0.0049\n",
      "\n",
      "Epoch 00008: mse improved from 4499.89209 to 4413.49219, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 9/10\n",
      "1429/1429 [==============================] - 0s 126us/step - loss: 4315.5554 - mse: 4315.5557 - accuracy: 0.0021\n",
      "\n",
      "Epoch 00009: mse improved from 4413.49219 to 4315.55566, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 10/10\n",
      "1429/1429 [==============================] - 0s 177us/step - loss: 4206.1926 - mse: 4206.1929 - accuracy: 0.0042\n",
      "\n",
      "Epoch 00010: mse improved from 4315.55566 to 4206.19287, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 1/10\n",
      "1429/1429 [==============================] - 0s 152us/step - loss: 4818.8674 - mse: 4818.8677 - accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: mse improved from inf to 4818.86768, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 2/10\n",
      "1429/1429 [==============================] - 0s 67us/step - loss: 4807.0107 - mse: 4807.0103 - accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00002: mse improved from 4818.86768 to 4807.01025, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 3/10\n",
      "1429/1429 [==============================] - 0s 65us/step - loss: 4784.3398 - mse: 4784.3403 - accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00003: mse improved from 4807.01025 to 4784.34033, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 4/10\n",
      "1429/1429 [==============================] - 0s 67us/step - loss: 4748.0086 - mse: 4748.0088 - accuracy: 0.0259\n",
      "\n",
      "Epoch 00004: mse improved from 4784.34033 to 4748.00879, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 5/10\n",
      "1429/1429 [==============================] - 0s 68us/step - loss: 4697.0544 - mse: 4697.0542 - accuracy: 0.0322\n",
      "\n",
      "Epoch 00005: mse improved from 4748.00879 to 4697.05420, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 6/10\n",
      "1429/1429 [==============================] - 0s 64us/step - loss: 4632.2928 - mse: 4632.2925 - accuracy: 0.0189\n",
      "\n",
      "Epoch 00006: mse improved from 4697.05420 to 4632.29248, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 7/10\n",
      "1429/1429 [==============================] - 0s 62us/step - loss: 4553.1492 - mse: 4553.1489 - accuracy: 0.0056\n",
      "\n",
      "Epoch 00007: mse improved from 4632.29248 to 4553.14893, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 8/10\n",
      "1429/1429 [==============================] - 0s 67us/step - loss: 4461.4940 - mse: 4461.4937 - accuracy: 0.0049\n",
      "\n",
      "Epoch 00008: mse improved from 4553.14893 to 4461.49365, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 9/10\n",
      "1429/1429 [==============================] - 0s 79us/step - loss: 4357.1793 - mse: 4357.1797 - accuracy: 0.0049\n",
      "\n",
      "Epoch 00009: mse improved from 4461.49365 to 4357.17969, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 10/10\n",
      "1429/1429 [==============================] - 0s 79us/step - loss: 4242.0038 - mse: 4242.0034 - accuracy: 0.0049\n",
      "\n",
      "Epoch 00010: mse improved from 4357.17969 to 4242.00342, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 1/10\n",
      "1429/1429 [==============================] - 0s 186us/step - loss: 4782.7487 - mse: 4782.7485 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: mse improved from inf to 4782.74854, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 2/10\n",
      "1429/1429 [==============================] - 0s 76us/step - loss: 4768.9745 - mse: 4768.9746 - accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00002: mse improved from 4782.74854 to 4768.97461, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 3/10\n",
      "1429/1429 [==============================] - 0s 75us/step - loss: 4743.8498 - mse: 4743.8501 - accuracy: 0.0014\n",
      "\n",
      "Epoch 00003: mse improved from 4768.97461 to 4743.85010, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 4/10\n",
      "1429/1429 [==============================] - 0s 72us/step - loss: 4704.5353 - mse: 4704.5347 - accuracy: 0.0280\n",
      "\n",
      "Epoch 00004: mse improved from 4743.85010 to 4704.53467, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 5/10\n",
      "1429/1429 [==============================] - 0s 74us/step - loss: 4649.4786 - mse: 4649.4780 - accuracy: 0.0322\n",
      "\n",
      "Epoch 00005: mse improved from 4704.53467 to 4649.47803, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 6/10\n",
      "1429/1429 [==============================] - 0s 75us/step - loss: 4578.2780 - mse: 4578.2778 - accuracy: 0.0147\n",
      "\n",
      "Epoch 00006: mse improved from 4649.47803 to 4578.27783, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 7/10\n",
      "1429/1429 [==============================] - 0s 77us/step - loss: 4492.0090 - mse: 4492.0088 - accuracy: 0.0049\n",
      "\n",
      "Epoch 00007: mse improved from 4578.27783 to 4492.00879, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 8/10\n",
      "1429/1429 [==============================] - 0s 73us/step - loss: 4391.4606 - mse: 4391.4604 - accuracy: 0.0049\n",
      "\n",
      "Epoch 00008: mse improved from 4492.00879 to 4391.46045, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 9/10\n",
      "1429/1429 [==============================] - 0s 74us/step - loss: 4278.2841 - mse: 4278.2837 - accuracy: 0.0063\n",
      "\n",
      "Epoch 00009: mse improved from 4391.46045 to 4278.28369, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 10/10\n",
      "1429/1429 [==============================] - 0s 76us/step - loss: 4152.6797 - mse: 4152.6797 - accuracy: 0.0056\n",
      "\n",
      "Epoch 00010: mse improved from 4278.28369 to 4152.67969, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 1/10\n",
      "1429/1429 [==============================] - 0s 195us/step - loss: 4769.3364 - mse: 4769.3364 - accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: mse improved from inf to 4769.33643, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 2/10\n",
      "1429/1429 [==============================] - 0s 75us/step - loss: 4757.4327 - mse: 4757.4326 - accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00002: mse improved from 4769.33643 to 4757.43262, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 3/10\n",
      "1429/1429 [==============================] - 0s 77us/step - loss: 4736.6056 - mse: 4736.6055 - accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00003: mse improved from 4757.43262 to 4736.60547, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 4/10\n",
      "1429/1429 [==============================] - 0s 75us/step - loss: 4703.8221 - mse: 4703.8218 - accuracy: 0.0266\n",
      "\n",
      "Epoch 00004: mse improved from 4736.60547 to 4703.82178, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 5/10\n",
      "1429/1429 [==============================] - 0s 73us/step - loss: 4657.2235 - mse: 4657.2241 - accuracy: 0.0392\n",
      "\n",
      "Epoch 00005: mse improved from 4703.82178 to 4657.22412, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 6/10\n",
      "1429/1429 [==============================] - 0s 75us/step - loss: 4596.8621 - mse: 4596.8623 - accuracy: 0.0294\n",
      "\n",
      "Epoch 00006: mse improved from 4657.22412 to 4596.86230, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 7/10\n",
      "1429/1429 [==============================] - 0s 73us/step - loss: 4522.5891 - mse: 4522.5884 - accuracy: 0.0098\n",
      "\n",
      "Epoch 00007: mse improved from 4596.86230 to 4522.58838, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 8/10\n",
      "1429/1429 [==============================] - 0s 117us/step - loss: 4436.9342 - mse: 4436.9341 - accuracy: 0.0042\n",
      "\n",
      "Epoch 00008: mse improved from 4522.58838 to 4436.93408, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 9/10\n",
      "1429/1429 [==============================] - 0s 166us/step - loss: 4338.8221 - mse: 4338.8223 - accuracy: 0.0056\n",
      "\n",
      "Epoch 00009: mse improved from 4436.93408 to 4338.82227, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n",
      "Epoch 10/10\n",
      "1429/1429 [==============================] - 0s 175us/step - loss: 4229.6271 - mse: 4229.6274 - accuracy: 0.0042\n",
      "\n",
      "Epoch 00010: mse improved from 4338.82227 to 4229.62744, saving model to C:\\Users\\Kanishk\\Downloads\\IE Courses\\Data Mining\\Project\\regressor.h5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "ss = ShuffleSplit(n_splits=5, test_size=0.25, random_state=0)\n",
    "for train_index, test_index in ss.split(X_transform):\n",
    "    X_train, y_train, X_test, y_test=X_transform[train_index],y.iloc[train_index],X_transform[test_index],y.iloc[test_index] \n",
    "    regressor.fit(X_train,y_train,epochs=10,batch_size=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.model.save_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477/477 [==============================] - 0s 87us/step\n"
     ]
    }
   ],
   "source": [
    "Pred_keras_regressor=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_keras_regressor_absolute=np.floor(Pred_keras_regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1db96394278>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, Pred_keras_regressor_absolute)\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 24.851153039832287\n",
      "MSE: 840.2138364779875\n",
      "RMSE: 28.986442287351988\n",
      "Accuracy: 1.257861635220126\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,mean_squared_error\n",
    "import numpy as np\n",
    "print('MAE:', mean_absolute_error(y_test, Pred_keras_regressor_absolute))\n",
    "print('MSE:', mean_squared_error(y_test, Pred_keras_regressor_absolute))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, Pred_keras_regressor_absolute)))\n",
    "print('Accuracy:',100*accuracy_score(y_test,Pred_keras_regressor_absolute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keras_reg=pd.DataFrame({'Actual Values':y_test,'Predictions':Pred_keras_regressor_absolute})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kanishk\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 53.,  51.],\n",
       "       [ 75.,  58.],\n",
       "       [  1.,  64.],\n",
       "       [ 97.,  62.],\n",
       "       [ 40.,  64.],\n",
       "       [100.,  65.],\n",
       "       [ 89.,  62.],\n",
       "       [ 23.,  64.],\n",
       "       [ 97.,  65.],\n",
       "       [ 48.,  64.],\n",
       "       [ 26.,  64.],\n",
       "       [100.,  45.],\n",
       "       [ 31.,  62.],\n",
       "       [ 96.,  64.],\n",
       "       [ 84.,  63.],\n",
       "       [100.,  63.],\n",
       "       [ 10.,  62.],\n",
       "       [ 66.,  61.],\n",
       "       [ 53.,  64.],\n",
       "       [ 43.,  64.],\n",
       "       [ 96.,  64.],\n",
       "       [ 91.,  64.],\n",
       "       [ 58.,  61.],\n",
       "       [ 47.,  64.],\n",
       "       [ 71.,  58.],\n",
       "       [ 81.,  56.],\n",
       "       [ 97.,  64.],\n",
       "       [ 45.,  60.],\n",
       "       [ 29.,  61.],\n",
       "       [ 85.,  59.],\n",
       "       [ 27.,  63.],\n",
       "       [ 85.,  65.],\n",
       "       [ 50.,  62.],\n",
       "       [ 88.,  59.],\n",
       "       [ 12.,  58.],\n",
       "       [ 93.,  65.],\n",
       "       [ 98.,  64.],\n",
       "       [ 41.,  64.],\n",
       "       [ 16.,  65.],\n",
       "       [ 31.,  64.],\n",
       "       [ 89.,  61.],\n",
       "       [ 95.,  60.],\n",
       "       [  3.,  64.],\n",
       "       [  7.,  64.],\n",
       "       [ 99.,  65.],\n",
       "       [ 42.,  65.],\n",
       "       [ 39.,  64.],\n",
       "       [ 34.,  63.],\n",
       "       [ 96.,  61.],\n",
       "       [ 89.,  57.],\n",
       "       [ 78.,  63.],\n",
       "       [ 80.,  61.],\n",
       "       [ 49.,  49.],\n",
       "       [ 53.,  63.],\n",
       "       [ 66.,  65.],\n",
       "       [ 95.,  65.],\n",
       "       [ 60.,  60.],\n",
       "       [100.,  47.],\n",
       "       [100.,  65.],\n",
       "       [ 98.,  61.],\n",
       "       [ 90.,  62.],\n",
       "       [ 55.,  64.],\n",
       "       [100.,  65.],\n",
       "       [ 69.,  64.],\n",
       "       [ 82.,  63.],\n",
       "       [ 75.,  62.],\n",
       "       [ 66.,  61.],\n",
       "       [ 99.,  63.],\n",
       "       [ 67.,  64.],\n",
       "       [100.,  60.],\n",
       "       [ 82.,  65.],\n",
       "       [ 54.,  64.],\n",
       "       [ 25.,  51.],\n",
       "       [ 92.,  62.],\n",
       "       [ 70.,  55.],\n",
       "       [100.,  66.],\n",
       "       [ 79.,  64.],\n",
       "       [ 37.,  65.],\n",
       "       [ 90.,  65.],\n",
       "       [100.,  45.],\n",
       "       [ 82.,  64.],\n",
       "       [ 57.,  58.],\n",
       "       [ 70.,  63.],\n",
       "       [ 57.,  61.],\n",
       "       [ 90.,  65.],\n",
       "       [ 43.,  60.],\n",
       "       [ 72.,  47.],\n",
       "       [  7.,  60.],\n",
       "       [ 84.,  60.],\n",
       "       [ 93.,  61.],\n",
       "       [ 74.,  65.],\n",
       "       [ 55.,  60.],\n",
       "       [ 22.,  64.],\n",
       "       [ 32.,  64.],\n",
       "       [ 92.,  57.],\n",
       "       [ 29.,  62.],\n",
       "       [ 85.,  64.],\n",
       "       [100.,  65.],\n",
       "       [ 88.,  62.],\n",
       "       [  4.,  62.],\n",
       "       [ 44.,  64.],\n",
       "       [ 58.,  64.],\n",
       "       [ 95.,  61.],\n",
       "       [ 82.,  64.],\n",
       "       [ 77.,  64.],\n",
       "       [ 88.,  61.],\n",
       "       [ 91.,  61.],\n",
       "       [ 53.,  62.],\n",
       "       [ 73.,  64.],\n",
       "       [ 54.,  62.],\n",
       "       [ 91.,  61.],\n",
       "       [100.,  65.],\n",
       "       [ 28.,  55.],\n",
       "       [ 48.,  64.],\n",
       "       [ 93.,  62.],\n",
       "       [ 87.,  63.],\n",
       "       [ 54.,  65.],\n",
       "       [ 79.,  63.],\n",
       "       [ 93.,  65.],\n",
       "       [ 79.,  59.],\n",
       "       [ 85.,  60.],\n",
       "       [ 88.,  62.],\n",
       "       [ 94.,  65.],\n",
       "       [ 73.,  61.],\n",
       "       [ 89.,  62.],\n",
       "       [  5.,  64.],\n",
       "       [ 40.,  64.],\n",
       "       [ 55.,  64.],\n",
       "       [ 62.,  63.],\n",
       "       [ 95.,  64.],\n",
       "       [100.,  47.],\n",
       "       [ 65.,  64.],\n",
       "       [ 93.,  65.],\n",
       "       [ 57.,  64.],\n",
       "       [100.,  60.],\n",
       "       [ 86.,  64.],\n",
       "       [ 46.,  62.],\n",
       "       [ 21.,  64.],\n",
       "       [ 46.,  60.],\n",
       "       [  1.,  62.],\n",
       "       [ 60.,  54.],\n",
       "       [ 22.,  64.],\n",
       "       [ 69.,  46.],\n",
       "       [ 51.,  60.],\n",
       "       [100.,  51.],\n",
       "       [ 91.,  64.],\n",
       "       [ 67.,  59.],\n",
       "       [ 78.,  60.],\n",
       "       [ 96.,  62.],\n",
       "       [ 23.,  64.],\n",
       "       [ 16.,  63.],\n",
       "       [ 98.,  64.],\n",
       "       [ 57.,  63.],\n",
       "       [ 54.,  57.],\n",
       "       [ 11.,  63.],\n",
       "       [ 93.,  63.],\n",
       "       [ 28.,  62.],\n",
       "       [ 51.,  64.],\n",
       "       [ 88.,  62.],\n",
       "       [ 99.,  64.],\n",
       "       [ 84.,  52.],\n",
       "       [ 71.,  59.],\n",
       "       [ 35.,  64.],\n",
       "       [100.,  97.],\n",
       "       [ 56.,  64.],\n",
       "       [100.,  65.],\n",
       "       [  7.,  63.],\n",
       "       [ 21.,  63.],\n",
       "       [ 84.,  61.],\n",
       "       [ 32.,  64.],\n",
       "       [ 90.,  64.],\n",
       "       [ 96.,  61.],\n",
       "       [ 95.,  65.],\n",
       "       [ 63.,  64.],\n",
       "       [ 69.,  64.],\n",
       "       [  1.,  61.],\n",
       "       [ 55.,  63.],\n",
       "       [ 79.,  64.],\n",
       "       [ 36.,  63.],\n",
       "       [ 97.,  62.],\n",
       "       [100.,  56.],\n",
       "       [ 81.,  59.],\n",
       "       [ 94.,  63.],\n",
       "       [ 94.,  62.],\n",
       "       [ 64.,  63.],\n",
       "       [ 42.,  64.],\n",
       "       [  1.,  64.],\n",
       "       [ 69.,  65.],\n",
       "       [ 53.,  57.],\n",
       "       [100.,  65.],\n",
       "       [ 98.,  62.],\n",
       "       [ 92.,  64.],\n",
       "       [ 71.,  61.],\n",
       "       [ 26.,  63.],\n",
       "       [ 99.,  61.],\n",
       "       [ 30.,  63.],\n",
       "       [ 71.,  64.],\n",
       "       [ 89.,  64.],\n",
       "       [ 82.,  63.],\n",
       "       [ 83.,  63.],\n",
       "       [ 98.,  65.],\n",
       "       [ 80.,  64.],\n",
       "       [ 42.,  64.],\n",
       "       [ 29.,  63.],\n",
       "       [ 53.,  59.],\n",
       "       [ 97.,  64.],\n",
       "       [ 31.,  57.],\n",
       "       [ 71.,  53.],\n",
       "       [ 68.,  58.],\n",
       "       [ 70.,  50.],\n",
       "       [ 81.,  62.],\n",
       "       [ 29.,  64.],\n",
       "       [ 20.,  62.],\n",
       "       [ 26.,  63.],\n",
       "       [ 63.,  63.],\n",
       "       [ 49.,  63.],\n",
       "       [ 52.,  64.],\n",
       "       [ 66.,  63.],\n",
       "       [ 99.,  63.],\n",
       "       [ 64.,  59.],\n",
       "       [ 53.,  53.],\n",
       "       [ 82.,  63.],\n",
       "       [ 95.,  64.],\n",
       "       [ 94.,  61.],\n",
       "       [ 36.,  64.],\n",
       "       [ 68.,  63.],\n",
       "       [ 24.,  64.],\n",
       "       [ 91.,  61.],\n",
       "       [ 87.,  64.],\n",
       "       [ 82.,  64.],\n",
       "       [ 17.,  63.],\n",
       "       [ 45.,  64.],\n",
       "       [ 44.,  64.],\n",
       "       [ 38.,  64.],\n",
       "       [ 77.,  61.],\n",
       "       [ 79.,  64.],\n",
       "       [  4.,  63.],\n",
       "       [ 42.,  61.],\n",
       "       [ 97.,  54.],\n",
       "       [ 45.,  63.],\n",
       "       [ 95.,  61.],\n",
       "       [ 77.,  64.],\n",
       "       [ 84.,  64.],\n",
       "       [ 64.,  61.],\n",
       "       [ 22.,  64.],\n",
       "       [ 70.,  57.],\n",
       "       [100.,  64.],\n",
       "       [ 93.,  65.],\n",
       "       [ 39.,  62.],\n",
       "       [ 36.,  65.],\n",
       "       [ 92.,  64.],\n",
       "       [  1.,  64.],\n",
       "       [ 41.,  64.],\n",
       "       [ 83.,  64.],\n",
       "       [ 65.,  62.],\n",
       "       [  4.,  65.],\n",
       "       [ 59.,  64.],\n",
       "       [ 55.,  60.],\n",
       "       [ 86.,  63.],\n",
       "       [100.,  65.],\n",
       "       [  6.,  60.],\n",
       "       [ 95.,  65.],\n",
       "       [ 37.,  60.],\n",
       "       [ 71.,  65.],\n",
       "       [ 72.,  61.],\n",
       "       [ 32.,  63.],\n",
       "       [ 88.,  64.],\n",
       "       [ 90.,  64.],\n",
       "       [ 35.,  62.],\n",
       "       [ 97.,  63.],\n",
       "       [ 79.,  64.],\n",
       "       [ 83.,  64.],\n",
       "       [ 58.,  65.],\n",
       "       [ 78.,  55.],\n",
       "       [ 61.,  65.],\n",
       "       [  6.,  62.],\n",
       "       [ 15.,  64.],\n",
       "       [ 51.,  62.],\n",
       "       [ 83.,  57.],\n",
       "       [ 26.,  64.],\n",
       "       [ 86.,  64.],\n",
       "       [ 29.,  61.],\n",
       "       [ 87.,  64.],\n",
       "       [ 90.,  58.],\n",
       "       [ 36.,  64.],\n",
       "       [ 91.,  63.],\n",
       "       [ 31.,  63.],\n",
       "       [ 88.,  59.],\n",
       "       [ 51.,  63.],\n",
       "       [ 21.,  65.],\n",
       "       [ 34.,  64.],\n",
       "       [ 78.,  65.],\n",
       "       [ 53.,  64.],\n",
       "       [ 79.,  61.],\n",
       "       [ 61.,  64.],\n",
       "       [ 58.,  65.],\n",
       "       [ 60.,  62.],\n",
       "       [ 32.,  64.],\n",
       "       [ 85.,  64.],\n",
       "       [ 44.,  64.],\n",
       "       [ 84.,  50.],\n",
       "       [ 98.,  64.],\n",
       "       [ 64.,  59.],\n",
       "       [ 50.,  65.],\n",
       "       [ 35.,  57.],\n",
       "       [ 96.,  61.],\n",
       "       [ 48.,  61.],\n",
       "       [  9.,  64.],\n",
       "       [ 98.,  59.],\n",
       "       [ 74.,  65.],\n",
       "       [ 42.,  63.],\n",
       "       [ 52.,  60.],\n",
       "       [ 82.,  56.],\n",
       "       [ 69.,  63.],\n",
       "       [ 64.,  65.],\n",
       "       [ 54.,  54.],\n",
       "       [ 36.,  64.],\n",
       "       [ 18.,  64.],\n",
       "       [  3.,  64.],\n",
       "       [ 42.,  63.],\n",
       "       [  4.,  63.],\n",
       "       [100.,  61.],\n",
       "       [ 51.,  62.],\n",
       "       [ 41.,  64.],\n",
       "       [ 92.,  62.],\n",
       "       [ 90.,  63.],\n",
       "       [ 99.,  83.],\n",
       "       [ 17.,  64.],\n",
       "       [ 80.,  64.],\n",
       "       [ 99.,  65.],\n",
       "       [ 35.,  61.],\n",
       "       [ 88.,  61.],\n",
       "       [ 22.,  64.],\n",
       "       [ 34.,  63.],\n",
       "       [ 69.,  61.],\n",
       "       [100.,  66.],\n",
       "       [  4.,  64.],\n",
       "       [ 97.,  64.],\n",
       "       [ 36.,  65.],\n",
       "       [ 79.,  63.],\n",
       "       [  3.,  65.],\n",
       "       [ 70.,  61.],\n",
       "       [ 45.,  46.],\n",
       "       [ 97.,  64.],\n",
       "       [ 80.,  51.],\n",
       "       [ 84.,  61.],\n",
       "       [ 24.,  59.],\n",
       "       [ 63.,  55.],\n",
       "       [ 75.,  62.],\n",
       "       [  5.,  60.],\n",
       "       [ 91.,  63.],\n",
       "       [ 40.,  62.],\n",
       "       [ 59.,  64.],\n",
       "       [ 54.,  60.],\n",
       "       [ 93.,  59.],\n",
       "       [ 79.,  64.],\n",
       "       [ 30.,  63.],\n",
       "       [ 22.,  62.],\n",
       "       [ 60.,  64.],\n",
       "       [ 84.,  57.],\n",
       "       [ 51.,  64.],\n",
       "       [ 81.,  57.],\n",
       "       [ 79.,  64.],\n",
       "       [ 71.,  64.],\n",
       "       [ 67.,  64.],\n",
       "       [ 85.,  64.],\n",
       "       [ 58.,  62.],\n",
       "       [ 95.,  62.],\n",
       "       [ 56.,  62.],\n",
       "       [ 92.,  65.],\n",
       "       [100.,  63.],\n",
       "       [ 36.,  63.],\n",
       "       [100.,  64.],\n",
       "       [100.,  59.],\n",
       "       [ 16.,  59.],\n",
       "       [ 77.,  64.],\n",
       "       [ 72.,  49.],\n",
       "       [ 95.,  63.],\n",
       "       [ 74.,  63.],\n",
       "       [ 99.,  58.],\n",
       "       [ 63.,  63.],\n",
       "       [ 99.,  59.],\n",
       "       [ 47.,  64.],\n",
       "       [ 73.,  65.],\n",
       "       [ 97.,  63.],\n",
       "       [ 98.,  64.],\n",
       "       [ 84.,  59.],\n",
       "       [ 78.,  63.],\n",
       "       [ 38.,  64.],\n",
       "       [ 70.,  60.],\n",
       "       [ 85.,  64.],\n",
       "       [ 83.,  65.],\n",
       "       [ 87.,  64.],\n",
       "       [ 94.,  62.],\n",
       "       [ 86.,  60.],\n",
       "       [ 83.,  58.],\n",
       "       [ 56.,  61.],\n",
       "       [ 15.,  61.],\n",
       "       [ 81.,  64.],\n",
       "       [ 46.,  59.],\n",
       "       [100.,  63.],\n",
       "       [ 19.,  47.],\n",
       "       [ 88.,  63.],\n",
       "       [ 97.,  62.],\n",
       "       [ 73.,  62.],\n",
       "       [ 14.,  63.],\n",
       "       [ 41.,  61.],\n",
       "       [ 34.,  62.],\n",
       "       [ 96.,  65.],\n",
       "       [ 48.,  60.],\n",
       "       [ 20.,  64.],\n",
       "       [ 52.,  64.],\n",
       "       [ 25.,  57.],\n",
       "       [ 21.,  64.],\n",
       "       [ 70.,  64.],\n",
       "       [ 68.,  62.],\n",
       "       [ 19.,  65.],\n",
       "       [ 67.,  59.],\n",
       "       [100.,  63.],\n",
       "       [ 84.,  61.],\n",
       "       [ 55.,  59.],\n",
       "       [ 97.,  61.],\n",
       "       [ 92.,  51.],\n",
       "       [ 96.,  64.],\n",
       "       [ 93.,  64.],\n",
       "       [ 70.,  62.],\n",
       "       [ 68.,  64.],\n",
       "       [ 40.,  62.],\n",
       "       [ 30.,  63.],\n",
       "       [ 68.,  62.],\n",
       "       [ 45.,  56.],\n",
       "       [ 26.,  64.],\n",
       "       [  1.,  56.],\n",
       "       [ 61.,  62.],\n",
       "       [ 59.,  64.],\n",
       "       [ 64.,  61.],\n",
       "       [ 65.,  63.],\n",
       "       [ 46.,  63.],\n",
       "       [100.,  62.],\n",
       "       [ 49.,  63.],\n",
       "       [ 76.,  60.],\n",
       "       [ 29.,  64.],\n",
       "       [ 87.,  64.],\n",
       "       [ 99.,  64.],\n",
       "       [ 79.,  65.],\n",
       "       [ 70.,  64.],\n",
       "       [ 58.,  57.],\n",
       "       [ 21.,  62.],\n",
       "       [ 39.,  63.],\n",
       "       [ 64.,  62.],\n",
       "       [ 58.,  63.],\n",
       "       [ 76.,  63.],\n",
       "       [ 90.,  65.],\n",
       "       [ 90.,  63.],\n",
       "       [  4.,  65.],\n",
       "       [ 82.,  63.],\n",
       "       [ 62.,  60.],\n",
       "       [ 18.,  64.],\n",
       "       [ 88.,  54.],\n",
       "       [ 81.,  61.],\n",
       "       [  8.,  62.],\n",
       "       [ 91.,  64.],\n",
       "       [ 63.,  58.],\n",
       "       [ 74.,  61.],\n",
       "       [ 22.,  63.],\n",
       "       [  1.,  64.],\n",
       "       [ 72.,  57.],\n",
       "       [ 65.,  62.],\n",
       "       [ 95.,  63.],\n",
       "       [ 75.,  61.],\n",
       "       [ 58.,  60.],\n",
       "       [ 13.,  60.],\n",
       "       [ 99.,  65.],\n",
       "       [ 83.,  63.],\n",
       "       [ 97.,  64.],\n",
       "       [ 87.,  50.],\n",
       "       [ 17.,  64.]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_keras_reg.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[279,   1],\n",
       "        [  0,   0]],\n",
       "\n",
       "       [[274,   0],\n",
       "        [  6,   0]],\n",
       "\n",
       "       [[278,   0],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[279,   0],\n",
       "        [  1,   0]],\n",
       "\n",
       "       [[278,   0],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[278,   0],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[275,   1],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[275,   1],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[278,   0],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[278,   0],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[279,   0],\n",
       "        [  1,   0]],\n",
       "\n",
       "       [[277,   1],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[278,   0],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[278,   0],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[279,   1],\n",
       "        [  0,   0]],\n",
       "\n",
       "       [[277,   2],\n",
       "        [  1,   0]],\n",
       "\n",
       "       [[278,   1],\n",
       "        [  1,   0]],\n",
       "\n",
       "       [[277,   2],\n",
       "        [  1,   0]],\n",
       "\n",
       "       [[276,   2],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[275,   1],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[277,   1],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[275,   5],\n",
       "        [  0,   0]],\n",
       "\n",
       "       [[279,   1],\n",
       "        [  0,   0]],\n",
       "\n",
       "       [[275,   4],\n",
       "        [  1,   0]],\n",
       "\n",
       "       [[278,   1],\n",
       "        [  1,   0]],\n",
       "\n",
       "       [[277,   3],\n",
       "        [  0,   0]],\n",
       "\n",
       "       [[272,   6],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[277,   1],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[279,   1],\n",
       "        [  0,   0]],\n",
       "\n",
       "       [[275,   2],\n",
       "        [  3,   0]],\n",
       "\n",
       "       [[276,   0],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[272,   6],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[274,   2],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[277,   1],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[274,   4],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[275,   3],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[278,   1],\n",
       "        [  1,   0]],\n",
       "\n",
       "       [[274,   5],\n",
       "        [  1,   0]],\n",
       "\n",
       "       [[276,   3],\n",
       "        [  1,   0]],\n",
       "\n",
       "       [[273,   5],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[270,   8],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[278,   1],\n",
       "        [  1,   0]],\n",
       "\n",
       "       [[277,   2],\n",
       "        [  1,   0]],\n",
       "\n",
       "       [[278,   2],\n",
       "        [  0,   0]],\n",
       "\n",
       "       [[274,   6],\n",
       "        [  0,   0]],\n",
       "\n",
       "       [[270,   9],\n",
       "        [  1,   0]],\n",
       "\n",
       "       [[277,   1],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[277,   1],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[271,   5],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[271,   4],\n",
       "        [  5,   0]],\n",
       "\n",
       "       [[276,   3],\n",
       "        [  1,   0]],\n",
       "\n",
       "       [[272,   6],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[274,   3],\n",
       "        [  3,   0]],\n",
       "\n",
       "       [[265,   6],\n",
       "        [  9,   0]],\n",
       "\n",
       "       [[273,   4],\n",
       "        [  3,   0]],\n",
       "\n",
       "       [[273,   5],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[274,   2],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[273,   6],\n",
       "        [  1,   0]],\n",
       "\n",
       "       [[273,   3],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[269,   8],\n",
       "        [  3,   0]],\n",
       "\n",
       "       [[272,   3],\n",
       "        [  5,   0]],\n",
       "\n",
       "       [[275,   3],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[273,   7],\n",
       "        [  0,   0]],\n",
       "\n",
       "       [[270,   5],\n",
       "        [  5,   0]],\n",
       "\n",
       "       [[271,   5],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[268,   6],\n",
       "        [  6,   0]],\n",
       "\n",
       "       [[276,   3],\n",
       "        [  1,   0]],\n",
       "\n",
       "       [[268,   8],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[274,   4],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[270,   6],\n",
       "        [  3,   1]],\n",
       "\n",
       "       [[272,   5],\n",
       "        [  2,   1]],\n",
       "\n",
       "       [[270,   7],\n",
       "        [  3,   0]],\n",
       "\n",
       "       [[268,   4],\n",
       "        [  8,   0]],\n",
       "\n",
       "       [[273,   2],\n",
       "        [  5,   0]],\n",
       "\n",
       "       [[270,   3],\n",
       "        [  6,   1]],\n",
       "\n",
       "       [[270,   5],\n",
       "        [  4,   1]],\n",
       "\n",
       "       [[271,   4],\n",
       "        [  5,   0]],\n",
       "\n",
       "       [[272,   4],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[276,   2],\n",
       "        [  2,   0]],\n",
       "\n",
       "       [[272,   2],\n",
       "        [  6,   0]],\n",
       "\n",
       "       [[275,   2],\n",
       "        [  3,   0]],\n",
       "\n",
       "       [[271,   4],\n",
       "        [  2,   3]],\n",
       "\n",
       "       [[272,   2],\n",
       "        [  6,   0]],\n",
       "\n",
       "       [[269,   4],\n",
       "        [  6,   1]],\n",
       "\n",
       "       [[275,   3],\n",
       "        [  1,   1]],\n",
       "\n",
       "       [[272,   3],\n",
       "        [  5,   0]],\n",
       "\n",
       "       [[274,   2],\n",
       "        [  4,   0]],\n",
       "\n",
       "       [[270,   2],\n",
       "        [  8,   0]],\n",
       "\n",
       "       [[276,   1],\n",
       "        [  3,   0]],\n",
       "\n",
       "       [[273,   1],\n",
       "        [  6,   0]],\n",
       "\n",
       "       [[273,   1],\n",
       "        [  6,   0]],\n",
       "\n",
       "       [[272,   2],\n",
       "        [  6,   0]],\n",
       "\n",
       "       [[279,   0],\n",
       "        [  1,   0]],\n",
       "\n",
       "       [[277,   0],\n",
       "        [  3,   0]],\n",
       "\n",
       "       [[269,   0],\n",
       "        [ 11,   0]],\n",
       "\n",
       "       [[279,   1],\n",
       "        [  0,   0]],\n",
       "\n",
       "       [[279,   1],\n",
       "        [  0,   0]],\n",
       "\n",
       "       [[279,   1],\n",
       "        [  0,   0]]], dtype=int64)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "multilabel_confusion_matrix(y_test,Pred_keras_regressor_absolute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[0,1,2,3,4,8,9,10,16,18,19,20,21,22,23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(a)):\n",
    "     a[i]=a[i]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 9, 10, 11, 17, 19, 20, 21, 22, 23, 24]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
